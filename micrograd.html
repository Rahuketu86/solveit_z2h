<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Minimal implementation of autograd">

<title>micrograd â€“ solveit_z2h</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-d09c2ebb0ad6a85e36aef4f9137b58e4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="micrograd â€“ solveit_z2h">
<meta property="og:description" content="Minimal implementation of autograd">
<meta property="og:image" content="https://Rahuketu86.github.io/solveit_z2h/01_micrograd_files/figure-html/cell-8-output-1.png">
<meta property="og:site_name" content="solveit_z2h">
<meta property="og:image:height" content="413">
<meta property="og:image:width" content="552">
<meta name="twitter:title" content="micrograd â€“ solveit_z2h">
<meta name="twitter:description" content="Minimal implementation of autograd">
<meta name="twitter:image" content="https://Rahuketu86.github.io/solveit_z2h/01_micrograd_files/figure-html/cell-8-output-1.png">
<meta name="twitter:image-height" content="413">
<meta name="twitter:image-width" content="552">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">solveit_z2h</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./micrograd.html">micrograd</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">solveit_z2h</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./micrograd.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">micrograd</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">utils</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./contextcollector.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Now you can call it:</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Read the markdown file</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#plan" id="toc-plan" class="nav-link active" data-scroll-target="#plan">Plan</a></li>
  <li><a href="#part-1-summary-understanding-derivatives" id="toc-part-1-summary-understanding-derivatives" class="nav-link" data-scroll-target="#part-1-summary-understanding-derivatives">Part 1 Summary: Understanding Derivatives</a></li>
  <li><a href="#part-2-summary-understanding-derivatives-and-gradients" id="toc-part-2-summary-understanding-derivatives-and-gradients" class="nav-link" data-scroll-target="#part-2-summary-understanding-derivatives-and-gradients">Part 2 Summary: Understanding Derivatives and Gradients</a>
  <ul class="collapse">
  <li><a href="#what-is-a-derivative" id="toc-what-is-a-derivative" class="nav-link" data-scroll-target="#what-is-a-derivative">What is a Derivative?</a></li>
  <li><a href="#multiple-inputs-partial-derivatives" id="toc-multiple-inputs-partial-derivatives" class="nav-link" data-scroll-target="#multiple-inputs-partial-derivatives">Multiple Inputs (Partial Derivatives)</a></li>
  <li><a href="#chain-rule-fundamentals" id="toc-chain-rule-fundamentals" class="nav-link" data-scroll-target="#chain-rule-fundamentals">Chain Rule Fundamentals</a></li>
  </ul></li>
  <li><a href="#part-3-summary-the-chain-rule-backpropagation" id="toc-part-3-summary-the-chain-rule-backpropagation" class="nav-link" data-scroll-target="#part-3-summary-the-chain-rule-backpropagation">Part 3 Summary: The Chain Rule &amp; Backpropagation</a></li>
  <li><a href="#part-4-summary-building-the-value-class" id="toc-part-4-summary-building-the-value-class" class="nav-link" data-scroll-target="#part-4-summary-building-the-value-class">Part 4 Summary: Building the Value Class</a></li>
  <li><a href="#part-5-summary-building-the-value-class" id="toc-part-5-summary-building-the-value-class" class="nav-link" data-scroll-target="#part-5-summary-building-the-value-class">Part 5 Summary: Building the Value Class</a>
  <ul class="collapse">
  <li><a href="#core-components" id="toc-core-components" class="nav-link" data-scroll-target="#core-components">Core Components</a></li>
  <li><a href="#primitive-operations-with-_backward" id="toc-primitive-operations-with-_backward" class="nav-link" data-scroll-target="#primitive-operations-with-_backward">Primitive Operations (with <code>_backward</code>)</a></li>
  <li><a href="#derived-operations-built-from-primitives" id="toc-derived-operations-built-from-primitives" class="nav-link" data-scroll-target="#derived-operations-built-from-primitives">Derived Operations (built from primitives)</a></li>
  <li><a href="#key-pattern" id="toc-key-pattern" class="nav-link" data-scroll-target="#key-pattern">Key Pattern</a></li>
  </ul></li>
  <li><a href="#part-6-summary-topological-sort-and-automatic-backpropagation" id="toc-part-6-summary-topological-sort-and-automatic-backpropagation" class="nav-link" data-scroll-target="#part-6-summary-topological-sort-and-automatic-backpropagation">Part 6 Summary: Topological Sort and Automatic Backpropagation</a>
  <ul class="collapse">
  <li><a href="#why-topological-sort" id="toc-why-topological-sort" class="nav-link" data-scroll-target="#why-topological-sort">Why Topological Sort?</a></li>
  <li><a href="#algorithm-dfs-based" id="toc-algorithm-dfs-based" class="nav-link" data-scroll-target="#algorithm-dfs-based">Algorithm (DFS-based)</a></li>
  <li><a href="#the-backward-method" id="toc-the-backward-method" class="nav-link" data-scroll-target="#the-backward-method">The <code>backward()</code> Method</a></li>
  <li><a href="#key-insight" id="toc-key-insight" class="nav-link" data-scroll-target="#key-insight">Key Insight</a></li>
  <li><a href="#value.backward" id="toc-value.backward" class="nav-link" data-scroll-target="#value.backward">Value.backward</a></li>
  <li><a href="#build_topo" id="toc-build_topo" class="nav-link" data-scroll-target="#build_topo">build_topo</a></li>
  <li><a href="#value.__rtruediv__" id="toc-value.__rtruediv__" class="nav-link" data-scroll-target="#value.__rtruediv__">Value.__rtruediv__</a></li>
  <li><a href="#value.__rsub__" id="toc-value.__rsub__" class="nav-link" data-scroll-target="#value.__rsub__">Value.__rsub__</a></li>
  <li><a href="#value.__rmul__" id="toc-value.__rmul__" class="nav-link" data-scroll-target="#value.__rmul__">Value.__rmul__</a></li>
  <li><a href="#value.__radd__" id="toc-value.__radd__" class="nav-link" data-scroll-target="#value.__radd__">Value.__radd__</a></li>
  <li><a href="#value.__truediv__" id="toc-value.__truediv__" class="nav-link" data-scroll-target="#value.__truediv__">Value.__truediv__</a></li>
  <li><a href="#value.__sub__" id="toc-value.__sub__" class="nav-link" data-scroll-target="#value.__sub__">Value.__sub__</a></li>
  <li><a href="#value.__neg__" id="toc-value.__neg__" class="nav-link" data-scroll-target="#value.__neg__">Value.__neg__</a></li>
  <li><a href="#value.__pow__" id="toc-value.__pow__" class="nav-link" data-scroll-target="#value.__pow__">Value.__pow__</a></li>
  <li><a href="#value.__mul__" id="toc-value.__mul__" class="nav-link" data-scroll-target="#value.__mul__">Value.__mul__</a></li>
  <li><a href="#value.__add__" id="toc-value.__add__" class="nav-link" data-scroll-target="#value.__add__">Value.__add__</a></li>
  <li><a href="#value" id="toc-value" class="nav-link" data-scroll-target="#value">Value</a></li>
  </ul></li>
  <li><a href="#part-7-summary-topological-sort-automatic-backward" id="toc-part-7-summary-topological-sort-automatic-backward" class="nav-link" data-scroll-target="#part-7-summary-topological-sort-automatic-backward">Part 7 Summary: Topological Sort &amp; Automatic Backward</a></li>
  <li><a href="#neural-network-implementation" id="toc-neural-network-implementation" class="nav-link" data-scroll-target="#neural-network-implementation">Neural Network Implementation</a></li>
  <li><a href="#part-8-summary-activation-functions" id="toc-part-8-summary-activation-functions" class="nav-link" data-scroll-target="#part-8-summary-activation-functions">Part 8 Summary: Activation Functions</a>
  <ul class="collapse">
  <li><a href="#implemented-activations" id="toc-implemented-activations" class="nav-link" data-scroll-target="#implemented-activations">Implemented Activations</a></li>
  </ul></li>
  <li><a href="#part-9-summary-training-neural-networks" id="toc-part-9-summary-training-neural-networks" class="nav-link" data-scroll-target="#part-9-summary-training-neural-networks">Part 9 Summary: Training Neural Networks</a>
  <ul class="collapse">
  <li><a href="#training-loop-structure" id="toc-training-loop-structure" class="nav-link" data-scroll-target="#training-loop-structure">Training Loop Structure</a></li>
  <li><a href="#loss-function-mse" id="toc-loss-function-mse" class="nav-link" data-scroll-target="#loss-function-mse">Loss Function (MSE)</a></li>
  <li><a href="#gradient-descent-update" id="toc-gradient-descent-update" class="nav-link" data-scroll-target="#gradient-descent-update">Gradient Descent Update</a></li>
  <li><a href="#critical-insight-activation-choice" id="toc-critical-insight-activation-choice" class="nav-link" data-scroll-target="#critical-insight-activation-choice">Critical Insight: Activation Choice</a></li>
  <li><a href="#training-results" id="toc-training-results" class="nav-link" data-scroll-target="#training-results">Training Results</a></li>
  </ul></li>
  <li><a href="#part-10-summary-neural-network-components" id="toc-part-10-summary-neural-network-components" class="nav-link" data-scroll-target="#part-10-summary-neural-network-components">Part 10 Summary: Neural Network Components</a>
  <ul class="collapse">
  <li><a href="#neuron" id="toc-neuron" class="nav-link" data-scroll-target="#neuron">Neuron</a></li>
  <li><a href="#layer" id="toc-layer" class="nav-link" data-scroll-target="#layer">Layer</a></li>
  <li><a href="#mlp-multi-layer-perceptron" id="toc-mlp-multi-layer-perceptron" class="nav-link" data-scroll-target="#mlp-multi-layer-perceptron">MLP (Multi-Layer Perceptron)</a></li>
  <li><a href="#parameter-management" id="toc-parameter-management" class="nav-link" data-scroll-target="#parameter-management">Parameter Management</a></li>
  </ul></li>
  <li><a href="#complete-dialog-synopsis" id="toc-complete-dialog-synopsis" class="nav-link" data-scroll-target="#complete-dialog-synopsis">Complete Dialog Synopsis</a>
  <ul class="collapse">
  <li><a href="#what-we-built" id="toc-what-we-built" class="nav-link" data-scroll-target="#what-we-built">What We Built</a></li>
  <li><a href="#major-accomplishments" id="toc-major-accomplishments" class="nav-link" data-scroll-target="#major-accomplishments">Major Accomplishments</a></li>
  <li><a href="#key-concepts-learned" id="toc-key-concepts-learned" class="nav-link" data-scroll-target="#key-concepts-learned">Key Concepts Learned</a></li>
  <li><a href="#following-andrej-karpathys-approach" id="toc-following-andrej-karpathys-approach" class="nav-link" data-scroll-target="#following-andrej-karpathys-approach">Following Andrej Karpathyâ€™s Approach</a></li>
  <li><a href="#final-achievement" id="toc-final-achievement" class="nav-link" data-scroll-target="#final-achievement">Final Achievement</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Rahuketu86/solveit_z2h/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="micrograd.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">micrograd</h1>
</div>

<div>
  <div class="description">
    Minimal implementation of autograd
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="plan" class="level2">
<h2 class="anchored" data-anchor-id="plan">Plan</h2>
<ul>
<li>Review micrograd implementation as per lecture. Implement everything from scratch</li>
<li>Generalize micrograd implementation for arrays and tensors using numpy</li>
<li>May be extend the ideas to jax, pytorch or tinygrad</li>
</ul>
<div id="841e6500" class="cell" data-time_run="2025-12-21T04:23:39.627883+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>summary_md <span class="op">=</span> pathlib.Path(<span class="st">"./transcripts/Summary.md"</span>).read_text()<span class="op">;</span> summary_md</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>transcript <span class="op">=</span> pathlib.Path(<span class="st">'./transcripts/lesson_01.txt'</span>).read_text()<span class="op">;</span> transcript[:<span class="dv">20</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>'hello  my  name  is '</code></pre>
</div>
</div>
<p>I want to follow along the tutorial 8 part tutorial zero to hero NN from Andrey Karpathy.I am going to do first part related to micrograd implementation. Please refer to $<code>summary_md</code> for overall course structure and use $<code>transcript</code> to guide me through the lesson.</p>
<section id="reply" class="level5">
<h5 class="anchored" data-anchor-id="reply">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great choice! Andrej Karpathyâ€™s micrograd tutorial is a fantastic way to understand neural networks from the ground up.</p>
<p><strong>What weâ€™re building:</strong> A tiny autograd engine called <em>micrograd</em> â€” it implements backpropagation, which is the core algorithm that powers all modern deep learning. The entire thing is only ~100 lines of Python!</p>
<p><strong>The big picture:</strong> 1. Understand derivatives intuitively 2. Build a <code>Value</code> class that tracks computations 3. Implement automatic backpropagation 4. Build a simple neural network on top</p>
<hr>
<p><strong>Letâ€™s start with Step 1: Derivative Intuition</strong></p>
<p>Before we build anything, Andrej wants us to <em>feel</em> what a derivative means â€” not just calculate it symbolically.</p>
<p>Hereâ€™s the idea: if you have a function <code>f(x)</code>, the derivative tells you <em>â€œif I nudge x a tiny bit, how much does f(x) change?â€</em></p>
<p><strong>Your first task:</strong> Create a simple function and explore its derivative numerically.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">5</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try: 1. Evaluate <code>f(3.0)</code> â€” what do you get? 2. Pick a tiny <code>h = 0.0001</code> and compute <code>(f(3.0 + h) - f(3.0)) / h</code></p>
<p>This approximates the derivative at x=3. What value do you get? Does the sign make sense if you look at where x=3 sits on a parabola?</p>
<p>Give it a try and let me know what you find!</p>
<div id="b643c67d" class="cell" data-time_run="2025-12-21T04:23:39.941993+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x): <span class="cf">return</span> <span class="dv">3</span><span class="op">*</span>x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">4</span><span class="op">*</span>x <span class="op">+</span> <span class="dv">5</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>f(<span class="fl">3.0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>20.0</code></pre>
</div>
</div>
<div id="3db96c27" class="cell" data-time_run="2025-12-21T04:23:40.229051+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="fl">3.0</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>(f(x<span class="op">+</span>h)<span class="op">-</span>f(x))<span class="op">/</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>14.00300000000243</code></pre>
</div>
</div>
<p>I expected (6*3-4=14) I go something close</p>
</section>
<section id="reply-1" class="level5">
<h5 class="anchored" data-anchor-id="reply-1">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent work! You got 14.003, which is very close to the exact derivative of 14. The small error (0.003) comes from using a finite <code>h</code> instead of an infinitely small one.</p>
<p><strong>Key insight:</strong> The derivative tells you the <em>slope</em> of the function at that point. At x=3, if you increase x by a tiny amount, f(x) increases about 14 times as fast.</p>
<p>Notice the sign is positive â€” that means the function is <em>increasing</em> at x=3. Makes sense for a parabola opening upward!</p>
<hr>
<p><strong>Now letâ€™s think about a different point:</strong></p>
<p>What do you think will happen at x = <strong>2/3</strong> (about 0.667)?</p>
<ul>
<li>Will the derivative be positive, negative, or zero?</li>
<li>Why?</li>
</ul>
<p>Try calculating it numerically if youâ€™d like, or just reason about where that point sits on the parabola <code>3xÂ² - 4x + 5</code>.</p>
<p>Derivative should be 0. This is at lowest point on parabola.where slope changes</p>
<div id="9ca1d487" class="cell" data-time_run="2025-12-21T04:23:40.358398+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>(f(x<span class="op">+</span>h)<span class="op">-</span>f(x))<span class="op">/</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>0.0029999999995311555</code></pre>
</div>
</div>
<div id="c5a1eea5" class="cell" data-time_run="2025-12-21T04:23:40.494087+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>))<span class="op">;</span> x</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>fxs <span class="op">=</span> [ f(x) <span class="cf">for</span> x <span class="kw">in</span> xs]<span class="op">;</span> fxs</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>[345,
 284,
 229,
 180,
 137,
 100,
 69,
 44,
 25,
 12,
 5,
 4,
 9,
 20,
 37,
 60,
 89,
 124,
 165,
 212]</code></pre>
</div>
</div>
<div id="e32115c1" class="cell" data-time_run="2025-12-21T04:23:40.598570+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a86cd89d" class="cell" data-time_run="2025-12-21T04:23:40.685394+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>plt.plot(xs, fxs)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>plt.vlines(<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, ymin<span class="op">=</span><span class="dv">0</span>, ymax<span class="op">=</span> <span class="bu">max</span>(fxs), color<span class="op">=</span><span class="st">'red'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-2" class="level5">
<h5 class="anchored" data-anchor-id="reply-2">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Youâ€™ve discovered something really important: <strong>at the minimum of the parabola, the derivative is zero!</strong></p>
<p>Your numerical calculation gave ~0.003 (essentially zero, just with tiny rounding error), and your graph beautifully shows that red line right at the bottom of the curve where the slope is flat.</p>
<p><strong>This is a key calculus concept:</strong> When the derivative equals zero, youâ€™re at a critical point â€” could be a minimum, maximum, or inflection point.</p>
<hr>
<p><strong>Letâ€™s connect this to the micrograd tutorial:</strong></p>
<p>Now that you understand what derivatives <em>mean</em>, weâ€™re ready to build something powerful. In the tutorial, youâ€™ll create a <code>Value</code> class that:</p>
<ol type="1">
<li>Wraps numbers (like <code>Value(2.0)</code>)</li>
<li>Tracks operations (addition, multiplication, etc.)</li>
<li><strong>Automatically computes derivatives</strong> through something called backpropagation</li>
</ol>
<p>Would you like to: - <strong>A)</strong> Start building the <code>Value</code> class right now? - <strong>B)</strong> First explore one more example with multiple inputs (like <code>f(a,b,c) = a*b + c</code>) to see how derivatives work with multiple variables?</p>
<p>What sounds more interesting to you?</p>
<p>I want to explore one more example with multiple input</p>
</section>
<section id="reply-3" class="level5">
<h5 class="anchored" data-anchor-id="reply-3">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great choice! Letâ€™s explore how derivatives work when a function has multiple inputs.</p>
<p>Hereâ€™s a simple function with three inputs:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> d(a, b, c):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a<span class="op">*</span>b <span class="op">+</span> c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Letâ€™s say <code>a=2.0</code>, <code>b=-3.0</code>, and <code>c=10.0</code>.</p>
<p><strong>First, whatâ€™s the output?</strong> Calculate <code>d(2.0, -3.0, 10.0)</code> â€” what do you get?</p>
<p><strong>Then, letâ€™s think:</strong> If we nudge just <code>a</code> by a tiny amount (keeping <code>b</code> and <code>c</code> fixed), how will the output change? Will it go up or down? By how much?</p>
<p>Try computing the derivative with respect to <code>a</code> using the same technique you used before:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># nudge only a, keep b and c the same</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>What do you expect to see?</p>
<div id="c48cba79" class="cell" data-time_run="2025-12-21T04:23:40.858822+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> d(a, b, c):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a<span class="op">*</span>b <span class="op">+</span> c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a09e1492" class="cell" data-time_run="2025-12-21T04:23:40.887583+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>h <span class="op">=</span> <span class="fl">0.001</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="1ec5f1ac" class="cell" data-time_run="2025-12-21T04:23:40.916316+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>a<span class="op">=</span><span class="fl">2.0</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>b<span class="op">=-</span><span class="fl">3.0</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>c<span class="op">=</span><span class="fl">10.0</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>d(a,b,c)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>4.0</code></pre>
</div>
</div>
<div id="29a4974d" class="cell" data-time_run="2025-12-21T04:23:40.955138+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>(d(a<span class="op">+</span>h, b, c)<span class="op">-</span>d(a, b, c))<span class="op">/</span>h</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># nudge only a, keep b and c the same</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>-3.0000000000001137</code></pre>
</div>
</div>
<p>Derivative of a should be b . Which we see from our calculation</p>
<div id="140b66b3" class="cell" data-time_run="2025-12-21T04:23:40.995166+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>(d(a, b<span class="op">+</span>h, c)<span class="op">-</span>d(a, b, c))<span class="op">/</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>1.9999999999997797</code></pre>
</div>
</div>
<p>Derivative of b should be a which we see from our calculations</p>
<div id="ef8713b2" class="cell" data-time_run="2025-12-21T04:23:41.032970+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>(d(a, b, c<span class="op">+</span>h)<span class="op">-</span>d(a, b, c))<span class="op">/</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>0.9999999999994458</code></pre>
</div>
</div>
<p>Derivative of c should be 1 which we see from our calculation. Of course we need to account for numerical error</p>
</section>
</section>
<section id="part-1-summary-understanding-derivatives" class="level2">
<h2 class="anchored" data-anchor-id="part-1-summary-understanding-derivatives">Part 1 Summary: Understanding Derivatives</h2>
<p><strong>Key Concepts:</strong> - Derivative = â€œsensitivityâ€ or â€œslopeâ€ - how much output changes when input changes - Numerical approximation: <code>(f(x+h) - f(x)) / h</code> for small h - Sign tells direction: positive = increasing, negative = decreasing - Zero derivative = critical point (min/max/inflection)</p>
<p><strong>Multiple inputs:</strong> - Each input has its own partial derivative - For <code>d = a*b + c</code>: âˆ‚d/âˆ‚a = b, âˆ‚d/âˆ‚b = a, âˆ‚d/âˆ‚c = 1</p>
<section id="reply-4" class="level5">
<h5 class="anchored" data-anchor-id="reply-4">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent work! Youâ€™ve discovered the <strong>local derivatives</strong> for each variable:</p>
<ul>
<li><strong>âˆ‚d/âˆ‚a = b</strong> (which is -3)</li>
<li><strong>âˆ‚d/âˆ‚b = a</strong> (which is 2)<br>
</li>
<li><strong>âˆ‚d/âˆ‚c = 1</strong></li>
</ul>
<p>This tells us something powerful: each input has its own â€œinfluenceâ€ on the output. For example, if you increase <code>a</code> slightly, the output changes by <code>-3</code> times that amount (it goes <em>down</em> because <code>b</code> is negative).</p>
<hr>
<p><strong>Hereâ€™s the key insight for micrograd:</strong></p>
<p>When we have <code>d = a*b + c</code>, we can think of this as a small computation graph: - First, <code>a*b</code> happens - Then, we add <code>c</code></p>
<p>In backpropagation, weâ€™ll work <em>backwards</em> through this graph, computing how each intermediate step affects the final output. This is the <strong>chain rule</strong> in action!</p>
<p><strong>Ready for the next step?</strong></p>
<p>Would you like to start building the <code>Value</code> class now? Weâ€™ll make it track these operations automatically so we never have to manually compute derivatives again!</p>
<p>Yes letâ€™s build the Value class now</p>
</section>
<section id="reply-5" class="level5">
<h5 class="anchored" data-anchor-id="reply-5">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Letâ€™s start building the <code>Value</code> class step by step.</p>
<p><strong>First, the basics:</strong> A <code>Value</code> object will wrap a number and eventually track how it was created. Letâ€™s start simple:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data <span class="op">=</span> data</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>):</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"Value(data=</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>data<span class="sc">}</span><span class="ss">)"</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try creating a couple of <code>Value</code> objects:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>What do you see when you print them?</p>
<p><strong>Next challenge:</strong> Right now, we canâ€™t do <code>a + b</code> â€” Python doesnâ€™t know how to add <code>Value</code> objects. We need to teach it!</p>
<p>Can you think about what should happen when we add two <code>Value</code> objects? What should the result be?</p>
<div id="6cc5e3fc" class="cell" data-time_run="2025-12-21T04:23:41.070573+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.utils <span class="im">import</span> store_attr, basic_repr</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cf436556" class="cell" data-time_run="2025-12-21T04:23:41.096884+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data): store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span>basic_repr(<span class="st">'data'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="e75f49d8" class="cell" data-time_run="2025-12-21T04:23:41.123333+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>Value(data<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Value(data=1)</code></pre>
</div>
</div>
<div id="6c5e90d5" class="cell" data-time_run="2025-12-21T04:23:41.159585+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Adding 2 value object should give new value object whose data is some of original</p>
</section>
<section id="reply-6" class="level5">
<h5 class="anchored" data-anchor-id="reply-6">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Exactly right! When we add two <code>Value</code> objects, we should get a new <code>Value</code> whose data is the sum of the original values.</p>
<p>Letâ€™s implement that by adding a special method called <code>__add__</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data): store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data'</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other):</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> Value(<span class="va">self</span>.data <span class="op">+</span> other.data)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try redefining your class with this new method, then test it:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>What does <code>c</code> show? Does it have the data you expected?</p>
<div id="ab635a33" class="cell" data-time_run="2025-12-21T04:23:41.185653+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data): store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span>basic_repr(<span class="st">'data'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="01c5fb9f" class="cell" data-time_run="2025-12-21T04:23:41.212394+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>a<span class="op">+</span>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Value(data=-1.0)</code></pre>
</div>
</div>
</section>
<section id="reply-7" class="level5">
<h5 class="anchored" data-anchor-id="reply-7">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! <code>a + b</code> gives <code>Value(data=-1.0)</code>, which is exactly right: 2.0 + (-3.0) = -1.0.</p>
<p><strong>Now letâ€™s add multiplication.</strong> Can you add a <code>__mul__</code> method to your <code>Value</code> class that handles multiplication?</p>
<p>Hint: It should work just like <code>__add__</code>, but multiply the data instead.</p>
<p>Try implementing it, then test with something like:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">*</span> b  <span class="co"># should give Value(data=-6.0)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Give it a shot!</p>
<div id="776625a4" class="cell" data-time_run="2025-12-21T04:23:41.250253+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.utils <span class="im">import</span> patch, patch_to</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="abe8d366" class="cell" data-time_run="2025-12-21T04:23:41.276185+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>:Value, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="8670ec00" class="cell" data-time_run="2025-12-21T04:23:41.302696+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>a<span class="op">*</span>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Value(data=-6.0)</code></pre>
</div>
</div>
</section>
<section id="reply-8" class="level5">
<h5 class="anchored" data-anchor-id="reply-8">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! Youâ€™ve got multiplication working. Now <code>a * b</code> correctly gives <code>Value(data=-6.0)</code>.</p>
<p><strong>Next crucial step:</strong> We need to track <em>where</em> values come from. Right now, our <code>Value</code> objects donâ€™t remember that <code>a * b</code> was created by multiplying <code>a</code> and <code>b</code>. This tracking is essential for backpropagation!</p>
<p>Letâ€™s add two new attributes to <code>Value</code>: - <code>_prev</code>: a set of the â€œparentâ€ values that created this one - <code>_op</code>: a string describing the operation (like <code>'+'</code> or <code>'*'</code>)</p>
<p>For leaf nodes (created directly), these will be empty. But for computed values, theyâ€™ll store the history.</p>
<p>Can you modify the <code>__init__</code> method to accept optional <code>children</code> and <code>op</code> parameters? Then update <code>__add__</code> and <code>__mul__</code> to pass this information when creating new values.</p>
<p>Give it a try, or let me know if youâ€™d like a hint!</p>
<p>Does fastcore has anything to patch properties?</p>
</section>
<section id="reply-9" class="level5">
<h5 class="anchored" data-anchor-id="reply-9">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Yes! <code>fastcore</code> has <code>@patch_property</code> (or <code>@patch_to</code> with <code>property</code>) for adding properties to existing classes.</p>
<p>For example:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.utils <span class="im">import</span> patch_property</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_property</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> some_prop(<span class="va">self</span>:Value):</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>.data <span class="op">*</span> <span class="dv">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Is that what youâ€™re looking for? Are you thinking of using properties for <code>_prev</code> and <code>_op</code>, or something else?</p>
<p>yes</p>
</section>
<section id="reply-10" class="level5">
<h5 class="anchored" data-anchor-id="reply-10">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great! You can use <code>@patch_property</code> to add <code>_prev</code> and <code>_op</code> as properties.</p>
<p>However, for this case, you might find it simpler to just add them as regular attributes in <code>__init__</code> since they need to be set when the object is created.</p>
<p>Hereâ€™s a hint for updating <code>__init__</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>):</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>    store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>._op <span class="op">=</span> op</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Then in <code>__add__</code> and <code>__mul__</code>, youâ€™d pass the children. For example:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data <span class="op">+</span> other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">'+'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Want to try implementing this? Or would you like me to show you the complete updated class?</p>
<div id="96cb20b7" class="cell" data-time_run="2025-12-21T04:23:41.338522+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>): </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>) <span class="co"># Largely overkill but want to try how fastcore works</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span> basic_repr(<span class="st">'data, _prev, _op'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="bf54268f" class="cell" data-time_run="2025-12-21T04:23:41.365402+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>Value(<span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Value(data=1, _prev=set(), _op='')</code></pre>
</div>
</div>
<div id="f71fe528" class="cell" data-time_run="2025-12-21T04:23:41.401382+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>:Value, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>:Value, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="85e7dd9b" class="cell" data-time_run="2025-12-21T04:23:41.429644+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>a<span class="op">*</span>b, a<span class="op">+</span>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(Value(data=-6.0, _prev={Value(data=2.0, _prev=set(), _op=''), Value(data=-3.0, _prev=set(), _op='')}, _op='*'),
 Value(data=-1.0, _prev={Value(data=2.0, _prev=set(), _op=''), Value(data=-3.0, _prev=set(), _op='')}, _op='+'))</code></pre>
</div>
</div>
</section>
<section id="reply-11" class="level5">
<h5 class="anchored" data-anchor-id="reply-11">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Your <code>Value</code> class is now tracking the computation graph!</p>
<p>Look at what youâ€™ve created: - <code>a * b</code> shows <code>_op='*'</code> and <code>_prev</code> contains both <code>a</code> and <code>b</code> - <code>a + b</code> shows <code>_op='+'</code> and also tracks its parents</p>
<p>This is the foundation of automatic differentiation! Each <code>Value</code> now knows its history.</p>
<p><strong>Next step: Adding gradients</strong></p>
<p>We need one more attribute: <code>grad</code> (the gradient/derivative). It should start at 0.0 for all values.</p>
<p>Can you add <code>self.grad = 0.0</code> to your <code>__init__</code> method? Then weâ€™ll be ready to implement backpropagation!</p>
<div id="9979e252" class="cell" data-time_run="2025-12-21T04:23:41.466467+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>) <span class="co"># Largely overkill but want to try how fastcore works</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="5dc16566" class="cell" data-time_run="2025-12-21T04:23:41.493240+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>:Value, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>:Value, other): <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="e35c6d54" class="cell" data-time_run="2025-12-21T04:23:41.520336+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>a<span class="op">*</span>b, a<span class="op">+</span>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=2.0, grad=0.0, _op='', _prev=set(), label=''), Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='')}, label=''),
 Value(data=-1.0, grad=0.0, _op='+', _prev={Value(data=2.0, grad=0.0, _op='', _prev=set(), label=''), Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='')}, label=''))</code></pre>
</div>
</div>
<div id="0f201fd4" class="cell" data-time_run="2025-12-21T04:23:41.558093+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> solveit_z2h.utils <span class="im">import</span> draw_dot</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="0a164fb9" class="cell" data-time_run="2025-12-21T04:23:41.584072+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>:Value): </span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="22ec37d9" class="cell" data-time_run="2025-12-21T04:23:41.610824+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-33-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="9bb6c2d6" class="cell" data-time_run="2025-12-21T04:23:41.647210+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)<span class="op">;</span>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-34-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8cc0a748" class="cell" data-time_run="2025-12-21T04:23:41.683628+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a<span class="op">*</span>b<span class="op">+</span>a<span class="op">+</span>b<span class="op">;</span>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-35-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="c4764dab" class="cell" data-time_run="2025-12-21T04:23:41.721237+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>c.label<span class="op">=</span><span class="st">'c'</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-36-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-12" class="level5">
<h5 class="anchored" data-anchor-id="reply-12">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! Youâ€™ve added <code>grad</code> and even added a <code>label</code> attribute for clarity. I also see youâ€™ve integrated a visualization function <a href="https://Rahuketu86.github.io/solveit_z2h/utils.html#draw_dot"><code>draw_dot</code></a> â€” thatâ€™s going to be really helpful for seeing the computation graph!</p>
<p>Now you have a nice expression: <code>c = a*b + a + b</code> which equals -7.0, and all the gradients are initialized to 0.</p>
<p><strong>Hereâ€™s the big question for backpropagation:</strong></p>
<p>If <code>c</code> is our â€œoutputâ€ and we want to know how <code>a</code> and <code>b</code> affect it, we need to fill in those <code>grad</code> values.</p>
<p>The first step is always: <strong>the gradient of the output with respect to itself is 1.0</strong></p>
<p>So weâ€™d set <code>c.grad = 1.0</code> (meaning â€œif c changes by 1, c changes by 1â€).</p>
<p>Then we work backwards through the graph to fill in <code>a.grad</code> and <code>b.grad</code>.</p>
<p>Would you like to: - <strong>A)</strong> Manually calculate what <code>a.grad</code> and <code>b.grad</code> should be (using the chain rule)? - <strong>B)</strong> Start implementing a <code>backward()</code> method that will do this automatically?</p>
<p>What sounds more interesting?</p>
<p>Letâ€™ do some examples of manual calculations to build the intuition</p>
</section>
<section id="reply-13" class="level5">
<h5 class="anchored" data-anchor-id="reply-13">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great choice! Building intuition first makes the code much easier to understand.</p>
<p>Letâ€™s start with your expression: <code>c = a*b + a + b</code> where <code>a=2.0</code> and <code>b=-3.0</code>.</p>
<p><strong>Question:</strong> What is the derivative of <code>c</code> with respect to <code>a</code>? (i.e., dc/da)</p>
<p>Think of it this way: if you nudge <code>a</code> by a tiny amount, how much does <code>c</code> change?</p>
<p>You can approach this two ways: 1. <strong>Numerically</strong> â€” try <code>(c(a+h, b) - c(a, b)) / h</code> like before 2. <strong>Analytically</strong> â€” look at <code>c = a*b + a + b</code> and differentiate with respect to <code>a</code> (treating <code>b</code> as a constant)</p>
<p>Try one or both approaches! What do you get for dc/da?</p>
<div id="14e84e5d" class="cell" data-time_run="2025-12-21T04:23:41.758368+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># c_dash = (a+h)*b+(a+h)+b;c_dash</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>a, b, h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a'),
 Value(data=-3.0, grad=0.0, _op='', _prev=set(), label=''),
 0.001)</code></pre>
</div>
</div>
<div id="54a5630a" class="cell" data-time_run="2025-12-21T04:23:41.795216+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>c_dash <span class="op">=</span> (a<span class="op">+</span>h)<span class="op">*</span>b<span class="op">+</span>(a<span class="op">+</span>h)<span class="op">+</span>b<span class="op">;</span>c_dash</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> c_dash = (a+h)*b+(a+h)+b;c_dash

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<p>How to check if something is number</p>
</section>
<section id="reply-14" class="level5">
<h5 class="anchored" data-anchor-id="reply-14">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good catch! You need to handle the case where youâ€™re adding a <code>Value</code> to a regular number (like <code>h</code>).</p>
<p>You can check if something is a number using:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="bu">isinstance</span>(other, (<span class="bu">int</span>, <span class="bu">float</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This returns <code>True</code> if <code>other</code> is an int or float, <code>False</code> otherwise.</p>
<p><strong>Hint:</strong> In your <code>__add__</code> method, if <code>other</code> is not a <code>Value</code>, you could wrap it in one first:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    other <span class="op">=</span> Value(other)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Want to try updating your <code>__add__</code> and <code>__mul__</code> methods to handle this?</p>
<div id="a84b83aa" class="cell" data-time_run="2025-12-19T06:07:38.146650+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="f524b76a" class="cell" data-time_run="2025-12-19T06:07:39.580514+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>c_dash <span class="op">=</span> (a<span class="op">+</span>h)<span class="op">*</span>b<span class="op">+</span>(a<span class="op">+</span>h)<span class="op">+</span>b<span class="op">;</span>c_dash</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2e53b0ba" class="cell" data-time_run="2025-12-19T06:07:41.219422+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>(c_dash<span class="op">-</span>c)<span class="op">/</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>What are magic methods for supporting substraction and div operators in python</p>
</section>
<section id="reply-15" class="level5">
<h5 class="anchored" data-anchor-id="reply-15">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>The magic methods for subtraction and division are:</p>
<ul>
<li><strong>Subtraction:</strong> <code>__sub__(self, other)</code> for <code>self - other</code></li>
<li><strong>Division:</strong> <code>__truediv__(self, other)</code> for <code>self / other</code></li>
</ul>
<p>You can also add the â€œreverseâ€ versions: - <code>__rsub__</code> for when a number is on the left: <code>5 - value_obj</code> - <code>__rtruediv__</code> for <code>5 / value_obj</code></p>
<p>Want to try implementing <code>__sub__</code> and <code>__truediv__</code> for your <code>Value</code> class? Theyâ€™ll follow the same pattern as <code>__add__</code> and <code>__mul__</code>.</p>
<div id="1908868a" class="cell" data-time_run="2025-12-21T04:23:41.896168+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">-</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb70-5"><a href="#cb70-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb70-6"><a href="#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb70-7"><a href="#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb70-8"><a href="#cb70-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb70-9"><a href="#cb70-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">-</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="cfa59183" class="cell" data-time_run="2025-12-21T04:23:41.922320+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>(c_dash<span class="op">-</span>c)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> (<span class="ansi-yellow-bg">c_dash</span>-c)

<span class="ansi-red-fg">NameError</span>: name 'c_dash' is not defined</pre>
</div>
</div>
</div>
<div id="9936a810" class="cell" data-time_run="2025-12-21T04:23:41.968168+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="op">-</span>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-44-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0a813b52" class="cell" data-time_run="2025-12-21T04:23:42.006268+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>c.data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>-7.0</code></pre>
</div>
</div>
<div id="ff66ce6c" class="cell" data-time_run="2025-12-21T04:23:42.043259+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>(<span class="dv">5</span><span class="op">-</span>c).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>12.0</code></pre>
</div>
</div>
<div id="d8140b41" class="cell" data-time_run="2025-12-21T04:23:42.079009+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Value(data=-7.0, grad=0.0, _op='+', _prev={Value(data=-3.0, grad=0.0, _op='', _prev=set(), label=''), Value(data=-4.0, grad=0.0, _op='+', _prev={Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a'), Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='')}, label=''), Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a')}, label='')}, label='c')</code></pre>
</div>
</div>
<div id="590d9831" class="cell" data-time_run="2025-12-21T04:23:42.116854+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">/</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"/"</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">/</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fd19d3a0" class="cell" data-time_run="2025-12-21T04:23:42.143756+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="op">/</span>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-49-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="bffdb2c0" class="cell" data-time_run="2025-12-21T04:23:42.182749+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>c<span class="op">/</span><span class="dv">5</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-50-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="1756d542" class="cell" data-time_run="2025-12-21T04:23:42.221179+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a<span class="op">*</span>b <span class="op">+</span> a<span class="op">+</span>b</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>((c_dash<span class="op">-</span>c)<span class="op">/</span>h).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 4</span>
<span class="ansi-green-fg">      2</span> b = Value(-<span class="ansi-green-fg">3.0</span>)
<span class="ansi-green-fg">      3</span> c = a*b + a+b
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">4</span> ((<span class="ansi-yellow-bg">c_dash</span>-c)/h).data

<span class="ansi-red-fg">NameError</span>: name 'c_dash' is not defined</pre>
</div>
</div>
</div>
<p>Analytically, it should be -b+1 for dc/da == -2</p>
</section>
<section id="reply-16" class="level5">
<h5 class="anchored" data-anchor-id="reply-16">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! You got <strong>-2.0</strong> numerically, and you correctly identified that analytically it should be <strong>-b + 1 = -(-3) + 1 = 3 + 1 = 4</strong>â€¦ wait, let me check your expression again.</p>
<p>Looking at <code>c = a*b + a + b</code>: - The derivative of <code>a*b</code> with respect to <code>a</code> is <code>b</code> - The derivative of <code>a</code> with respect to <code>a</code> is <code>1</code> - The derivative of <code>b</code> with respect to <code>a</code> is <code>0</code></p>
<p>So <strong>dc/da = b + 1 = -3 + 1 = -2</strong> âœ“</p>
<p>Your numerical result matches perfectly!</p>
<p><strong>Now try:</strong> What should <strong>dc/db</strong> be?</p>
<p>Think through it analytically first, then verify numerically if youâ€™d like!</p>
<p>Analytically, it should be a+1 for dc/da == 3</p>
<div id="1826950c" class="cell" data-time_run="2025-12-21T04:23:42.266561+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>c_dash <span class="op">=</span> (a)<span class="op">*</span>(b<span class="op">+</span>h)<span class="op">+</span>(a)<span class="op">+</span>(b<span class="op">+</span>h)<span class="op">;</span>c_dash</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>((c_dash<span class="op">-</span>c)<span class="op">/</span>h).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> c_dash = (a)*(b+h)+(a)+(b+h);c_dash
<span class="ansi-green-fg">      2</span> ((c_dash-c)/h).data

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
</section>
<section id="reply-17" class="level5">
<h5 class="anchored" data-anchor-id="reply-17">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! You got <strong>dc/db = 3.0</strong>, which matches your analytical calculation of <strong>a + 1 = 2 + 1 = 3</strong> âœ“</p>
<p>Youâ€™re building great intuition here! Notice how: - <strong>dc/da = b + 1 = -2</strong> (tells us how <code>a</code> influences <code>c</code>) - <strong>dc/db = a + 1 = 3</strong> (tells us how <code>b</code> influences <code>c</code>)</p>
<p>These are the gradients we eventually want to store in <code>a.grad</code> and <code>b.grad</code>!</p>
<p><strong>Ready for the next step?</strong></p>
<p>Now that you understand what the gradients <em>should</em> be, would you like to start implementing the <code>backward()</code> method that will calculate these automatically? Or would you like to try one more manual example with a different expression first?</p>
<p>Letâ€™s do one more with longer chain</p>
</section>
<section id="reply-18" class="level5">
<h5 class="anchored" data-anchor-id="reply-18">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great idea! Letâ€™s build a longer chain to see how gradients flow through multiple operations.</p>
<p>Hereâ€™s a new expression:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a chain: d = a*b, e = d + c, f = e*e</span></span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>So we have: **f = (a*b + c)Â²**</p>
<p><strong>Questions to explore:</strong></p>
<ol type="1">
<li>What is <code>f.data</code>? (the forward pass value)</li>
<li>What should <strong>df/da</strong> be? Think about how <code>a</code> affects <code>d</code>, then <code>d</code> affects <code>e</code>, then <code>e</code> affects <code>f</code>. This is the <strong>chain rule</strong>!</li>
</ol>
<p>Try building this expression first and see what <code>f.data</code> is. Then we can work on the gradient!</p>
<div id="f94c632b" class="cell" data-time_run="2025-12-21T04:23:42.313003+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a chain: d = a*b, e = d + c, f = e*e</span></span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="9c01dd11" class="cell" data-time_run="2025-12-21T04:23:42.338975+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-54-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>f.data is 16</p>
</section>
<section id="reply-19" class="level5">
<h5 class="anchored" data-anchor-id="reply-19">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! <code>f.data = 16</code> because: - d = 2 Ã— (-3) = -6 - e = -6 + 10 = 4 - f = 4 Ã— 4 = 16</p>
<p><strong>Now for the gradient df/da:</strong></p>
<p>Think through the chain rule step by step: 1. How does <code>a</code> affect <code>d</code>? (Whatâ€™s dd/da?) 2. How does <code>d</code> affect <code>e</code>? (Whatâ€™s de/dd?) 3. How does <code>e</code> affect <code>f</code>? (Whatâ€™s df/de?)</p>
<p>The chain rule says: <strong>df/da = (df/de) Ã— (de/dd) Ã— (dd/da)</strong></p>
<p>Can you work out each piece? Start with the easiest one â€” whatâ€™s <strong>de/dd</strong>?</p>
<p>h change in a will result in b*h change in d</p>
<div id="92160564" class="cell" data-time_run="2025-12-21T04:23:42.377959+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>d_dash <span class="op">=</span> (a<span class="op">+</span>h)<span class="op">*</span>b</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>((d_dash<span class="op">-</span>d)<span class="op">/</span>h).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> d_dash = (<span class="ansi-yellow-bg">a</span><span class="ansi-yellow-bg">+</span><span class="ansi-yellow-bg">h</span>)*b
<span class="ansi-green-fg">      2</span> ((d_dash-d)/h).data

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<div id="f476f83a" class="cell" data-time_run="2025-12-21T04:23:42.425286+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>(b<span class="op">*</span>h).data, (d_dash<span class="op">-</span>d).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> (<span class="ansi-yellow-bg">b</span><span class="ansi-yellow-bg">*</span><span class="ansi-yellow-bg">h</span>).data, (d_dash-d).data

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 5</span>, in <span class="ansi-cyan-fg">__mul__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      4</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">5</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__mul__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data*<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">*</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<p>Since d = a<em>b, e = d + c, f = e</em>e, - Any change in d will have equivalent change in e - Any change in e will have 2*e-val times change in f</p>
<div id="a439f8af" class="cell" data-time_run="2025-12-21T04:23:42.471974+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>e_dash <span class="op">=</span> (d<span class="op">+</span>h)<span class="op">+</span>c</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>(e_dash<span class="op">-</span>e).data, h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> e_dash = (<span class="ansi-yellow-bg">d</span><span class="ansi-yellow-bg">+</span><span class="ansi-yellow-bg">h</span>)+c
<span class="ansi-green-fg">      2</span> (e_dash-e).data, h

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<div id="f07005f0" class="cell" data-time_run="2025-12-21T04:23:42.521011+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>f_dash <span class="op">=</span> (e<span class="op">+</span>h)<span class="op">*</span>(e<span class="op">+</span>h)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>(f<span class="op">-</span>f_dash).data, <span class="dv">2</span><span class="op">*</span>e.data<span class="op">*</span>h</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> f_dash = (<span class="ansi-yellow-bg">e</span><span class="ansi-yellow-bg">+</span><span class="ansi-yellow-bg">h</span>)*(e+h)
<span class="ansi-green-fg">      2</span> (f-f_dash).data, <span class="ansi-green-fg">2</span>*e.data*h

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<div id="920a99b7" class="cell" data-time_run="2025-12-21T04:23:42.569562+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df/da</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a921ef9c" class="cell" data-time_run="2025-12-21T04:23:42.596828+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> (a<span class="op">+</span>h) <span class="op">*</span> b</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>f_dash <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>f_dash.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> d = (<span class="ansi-yellow-bg">a</span><span class="ansi-yellow-bg">+</span><span class="ansi-yellow-bg">h</span>) * b
<span class="ansi-green-fg">      2</span> d.label = <span class="ansi-yellow-fg">'</span><span class="ansi-yellow-fg">d</span><span class="ansi-yellow-fg">'</span>
<span class="ansi-green-fg">      3</span> e = d + c

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
<div id="efd080c0" class="cell" data-time_run="2025-12-21T04:23:42.643612+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co">#df/da</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>df_da <span class="op">=</span> ((f_dash<span class="op">-</span>f)<span class="op">/</span>h)<span class="op">;</span> df_da.data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>
<span class="ansi-green-fg">      1</span> <span style="font-style:italic;color:rgb(95,135,135)">#df/da</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> df_da = ((f_dash-f)/h); df_da.data

<span class="ansi-red-fg">NameError</span>: name 'f_dash' is not defined</pre>
</div>
</div>
</div>
<div id="88f67e02" class="cell" data-time_run="2025-12-21T04:23:42.690059+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">*</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>:Value, other): </span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">+</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2563692e" class="cell" data-time_run="2025-12-21T04:23:42.716417+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Analytically df/da = (df/de) Ã— (de/dd) Ã— (dd/da) for d = a*b, e = d + c, f = e*e</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="co"># df/de = 2e</span></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="co"># de/dd = 1</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co"># dd/da = b</span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co"># So 2e*1*b</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>(<span class="dv">2</span><span class="op">*</span>e<span class="op">*</span>b).data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>-24.0</code></pre>
</div>
</div>
<div id="62ce024b" class="cell" data-time_run="2025-12-21T04:23:42.752998+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Numerical Calculations via chain rule</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>dd_da <span class="op">=</span> ((a<span class="op">+</span>h)<span class="op">*</span>b<span class="op">-</span>a<span class="op">*</span>b)<span class="op">/</span>h<span class="op">;</span> dd_da.data</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>de_dd <span class="op">=</span> (((d<span class="op">+</span>h)<span class="op">+</span>c)<span class="op">-</span>(d<span class="op">+</span>c))<span class="op">/</span>h<span class="op">;</span> de_dd.data</span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>df_de <span class="op">=</span> ((e<span class="op">+</span>h)<span class="op">*</span>(e<span class="op">+</span>h)<span class="op">-</span>e<span class="op">*</span>e)<span class="op">/</span>h<span class="op">;</span> df_de.data</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>df_da <span class="op">=</span> df_de<span class="op">*</span>de_dd<span class="op">*</span>dd_da<span class="op">;</span> df_da.data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>
<span class="ansi-green-fg">      1</span> <span style="font-style:italic;color:rgb(95,135,135)"># Numerical Calculations via chain rule</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> dd_da = ((a+h)*b-a*b)/h; dd_da.data
<span class="ansi-green-fg">      3</span> de_dd = (((d+h)+c)-(d+c))/h; de_dd.data
<span class="ansi-green-fg">      4</span> df_de = ((e+h)*(e+h)-e*e)/h; df_de.data

<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[1]</span><span class="ansi-green-fg">, line 2</span>, in <span class="ansi-cyan-fg">__add__</span><span class="ansi-blue-fg">(self, other)</span>
<span class="ansi-green-fg">      1</span> <span style="color:rgb(175,0,255)">@patch_to</span>(Value)
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">__add__</span>(<span style="color:rgb(0,135,0)">self</span>:Value, other): <span style="font-weight:bold;color:rgb(0,135,0)">return</span> Value(<span style="color:rgb(0,135,0)">self</span>.data+<span class="ansi-yellow-bg">other</span><span class="ansi-yellow-bg">.</span><span class="ansi-yellow-bg">data</span>, children=(<span style="color:rgb(0,135,0)">self</span>, other), op=<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">+</span><span class="ansi-yellow-fg">"</span>)

<span class="ansi-red-fg">AttributeError</span>: 'float' object has no attribute 'data'</pre>
</div>
</div>
</div>
</section>
<section id="reply-20" class="level5">
<h5 class="anchored" data-anchor-id="reply-20">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent work! Youâ€™ve successfully computed <strong>df/da = -24</strong> using both methods:</p>
<ol type="1">
<li><strong>Numerically</strong> (direct): -23.991</li>
<li><strong>Chain rule</strong> (step by step): -23.985</li>
<li><strong>Analytically</strong>: 2Ã—eÃ—b = 2Ã—4Ã—(-3) = <strong>-24</strong> âœ“</li>
</ol>
<p>This is the essence of backpropagation! You computed: - <strong>dd/da = b = -3</strong> (local gradient at the <code>*</code> operation) - <strong>de/dd = 1</strong> (local gradient at the <code>+</code> operation)<br>
- <strong>df/de = 2e = 8</strong> (local gradient at the <code>e*e</code> operation)</p>
<p>Then multiplied them: <strong>-3 Ã— 1 Ã— 8 = -24</strong></p>
<hr>
<p><strong>Key insight:</strong> Each operation only needs to know its <em>local</em> gradient. Then we multiply them together (chain rule) to get the full gradient!</p>
<p><strong>Ready to code this?</strong> Would you like to start implementing the <code>backward()</code> method now? Weâ€™ll make each operation (like <code>+</code> and <code>*</code>) store a little function that knows how to compute its local gradients.</p>
<p>Okay, I understand the insight. Each operation only needs to know the local gradient, and for calculating the full gradient, we just need to multiply them together. Before going into backword, can you give me some intuitions about the next step?</p>
</section>
<section id="reply-21" class="level5">
<h5 class="anchored" data-anchor-id="reply-21">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great question! Hereâ€™s the intuition for what comes next:</p>
<p><strong>The backward() method will:</strong></p>
<ol type="1">
<li><p><strong>Start at the output</strong> (like <code>f</code>) and set <code>f.grad = 1.0</code> â€” this means â€œif f changes by 1, f changes by 1â€ (the base case)</p></li>
<li><p><strong>Work backwards</strong> through the graph, visiting each operation in reverse order</p></li>
<li><p><strong>At each operation</strong>, use the local gradient to â€œpass backâ€ the gradient to its inputs</p></li>
</ol>
<p>For example, at the <code>e * e</code> operation: - We know <code>f.grad</code> (how much f affects the final output) - We compute the local gradient: <code>df/de = 2*e</code> - We update <code>e.grad</code> by multiplying: <code>e.grad += f.grad * (2*e)</code></p>
<p>The <code>+=</code> is important because a value might be used multiple times (like <code>e</code> is used twice in <code>e*e</code>)!</p>
<p><strong>Question:</strong> Looking at your expression <code>d = a*b</code>, if we know <code>d.grad</code>, how would you calculate what to add to <code>a.grad</code>? Whatâ€™s the local gradient of <code>*</code> with respect to <code>a</code>?</p>
<p>We calculate a.grad as b*d.grad, localgradient is b</p>
</section>
<section id="reply-22" class="level5">
<h5 class="anchored" data-anchor-id="reply-22">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Youâ€™ve got it exactly right:</p>
<p><strong>For <code>d = a * b</code>:</strong> - Local gradient with respect to <code>a</code> is <code>b</code> - So: <code>a.grad += d.grad * b.data</code></p>
<p>And by symmetry: - Local gradient with respect to <code>b</code> is <code>a</code><br>
- So: <code>b.grad += d.grad * a.data</code></p>
<p><strong>Now hereâ€™s the implementation question:</strong></p>
<p>Each operation needs to â€œknowâ€ how to do this backward pass. Weâ€™ll store a function called <code>_backward</code> in each <code>Value</code> that gets created.</p>
<p>For example, when you do <code>d = a * b</code>, we need to store a function that says â€œwhen backward() is called on d, update a.grad and b.grad using the local gradients.â€</p>
<p>Would you like to try adding a <code>_backward</code> attribute to your <code>Value</code> class and implementing it for the <code>*</code> operation? Or would you like me to show you a small example first?</p>
<p>Does it need to be an attribute or a method?</p>
</section>
<section id="reply-23" class="level5">
<h5 class="anchored" data-anchor-id="reply-23">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good question! It could be either, but hereâ€™s the key distinction:</p>
<p><strong>Attribute</strong> (a stored function): - Each <code>Value</code> object stores its own specific backward function - Different operations (like <code>+</code> vs <code>*</code>) can have different backward logic - More flexible â€” youâ€™re storing â€œwhat to doâ€ when this specific value was created</p>
<p><strong>Method</strong> (same for all Values): - Would be the same function for every <code>Value</code> object - But different operations need different backward logic!</p>
<p>So we use an <strong>attribute</strong> â€” each <code>Value</code> stores its own <code>_backward</code> function that knows how to propagate gradients for the specific operation that created it.</p>
<p>By default (for leaf nodes), <code>_backward</code> does nothing. But for computed values, weâ€™ll set it to the appropriate function.</p>
<p>Want to try adding <code>self._backward = lambda: None</code> to your <code>__init__</code> method as a starting point?</p>
<p>okay can you collect Value class implementation and all the patch methods in next code cell.Keep class structure and patch_to methods as it is and also add self._backward = lambda: None to original class</p>
</section>
<section id="reply-24" class="level5">
<h5 class="anchored" data-anchor-id="reply-24">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Hereâ€™s the complete <code>Value</code> class with all the patches collected:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-16"><a href="#cb98-16" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-17"><a href="#cb98-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-18"><a href="#cb98-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-19"><a href="#cb98-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb98-20"><a href="#cb98-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-21"><a href="#cb98-21" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-22"><a href="#cb98-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-23"><a href="#cb98-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-24"><a href="#cb98-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">-</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb98-25"><a href="#cb98-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-26"><a href="#cb98-26" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-27"><a href="#cb98-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-28"><a href="#cb98-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-29"><a href="#cb98-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">/</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"/"</span>)</span>
<span id="cb98-30"><a href="#cb98-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-31"><a href="#cb98-31" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-32"><a href="#cb98-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-33"><a href="#cb98-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-34"><a href="#cb98-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">*</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb98-35"><a href="#cb98-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-36"><a href="#cb98-36" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-37"><a href="#cb98-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-38"><a href="#cb98-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-39"><a href="#cb98-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">+</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb98-40"><a href="#cb98-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-41"><a href="#cb98-41" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-42"><a href="#cb98-42" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-43"><a href="#cb98-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-44"><a href="#cb98-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">-</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb98-45"><a href="#cb98-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-46"><a href="#cb98-46" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-47"><a href="#cb98-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb98-48"><a href="#cb98-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb98-49"><a href="#cb98-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">/</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"/"</span>)</span>
<span id="cb98-50"><a href="#cb98-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-51"><a href="#cb98-51" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb98-52"><a href="#cb98-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>): </span>
<span id="cb98-53"><a href="#cb98-53" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb98-54"><a href="#cb98-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Ready to add the backward logic to the operations?</p>
<div id="01158b47" class="cell" data-time_run="2025-12-21T04:23:42.810650+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb99-15"><a href="#cb99-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-16"><a href="#cb99-16" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-17"><a href="#cb99-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-18"><a href="#cb99-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-19"><a href="#cb99-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb99-20"><a href="#cb99-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-21"><a href="#cb99-21" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-22"><a href="#cb99-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-23"><a href="#cb99-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-24"><a href="#cb99-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">-</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb99-25"><a href="#cb99-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-26"><a href="#cb99-26" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-27"><a href="#cb99-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-28"><a href="#cb99-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-29"><a href="#cb99-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(<span class="va">self</span>.data<span class="op">/</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"/"</span>)</span>
<span id="cb99-30"><a href="#cb99-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-31"><a href="#cb99-31" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-32"><a href="#cb99-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span>.<span class="fu">__mul__</span>(other)</span>
<span id="cb99-33"><a href="#cb99-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-34"><a href="#cb99-34" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-35"><a href="#cb99-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span>.<span class="fu">__add__</span>(other)</span>
<span id="cb99-36"><a href="#cb99-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-37"><a href="#cb99-37" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-38"><a href="#cb99-38" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-39"><a href="#cb99-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-40"><a href="#cb99-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">-</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"-"</span>)</span>
<span id="cb99-41"><a href="#cb99-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-42"><a href="#cb99-42" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-43"><a href="#cb99-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb99-44"><a href="#cb99-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb99-45"><a href="#cb99-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Value(other.data<span class="op">/</span><span class="va">self</span>.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"/"</span>)</span>
<span id="cb99-46"><a href="#cb99-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-47"><a href="#cb99-47" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb99-48"><a href="#cb99-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>): </span>
<span id="cb99-49"><a href="#cb99-49" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb99-50"><a href="#cb99-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Provide the last test case to verify</p>
</section>
<section id="reply-25" class="level5">
<h5 class="anchored" data-anchor-id="reply-25">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Hereâ€™s a test case to verify everything still works:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span>
<span id="cb100-11"><a href="#cb100-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-12"><a href="#cb100-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f.data = </span><span class="sc">{</span>f<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Should be 16.0</span></span>
<span id="cb100-13"><a href="#cb100-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f.grad = </span><span class="sc">{</span>f<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try running this to make sure your new <code>Value</code> class works correctly!</p>
<div id="a2f5d1f2" class="cell" data-time_run="2025-12-21T04:23:42.839476+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f.data = </span><span class="sc">{</span>f<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Should be 16.0</span></span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"f.grad = </span><span class="sc">{</span>f<span class="sc">.</span>grad<span class="sc">}</span><span class="ss">"</span>)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>f.data = 16.0
f.grad = 0.0</code></pre>
</div>
</div>
<div id="0fe2ac12" class="cell" data-time_run="2025-12-21T04:23:42.876736+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-67-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="08d1a54b" class="cell" data-time_run="2025-12-21T04:23:42.914367+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="op">+</span>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-68-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0d833e4c" class="cell" data-time_run="2025-12-21T04:23:42.953320+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span><span class="op">*</span>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-69-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Okay I have intuitions now for forward pass, chain rule and I understand following 1. For any operation you only need to know the current gradient 2. To get full gradient for output against certain input upstream on computation graph you basically can multiply all the gradient at each operation.</p>
<p>However I need more intuition to jump for here to backward pass. Help me understand like I am a beginner in calculas</p>
</section>
<section id="reply-26" class="level5">
<h5 class="anchored" data-anchor-id="reply-26">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great question! Let me build the intuition step by step.</p>
<p><strong>Imagine water flowing backwards through pipes:</strong></p>
<p>Your computation graph is like a network of pipes:</p>
<pre><code>a â”€â”€â”
    â”œâ”€â”€(*)--&gt; d â”€â”€â”
b â”€â”€â”˜             â”œâ”€â”€(+)--&gt; e â”€â”€â”
                  â”‚             â”œâ”€â”€(*)--&gt; f
c â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                    e â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<p>In the <strong>forward pass</strong>, values flow left-to-right (data flows through).</p>
<p>In the <strong>backward pass</strong>, gradients flow right-to-left (influence flows back).</p>
<p><strong>The key idea:</strong></p>
<p>Start at the end (<code>f</code>) and ask: <em>â€œHow much does each thing upstream affect me?â€</em></p>
<ol type="1">
<li>Set <code>f.grad = 1</code> â€” â€œf affects f by exactly 1â€</li>
<li>Then ask: â€œf came from <code>e * e</code>, so how much does <code>e</code> affect <code>f</code>?â€</li>
<li>Compute the local gradient (2Ã—e = 8), multiply by <code>f.grad</code>, and add to <code>e.grad</code></li>
<li>Keep going backwardsâ€¦</li>
</ol>
<p><strong>The question for you:</strong></p>
<p>Why do we start from the output and go backwards, instead of starting from the inputs?</p>
<p>Okay I get the calculation, However I still donâ€™t have good intuition on it. Did Karpathy used some analogies to explain this in his video. Please review. Help me get an intuition for each backward operation</p>
</section>
<section id="reply-27" class="level5">
<h5 class="anchored" data-anchor-id="reply-27">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great idea! Let me check what Karpathy says in the videoâ€¦</p>
<p>From the transcript, he uses this intuition:</p>
<p><strong>â€œIf I wiggle this input a tiny bit, how does the output respond?â€</strong></p>
<p>Hereâ€™s how he explains each operation:</p>
<hr>
<p><strong>Plus node (+):</strong> He calls it a â€œdistributor of gradientâ€ â€” the gradient just flows through equally to both inputs.</p>
<p><em>Intuition:</em> If <code>c = a + b</code>, and you wiggle <code>a</code> by 1, then <code>c</code> wiggles by exactly 1. Same for <code>b</code>. So both get the full gradient passed back.</p>
<hr>
<p>**Times node (*):** The gradient â€œswapsâ€ the values.</p>
<p><em>Intuition:</em> If <code>d = a * b</code>, and you wiggle <code>a</code> by a tiny amount, how much does <code>d</code> change? It changes by <code>b</code> times that amount! So the gradient for <code>a</code> involves <code>b</code>.</p>
<hr>
<p><strong>His key phrase:</strong> The gradient is â€œthe sensitivity of the output with respect to this input.â€</p>
<p>Does the â€œwiggleâ€ intuition help? Would you like to manually trace through the backward pass for your <code>f = e * e</code> example using this thinking?</p>
<p>This is better I still need some for explaination to make it click. Can you try more examples, different ways of explainations. Feel free to check online if necessary</p>
</section>
<section id="reply-28" class="level5">
<h5 class="anchored" data-anchor-id="reply-28">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Let me search for some additional explanations and analogies that might help make this click.I found some great analogies! Let me share a few different ways to think about backpropagation:</p>
<hr>
<p><strong>Analogy 1: The â€œTelephone Gameâ€</strong></p>
<p>Think of it like the childrenâ€™s game â€œtelephoneâ€ â€” but in reverse! <a href="https://medium.com/geekculture/deep-learning-part-3-backpropagation-nothing-but-a-game-of-telephone-e0d716f6d362" title="Deep Learning Part 3: Backpropagation; Nothing But a Game of Telephone | by Ali H Khanafer | Geek Culture | Medium">*</a> â€œWeâ€™ll do this by seeing how errors are propagated from one person to another in the game of â€˜telephoneâ€™.â€</p>
<p>In the forward pass, a message (data) travels from person to person. In the backward pass, weâ€™re figuring out: â€œHow much did each person contribute to the final message being wrong?â€</p>
<hr>
<p><strong>Analogy 2: Gates that â€œWantâ€ Things</strong> (from Stanfordâ€™s CS231n)</p>
<p><a href="https://cs231n.github.io/optimization-2/" title="Neural Networks: Backpropagation">*</a> â€œIf we anthropomorphize the circuit as wanting to output a higher value (which can help with intuition), then we can think of the circuit as â€˜wantingâ€™ the output of the add gate to be lower (due to negative sign), and with a force of 4.â€</p>
<p>Each gate â€œreceivesâ€ a signal from downstream saying â€œI want you to be higher/lower by this muchâ€ and then passes that message back to its inputs.</p>
<hr>
<p><strong>Analogy 3: Sensitivity = â€œHow much would a wiggle affect things?â€</strong></p>
<p><a href="https://medium.com/spidernitt/breaking-down-neural-networks-an-intuitive-approach-to-backpropagation-3b2ff958794c" title="Breaking down Neural Networks: An intuitive approach to Backpropagation | by Benedict Florance Arockiaraj | Spider R&amp;D | Medium">*</a> â€œThe derivative of a function on each variable tells us the sensitivity of the function with respect to that variable.â€</p>
<p>If you increase variable x by a tiny amount Îµ, and the output increases by 3Îµ, then the gradient is 3.</p>
<hr>
<p><strong>Which analogy resonates most with you?</strong> Would you like me to walk through your <code>f = e * e</code> example using one of these mental models?</p>
<p>Yeah! Here is what I understand so far. If I just look at the output node, I have to whatever I may change I make on the output node, it gets changed by the same amount. It is like just saying fgrad = 1. Next, because F is made up of D and E. Now, what do I change in E to? Here I loose my chain of thought</p>
</section>
<section id="reply-29" class="level5">
<h5 class="anchored" data-anchor-id="reply-29">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Youâ€™re so close! Let me help you with that next step.</p>
<p>Youâ€™re right: <code>f.grad = 1</code> means â€œf affects itself by 1.â€</p>
<p>Now for <code>e</code>: Youâ€™re asking â€œwhat do I change in <code>e</code> to affect <code>f</code>?â€</p>
<p>Hereâ€™s the key question: <strong>If I wiggle <code>e</code> by a tiny amount, how much does <code>f</code> wiggle?</strong></p>
<p>Look at your expression: <code>f = e * e</code></p>
<p>If <code>e = 4</code> and you increase it to <code>e = 4.001</code>, what happens to <code>f</code>?</p>
<p>Try calculating: whatâ€™s <code>4.001 * 4.001</code> compared to <code>4 * 4</code>? How much did <code>f</code> change when <code>e</code> changed by 0.001?</p>
<p>Okay I understand this.</p>
</section>
<section id="reply-30" class="level5">
<h5 class="anchored" data-anchor-id="reply-30">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! So you found that when <code>e</code> changes by 0.001, <code>f</code> changes by about 0.008, which is <strong>8 times as much</strong>.</p>
<p>Thatâ€™s because <code>f = e * e</code>, so the derivative is <code>2*e = 2*4 = 8</code>.</p>
<p><strong>Now hereâ€™s the key connection:</strong></p>
<ul>
<li><code>f.grad = 1</code> (how much f affects the final output, which is itself)</li>
<li>Local gradient <code>df/de = 8</code> (how much e affects f)</li>
<li>So: <code>e.grad = f.grad * 8 = 1 * 8 = 8</code></li>
</ul>
<p>This means: â€œif I wiggle <code>e</code>, the final output <code>f</code> will wiggle 8 times as much.â€</p>
<p><strong>Does this click now?</strong> We multiply the â€œdownstream gradientâ€ (<code>f.grad</code>) by the â€œlocal gradientâ€ (<code>df/de</code>) to get <code>e.grad</code>.</p>
<p>Okay, this also looks ok. Here is what I missed in understanding. Basically, how did you jump from one to f.grad. That generalization bit</p>
</section>
<section id="reply-31" class="level5">
<h5 class="anchored" data-anchor-id="reply-31">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Ah, thatâ€™s the crucial insight! Let me clarify that jump.</p>
<p><strong>The generalization:</strong></p>
<ul>
<li>Right now, <code>f</code> is our final output, so <code>f.grad = 1</code> (base case)</li>
<li>But imagine <code>f</code> was connected to something else, like <code>g = f + 10</code></li>
<li>Then <code>f.grad</code> would be â€œhow much does <code>f</code> affect <code>g</code>?â€ (which would be 1 from the + operation)</li>
<li>And if <code>g</code> connected to something else, <code>f.grad</code> would accumulate that information too</li>
</ul>
<p><strong>The pattern:</strong></p>
<p>Every nodeâ€™s <code>.grad</code> means: <em>â€œHow much does this node affect the FINAL output?â€</em></p>
<p>So when we compute <code>e.grad</code>, weâ€™re really asking: â€œHow much does <code>e</code> affect the final output (which is <code>f</code>)?â€</p>
<p>Answer: <code>e</code> affects <code>f</code> by a factor of 8 (local gradient), and <code>f</code> affects the final output by 1 (because <code>f.grad = 1</code>), so <code>e.grad = 8 * 1 = 8</code>.</p>
<p><strong>Does this connection make sense now?</strong> The <code>.grad</code> always stores â€œinfluence on the final output,â€ not just the immediate next node.</p>
<p>Okay, grad always shows impact on the final output, assuming derivative is the impact on the next output in the chain Is that correct?</p>
</section>
<section id="reply-32" class="level5">
<h5 class="anchored" data-anchor-id="reply-32">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Almost! Let me clarify the distinction:</p>
<p><strong>Local derivative</strong> = impact on the <em>immediate next node</em> in the chain</p>
<p><strong><code>.grad</code></strong> = impact on the <em>final output</em> (accumulated through the whole chain)</p>
<p>So for <code>d = a * b</code> â†’ <code>e = d + c</code> â†’ <code>f = e * e</code>:</p>
<ul>
<li>The local derivative <code>dd/da = b</code> (how <code>a</code> affects <code>d</code>)</li>
<li>But <code>a.grad</code> = impact of <code>a</code> on <code>f</code> (the final output)</li>
<li>We get <code>a.grad</code> by multiplying all the local derivatives along the chain</li>
</ul>
<p><strong>Does this distinction make sense?</strong> Local derivatives are the building blocks, and <code>.grad</code> is the accumulated result through the whole path.</p>
<p>Yes, this makes sense. How to jump from here to current grad as local derivative into next output grad</p>
</section>
<section id="reply-33" class="level5">
<h5 class="anchored" data-anchor-id="reply-33">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Thatâ€™s the <strong>chain rule formula</strong>:</p>
<pre><code>current_node.grad += next_node.grad * local_derivative</code></pre>
<p><strong>Breaking it down:</strong></p>
<ul>
<li><code>next_node.grad</code> = how much the next node affects the final output</li>
<li><code>local_derivative</code> = how much the current node affects the next node</li>
<li>Multiply them = how much the current node affects the final output</li>
</ul>
<p><strong>Example:</strong> For <code>e = d + c</code>: - <code>d.grad += e.grad * 1</code> (local derivative of + is 1) - If <code>e.grad = 8</code>, then <code>d.grad</code> gets 8 added to it</p>
<p><strong>The <code>+=</code> is important:</strong> If a node is used multiple times (like <code>e</code> in <code>e * e</code>), we accumulate gradients from all paths.</p>
<p>Want to try implementing the <code>_backward</code> function for the <code>*</code> operation now?</p>
<p>I get it now. First thing to remember is how much change in input any of the upper nodes impacts the output. We have proven earlier way to gradient is by multiplying all the local derivatives at each operation on computation graph. We donâ€™t need anything else. Now letâ€™s imagine your graph has 3 subsequent nodes to output. Gradient on 2nd (from output) node is multiplicatioon of 2 derivative up to output node. Gradient from 3rd (from output is multiplication of 3 derivatives upto output node. so grad(n-1) = local_derivative<em>grad(n)â€¦ You can have multiple operators from node n-1 to n.&nbsp;So we expand this further to grad(n-1) += local_derivative</em>grad(n). How am I doing so far? Offer a critical persepective</p>
</section>
<section id="reply-34" class="level5">
<h5 class="anchored" data-anchor-id="reply-34">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Excellent! Youâ€™ve nailed the core concept. Your explanation is solid. Let me offer a small clarification on the <code>+=</code> part:</p>
<p><strong>What you said:</strong> â€œYou can have multiple operators from node n-1 to nâ€</p>
<p><strong>More precisely:</strong> A node can contribute to the final output through <em>multiple paths</em>.</p>
<p>For example: - <code>e</code> is used twice in <code>f = e * e</code> (same operation, but <code>e</code> appears twice) - Or a node might feed into two different operations downstream</p>
<p>In both cases, we <strong>accumulate</strong> (<code>+=</code>) because the total influence is the sum of influences through all paths.</p>
<p><strong>Youâ€™re ready!</strong> Want to try implementing <code>_backward</code> for the <code>*</code> operation now? Start with <code>__mul__</code> and think about: - Whatâ€™s the local derivative with respect to <code>self</code>? - Whatâ€™s the local derivative with respect to <code>other</code>?</p>
<p>Thanks , indeed a node can contribute to final output through multiple paths , influence of which needs to be accumulated clears it finally. Now thinking about multiplication r=2z, z = x<em>y, derivative of dz/dx = y and dz/dy = z. So if output is r. dr/dx = 2y and dr/dy = 2x. So for change in x -is y(local derivative)</em> next_layer_grad(dr/dz( or 2)). In multiplication operation , if self is x. current_node_grad= other.data(local derivative)* next_node_grad. So to answer your question</p>
<p>Derivative of self = other.data Derivative of other = self.data</p>
<p>node_grad+= other.data*next_node_grad (for self)</p>
</section>
<section id="reply-35" class="level5">
<h5 class="anchored" data-anchor-id="reply-35">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Youâ€™ve got it exactly right:</p>
<p>For <code>out = self * other</code>: - <code>self.grad += other.data * out.grad</code> - <code>other.grad += self.data * out.grad</code></p>
<p>Now letâ€™s implement it! Hereâ€™s the pattern:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try implementing this yourself! The key is defining the <code>_backward</code> function inside <code>__mul__</code> so it â€œremembersâ€ <code>self</code>, <code>other</code>, and <code>out</code>.</p>
<div id="83f4b302" class="cell" data-time_run="2025-12-21T04:23:42.993435+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Another thing which is a little hazy is the use of this outward _backward attribute and itâ€™s implementation in each operation . Can you help me understand better?</p>
</section>
<section id="reply-36" class="level5">
<h5 class="anchored" data-anchor-id="reply-36">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great question! Let me clarify why <code>_backward</code> works this way:</p>
<p><strong>Why an attribute (not a method)?</strong></p>
<p>Each <code>Value</code> is created by a <em>different</em> operation â€” some by <code>+</code>, some by <code>*</code>, some are leaf nodes. Each needs its own specific backward logic.</p>
<p><strong>Why define it inside the operation?</strong></p>
<p>The <code>_backward</code> function needs to â€œrememberâ€ three things: - <code>self</code> (first operand) - <code>other</code> (second operand)<br>
- <code>out</code> (the result)</p>
<p>By defining <code>_backward</code> inside <code>__mul__</code>, it creates a <strong>closure</strong> â€” the function captures those variables and remembers them for later.</p>
<p><strong>Example walkthrough:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">3.0</span>)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b  <span class="co"># At this moment, c._backward is created</span></span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>           <span class="co"># It "remembers" a, b, and c (as out)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Later, when we call <code>c._backward()</code>, it still knows about <code>a</code> and <code>b</code>, so it can update <code>a.grad</code> and <code>b.grad</code>.</p>
<p>Does the closure concept make sense? Would you like to trace through a small example to see this in action?</p>
</section>
</section>
<section id="part-2-summary-understanding-derivatives-and-gradients" class="level2">
<h2 class="anchored" data-anchor-id="part-2-summary-understanding-derivatives-and-gradients">Part 2 Summary: Understanding Derivatives and Gradients</h2>
<section id="what-is-a-derivative" class="level3">
<h3 class="anchored" data-anchor-id="what-is-a-derivative">What is a Derivative?</h3>
<ul>
<li><strong>Definition</strong>: Sensitivity or slope - how much output changes when input changes</li>
<li><strong>Numerical approximation</strong>: <code>(f(x+h) - f(x)) / h</code> for small h</li>
<li><strong>Sign interpretation</strong>:
<ul>
<li>Positive = function increasing</li>
<li>Negative = function decreasing</li>
<li>Zero = critical point (min/max/inflection)</li>
</ul></li>
</ul>
</section>
<section id="multiple-inputs-partial-derivatives" class="level3">
<h3 class="anchored" data-anchor-id="multiple-inputs-partial-derivatives">Multiple Inputs (Partial Derivatives)</h3>
<ul>
<li>Each input has its own partial derivative</li>
<li><strong>Example</strong>: For <code>d = a*b + c</code>
<ul>
<li>âˆ‚d/âˆ‚a = b</li>
<li>âˆ‚d/âˆ‚b = a</li>
<li>âˆ‚d/âˆ‚c = 1</li>
</ul></li>
</ul>
</section>
<section id="chain-rule-fundamentals" class="level3">
<h3 class="anchored" data-anchor-id="chain-rule-fundamentals">Chain Rule Fundamentals</h3>
<ul>
<li><strong>Local derivative</strong>: How current node affects immediate next node</li>
<li><strong>Global gradient (<code>.grad</code>)</strong>: Accumulated impact on final output through entire chain</li>
<li><strong>Formula</strong>: <code>current_node.grad += next_node.grad * local_derivative</code></li>
<li><strong>Key insight</strong>: Use <code>+=</code> because nodes used multiple times accumulate gradients from all paths</li>
</ul>
<p>Letâ€™ see the example</p>
<section id="reply-37" class="level5">
<h5 class="anchored" data-anchor-id="reply-37">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Letâ€™s trace through a concrete example step by step:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>c.label <span class="op">=</span> <span class="st">'c'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>At the moment <code>c = a * b</code> is executed:</strong></p>
<ol type="1">
<li>Inside <code>__mul__</code>, the function <code>_backward()</code> is defined</li>
<li>This function â€œcapturesâ€ the variables <code>a</code>, <code>b</code>, and <code>out</code> (which becomes <code>c</code>)</li>
<li><code>c._backward</code> now points to this function</li>
</ol>
<p><strong>Now letâ€™s manually call the backward pass:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>c.grad <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># Base case: output affects itself by 1</span></span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>c._backward()  <span class="co"># This runs the function we stored</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>What happens inside <code>c._backward()</code>?</strong> - It still â€œremembersâ€ <code>a</code>, <code>b</code>, and <code>c</code> from when it was created - Executes: <code>a.grad += b.data * c.grad</code> â†’ <code>a.grad += 3.0 * 1.0 = 3.0</code> - Executes: <code>b.grad += a.data * c.grad</code> â†’ <code>b.grad += 2.0 * 1.0 = 2.0</code></p>
<p>Try running this code and checking <code>a.grad</code> and <code>b.grad</code>! What do you get?</p>
<div id="bd62b8ca" class="cell" data-time_run="2025-12-21T04:23:43.020261+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>c.label <span class="op">=</span> <span class="st">'c'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="fdebb449" class="cell" data-time_run="2025-12-21T04:23:43.046342+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-72-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="1162cf18" class="cell" data-time_run="2025-12-21T04:23:43.087195+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c) <span class="co"># Stores a and b</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Value(data=6.0, grad=0.0, _op='*', _prev={Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a'), Value(data=3.0, grad=0.0, _op='', _prev=set(), label='b')}, label='c')</code></pre>
</div>
</div>
<div id="f2ea901f" class="cell" data-time_run="2025-12-21T04:23:43.126994+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>c.grad <span class="op">=</span> <span class="fl">1.0</span>  <span class="co"># Base case: output affects itself by 1</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-74-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8787a572" class="cell" data-time_run="2025-12-21T04:23:43.164529+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>c._backward()  <span class="co"># This runs the function we stored</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="736af959" class="cell" data-time_run="2025-12-21T04:23:43.191020+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-76-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Okay now I get what Karpathy meant that multiplying operation swaps the gradient</p>
</section>
<section id="reply-38" class="level5">
<h5 class="anchored" data-anchor-id="reply-38">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Exactly! You can see it right there: - <code>a.grad = 3.0</code> (which is <code>b.data</code>) - <code>b.grad = 2.0</code> (which is <code>a.data</code>)</p>
<p>The values swap! Thatâ€™s the beauty of the multiplication derivative.</p>
<p><strong>Now try implementing <code>_backward</code> for <code>__add__</code>:</strong></p>
<p>Remember: for <code>out = self + other</code>, the local derivative with respect to both <code>self</code> and <code>other</code> isâ€¦ what?</p>
<div id="65fd3ba5" class="cell" data-time_run="2025-12-21T04:23:43.228341+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> out.grad</span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> out.grad</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Okay addition with just pass the gradient to prior layer as local gradient is 1</p>
</section>
<section id="reply-39" class="level5">
<h5 class="anchored" data-anchor-id="reply-39">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Exactly! The <code>+</code> node just â€œdistributesâ€ the gradient to both inputs â€” Karpathy calls it a â€œgradient router.â€</p>
<p><strong>Quick test:</strong> Try this chain and manually call <code>_backward</code> in reverse order:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> b</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>c.label <span class="op">=</span> <span class="st">'c'</span></span>
<span id="cb121-5"><a href="#cb121-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-6"><a href="#cb121-6" aria-hidden="true" tabindex="-1"></a>c.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb121-7"><a href="#cb121-7" aria-hidden="true" tabindex="-1"></a>c._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>What do you get for <code>a.grad</code> and <code>b.grad</code>?</p>
<div id="f57b215e" class="cell" data-time_run="2025-12-21T04:23:43.255324+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> a <span class="op">+</span> b</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>c.label <span class="op">=</span> <span class="st">'c'</span></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>c.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a>c._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="8d05c219" class="cell" data-time_run="2025-12-21T04:23:43.282266+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>c</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-79-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>I am thinking I should implement sub , truediv in form of add and multiplication but I donâ€™t want to add extra operations which may complicate autograd. Is my thinking correct or I am worrying for nothing</p>
</section>
<section id="reply-40" class="level5">
<h5 class="anchored" data-anchor-id="reply-40">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Your thinking is correct! This is exactly what Karpathy does in micrograd.</p>
<p><strong>The approach:</strong> - <code>a - b</code> = <code>a + (-b)</code> = <code>a + (b * -1)</code> - <code>a / b</code> = <code>a * (b ** -1)</code></p>
<p>This way you only need <code>_backward</code> for <code>+</code>, <code>*</code>, and <code>**</code> (power), and the chain rule handles the rest automatically!</p>
<p>Want to try implementing <code>__neg__</code> (negation) first? Itâ€™s just multiplying by -1.</p>
<div id="ea3836a8" class="cell" data-time_run="2025-12-21T04:23:56.258529+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__neg__</span>(<span class="va">self</span>): </span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(<span class="va">self</span>, Value): <span class="va">self</span> <span class="op">=</span> Value(<span class="va">self</span>)</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> <span class="op">-</span><span class="dv">1</span><span class="op">*</span><span class="va">self</span></span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="c2e0574d" class="cell" data-time_run="2025-12-21T04:23:57.333953+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-81-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-41" class="level5">
<h5 class="anchored" data-anchor-id="reply-41">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! <code>__neg__</code> works by multiplying by -1, and since you already have <code>_backward</code> for <code>*</code>, the gradients will flow correctly automatically.</p>
<p><strong>Now for subtraction:</strong> Can you implement <code>__sub__</code> using <code>__neg__</code> and <code>__add__</code>?</p>
<p>Hint: <code>a - b</code> = <code>a + (-b)</code></p>
<div id="29a24471" class="cell" data-time_run="2025-12-21T04:39:41.448758+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span>.<span class="fu">__add__</span>(other.<span class="fu">__neg__</span>())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="e272c54f" class="cell" data-time_run="2025-12-21T04:39:42.875972+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-83-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ebb36c79" class="cell" data-time_run="2025-12-21T04:39:44.103613+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-84-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8b1b84a6" class="cell" data-time_run="2025-12-21T04:39:45.280548+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>a<span class="op">-</span>b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-85-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f857f2b7" class="cell" data-time_run="2025-12-21T04:42:15.197012+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other<span class="op">-</span><span class="va">self</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a9b2721b" class="cell" data-time_run="2025-12-21T04:42:20.752720+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> <span class="op">-</span> a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-87-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="811d07bb" class="cell" data-time_run="2025-12-21T04:43:49.378551+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="dv">5</span><span class="op">-</span>a<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-89-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="99584cce" class="cell" data-time_run="2025-12-21T04:43:56.603882+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>t._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="f39eecbd" class="cell" data-time_run="2025-12-21T04:44:00.039980+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-91-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>I think there is a problem here. It is not getting grad =1 at last node on computational graph</p>
</section>
<section id="reply-42" class="level5">
<h5 class="anchored" data-anchor-id="reply-42">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good catch! Youâ€™re right â€” you forgot to set <code>t.grad = 1.0</code> before calling <code>t._backward()</code>.</p>
<p>Try:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>t._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Then check <code>t</code> again. The gradients should now flow back through the graph!</p>
<p>Should I not have a mechanism to check it?</p>
</section>
<section id="reply-43" class="level5">
<h5 class="anchored" data-anchor-id="reply-43">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good thinking! Youâ€™re right â€” weâ€™ll eventually want a <code>backward()</code> method that:</p>
<ol type="1">
<li>Automatically sets <code>self.grad = 1.0</code> (for the output node)</li>
<li>Calls all the <code>_backward()</code> functions in the right order</li>
</ol>
<p>But thereâ€™s a tricky part: <strong>whatâ€™s the â€œright orderâ€?</strong></p>
<p>We need to call <code>_backward()</code> on nodes in reverse topological order (from output backwards through the graph).</p>
<p>Would you like to: - <strong>A)</strong> First practice manually calling <code>_backward()</code> on a longer chain to understand the ordering? - <strong>B)</strong> Jump straight to implementing the automatic <code>backward()</code> method with topological sort?</p>
<div id="503b1847" class="cell" data-time_run="2025-12-21T04:46:36.236972+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="dv">5</span><span class="op">-</span>a<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-92-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e1640b42" class="cell" data-time_run="2025-12-21T04:46:43.311415+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>t._backward()<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-93-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Okay letâ€™s continue with manual _backward implementation for now and finish the rest</p>
</section>
<section id="reply-44" class="level5">
<h5 class="anchored" data-anchor-id="reply-44">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great! Letâ€™s practice with the longer chain we had before:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb138-5"><a href="#cb138-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb138-6"><a href="#cb138-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb138-7"><a href="#cb138-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb138-8"><a href="#cb138-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb138-9"><a href="#cb138-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb138-10"><a href="#cb138-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Your task:</strong> Manually call <code>_backward()</code> in the correct order to fill in all the gradients.</p>
<p><strong>Hint:</strong> Start from <code>f</code> and work backwards. Whatâ€™s the correct sequence of calls?</p>
<p>Try it and let me know what gradients you get for <code>a</code>, <code>b</code>, and <code>c</code>!</p>
<div id="d3bac262" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="e2440143" class="cell" data-time_run="2025-12-21T04:47:56.121937+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-95-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="a2184d6c" class="cell" data-time_run="2025-12-21T04:48:46.354034+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>f.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>f._backward()<span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-96-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Okay doesnâ€™t look right for e which is zero and this is not getting it correctly</p>
</section>
<section id="reply-45" class="level5">
<h5 class="anchored" data-anchor-id="reply-45">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Youâ€™re right to notice somethingâ€™s off! Look at <code>f._backward()</code> â€” it should have updated <code>e.grad</code>, but youâ€™re seeing itâ€™s still 0.</p>
<p><strong>Debug question:</strong> Look at your <code>f</code> output. Can you see what <code>e.data</code> is? Itâ€™s one of the values in <code>_prev</code>.</p>
<p>The issue is that <code>f = e * e</code> means both operands are the same <code>e</code> object. When you call <code>f._backward()</code>, it should update <code>e.grad</code> twice (once for each position).</p>
<p>Try calling <code>e._backward()</code> next and see what happens to <code>d.grad</code> and <code>c.grad</code>. Does the gradient flow continue?</p>
<div id="577982f8" class="cell" data-time_run="2025-12-21T04:50:24.559635+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>e.data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>4.0</code></pre>
</div>
</div>
<div id="997ac479" class="cell" data-time_run="2025-12-21T04:51:15.038240+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Value(data=16.0, grad=1.0, _op='*', _prev={Value(data=4.0, grad=0.0, _op='+', _prev={Value(data=10.0, grad=0.0, _op='', _prev=set(), label='c'), Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a'), Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='b')}, label='d')}, label='e')}, label='f')</code></pre>
</div>
</div>
<div id="a7e90a00" class="cell" data-time_run="2025-12-21T04:53:21.256263+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>e</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-99-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="9435b717" class="cell" data-time_run="2025-12-21T04:53:43.297676+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>e.grad <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>e._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="5df32959" class="cell" data-time_run="2025-12-21T04:53:46.327962+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>e</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-101-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>No it is not flowing back at all . What did I do /</p>
</section>
<section id="reply-46" class="level5">
<h5 class="anchored" data-anchor-id="reply-46">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Look carefully at what you did:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>e.grad <span class="op">=</span> <span class="dv">1</span>  <span class="co"># You manually set this to 1</span></span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>e._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>But <code>e.grad</code> should have been set by <code>f._backward()</code>, not manually by you!</p>
<p><strong>The problem:</strong> When you called <code>f._backward()</code>, it should have updated <code>e.grad</code> from 0 to 8 (because <code>df/de = 2*e = 8</code>).</p>
<p>But looking at your output, <code>e.grad</code> is still 0 after <code>f._backward()</code>. That means the gradient didnâ€™t flow from <code>f</code> to <code>e</code>.</p>
<p><strong>Can you check:</strong> What does <code>f._prev</code> contain? Print it out and see if <code>e</code> is actually in there.</p>
<div id="6fe63d03" class="cell" data-time_run="2025-12-21T04:56:01.274619+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>L(f._prev).<span class="bu">map</span>(<span class="kw">lambda</span> o : o.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#1) ['e']</code></pre>
</div>
</div>
<p>Yes e is there</p>
</section>
<section id="reply-47" class="level5">
<h5 class="anchored" data-anchor-id="reply-47">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good! So <code>e</code> is in <code>f._prev</code>. But <code>e.grad</code> didnâ€™t get updated when you called <code>f._backward()</code>.</p>
<p><strong>Question:</strong> Look at your <code>__mul__</code> implementation. When <code>f = e * e</code>, both <code>self</code> and <code>other</code> point to the <em>same</em> <code>e</code> object.</p>
<p>What happens in your <code>_backward</code> function when you do:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>If <code>self</code> and <code>other</code> are the same object, whatâ€™s the issue?</p>
<div id="6013a4eb" class="cell" data-time_run="2025-12-21T04:57:56.780997+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> Value(<span class="dv">2</span>, label<span class="op">=</span><span class="st">'s'</span>)<span class="op">;</span> s</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-103-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="85e4c4dd" class="cell" data-time_run="2025-12-21T04:58:08.276019+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> s<span class="op">*</span>s<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-104-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="59621dd6" class="cell" data-time_run="2025-12-21T04:58:48.009895+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>t._backward()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="6735058a" class="cell" data-time_run="2025-12-21T04:58:52.220045+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-106-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>ok mult works fine</p>
</section>
<section id="reply-48" class="level5">
<h5 class="anchored" data-anchor-id="reply-48">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great! So <code>s.grad = 4.0</code> which is correct (2 + 2 = 4, accumulated from both uses).</p>
<p><strong>Now back to your <code>f</code> problem:</strong> If <code>t = s*s</code> works fine, why doesnâ€™t <code>f = e*e</code> work?</p>
<p>Let me check your earlier output more carefullyâ€¦</p>
<p>Wait, I see it now! Look at <code>f._prev</code> â€” it only has ONE <code>e</code> in the set, not two! Thatâ€™s because <code>_prev</code> is a <strong>set</strong>, and sets donâ€™t allow duplicates.</p>
<p>So when <code>f = e * e</code>, the set <code>{e, e}</code> becomes just <code>{e}</code>. Thatâ€™s fine for tracking the graph structure, but your <code>_backward</code> needs to handle this correctly.</p>
<p>Actually, your <code>__mul__</code> implementation should still work because <code>self</code> and <code>other</code> both point to <code>e</code>, so the <code>+=</code> should accumulate. Let me thinkâ€¦</p>
<p>Can you try recreating <code>f</code> fresh and calling <code>f._backward()</code> again? Maybe thereâ€™s a stale reference issue.</p>
<div id="ad579e87" class="cell" data-time_run="2025-12-21T05:00:13.817971+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb157-8"><a href="#cb157-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb157-9"><a href="#cb157-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb157-10"><a href="#cb157-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span><span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-107-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6deee2f5" class="cell" data-time_run="2025-12-21T05:00:28.323554+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>f.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>f._backward()<span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-108-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Actually now that I see it e is working correctly. Although itâ€™s not recursively passing all the way down</p>
</section>
<section id="reply-49" class="level5">
<h5 class="anchored" data-anchor-id="reply-49">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Exactly! You can see <code>e.grad = 8.0</code> now, which is correct (2 * e.data * f.grad = 2 * 4 * 1 = 8).</p>
<p><strong>The key insight:</strong> Calling <code>f._backward()</code> only goes ONE step back â€” it updates <code>e.grad</code>, but doesnâ€™t continue further.</p>
<p>You need to manually call the rest:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb159"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>e._backward()  <span class="co"># This should update d.grad and c.grad</span></span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>d._backward()  <span class="co"># This should update a.grad and b.grad</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try calling these in order and check what gradients you get for <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code>!</p>
<div id="80b0fb38" class="cell" data-time_run="2025-12-21T05:02:49.325067+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>e._backward()<span class="op">;</span>f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-109-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f9ef5060" class="cell" data-time_run="2025-12-21T05:03:43.636433+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>d._backward()<span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-110-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="part-3-summary-the-chain-rule-backpropagation" class="level2">
<h2 class="anchored" data-anchor-id="part-3-summary-the-chain-rule-backpropagation">Part 3 Summary: The Chain Rule &amp; Backpropagation</h2>
<p><strong>Key insights:</strong> - <strong>Local derivative</strong>: how current node affects immediate next node - <strong><code>.grad</code></strong>: accumulated impact on final output through entire chain - <strong>Chain rule formula</strong>: <code>current_node.grad += next_node.grad * local_derivative</code> - <strong><code>+=</code> is crucial</strong>: nodes used multiple times accumulate gradients from all paths</p>
<p><strong>Example:</strong> For <code>f = e * e</code> where <code>e = d + c</code>: - Local: df/de = 2<em>e - Chain: e.grad = f.grad </em> (2<em>e) = 1 </em> 8 = 8</p>
<p>ok now I have manually checked everylevel</p>
<section id="reply-50" class="level5">
<h5 class="anchored" data-anchor-id="reply-50">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Youâ€™ve successfully backpropagated through the entire graph manually! Letâ€™s verify the final gradients:</p>
<ul>
<li><code>f.grad = 1.0</code> âœ“</li>
<li><code>e.grad = 8.0</code> âœ“ (2 Ã— e = 2 Ã— 4)</li>
<li><code>d.grad = 8.0</code> âœ“ (passed through +)</li>
<li><code>c.grad = 8.0</code> âœ“ (passed through +)</li>
<li><code>a.grad = -24.0</code> âœ“ (b Ã— d.grad = -3 Ã— 8)</li>
<li><code>b.grad = 16.0</code> âœ“ (a Ã— d.grad = 2 Ã— 8)</li>
</ul>
<p>These match what we calculated analytically earlier!</p>
<p><strong>Now you see the problem:</strong> Manually calling <code>_backward()</code> in the right order is tedious and error-prone.</p>
<p><strong>Next step:</strong> We need to implement an automatic <code>backward()</code> method that: 1. Figures out the correct order (topological sort) 2. Calls all the <code>_backward()</code> functions automatically</p>
<p>Ready to tackle that?</p>
<p>I think I should implement pow operator first and convert div in form of power. Can we go back to it</p>
</section>
<section id="reply-51" class="level5">
<h5 class="anchored" data-anchor-id="reply-51">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good thinking! Yes, letâ€™s implement <code>__pow__</code> first, then we can express division as <code>a / b = a * b**-1</code>.</p>
<p><strong>For <code>out = self ** other</code> (where <code>other</code> is a constant like 2 or -1):</strong></p>
<p>Whatâ€™s the local derivative with respect to <code>self</code>?</p>
<p>Hint: Remember the power rule from calculus: d/dx(x^n) = n * x^(n-1)</p>
<p>Can you try implementing <code>__pow__</code> following the same pattern as <code>__mul__</code>?</p>
<div id="860df440" class="cell" data-time_run="2025-12-21T05:07:55.304511+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(<span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>int</code></pre>
</div>
</div>
<div id="a0eb9a3d" class="cell" data-time_run="2025-12-21T05:21:01.002081+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__pow__</span>(<span class="va">self</span>, other): </span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">type</span>(other) <span class="kw">in</span> (<span class="bu">int</span>, <span class="bu">float</span>)</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">**</span>other, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">"**"</span>)</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (other<span class="op">*</span>(<span class="va">self</span>.data <span class="op">**</span>(other<span class="op">-</span><span class="dv">1</span>)))<span class="op">*</span> out.grad</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="part-4-summary-building-the-value-class" class="level2">
<h2 class="anchored" data-anchor-id="part-4-summary-building-the-value-class">Part 4 Summary: Building the Value Class</h2>
<p><strong>Core components:</strong> - <code>data</code>: the actual number - <code>_prev</code>: set of parent nodes (computation graph) - <code>_op</code>: operation that created this value - <code>grad</code>: gradient (initialized to 0) - <code>_backward</code>: function to propagate gradients</p>
<p><strong>Operations implemented:</strong> - Addition, multiplication, power (primitives with _backward) - Subtraction, division, negation (derived from primitives)</p>
<div id="25269fbb" class="cell" data-time_run="2025-12-21T05:21:04.265585+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> Value(<span class="dv">2</span>, label<span class="op">=</span><span class="st">'s'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="af5162eb" class="cell" data-time_run="2025-12-21T05:21:05.926220+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> s<span class="op">**</span><span class="dv">2</span><span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-114-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="6bdd4979" class="cell" data-time_run="2025-12-21T05:21:07.285173+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>t._backward()<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-115-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0f6fb06d" class="cell" data-time_run="2025-12-21T05:23:55.455440+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> Value(<span class="dv">4</span>, label<span class="op">=</span><span class="st">'s'</span>)<span class="op">;</span> s</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> s<span class="op">**</span><span class="fl">0.5</span><span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-116-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="795dd8b5" class="cell" data-time_run="2025-12-21T05:24:00.163684+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>t._backward()<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-117-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f503d3a7" class="cell" data-time_run="2025-12-21T05:30:18.793750+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span><span class="op">*</span>other.<span class="fu">__pow__</span>(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="780e3c7c" class="cell" data-time_run="2025-12-21T05:32:40.553223+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> Value(<span class="dv">2</span>, label<span class="op">=</span><span class="st">'s'</span>)<span class="op">;</span> s</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-119-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="08b464a3" class="cell" data-time_run="2025-12-21T05:32:41.380562+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> s<span class="op">/</span><span class="dv">2</span><span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-120-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="f3a5bea9" class="cell" data-time_run="2025-12-21T05:32:42.813898+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>t._backward()<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-121-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="a6314574" class="cell" data-time_run="2025-12-21T05:34:55.994393+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other<span class="op">/</span><span class="va">self</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="0c1e72e0" class="cell" data-time_run="2025-12-21T05:35:24.126106+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> Value(<span class="dv">2</span>, label<span class="op">=</span><span class="st">'s'</span>)<span class="op">;</span> s</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-123-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="ffd793c3" class="cell" data-time_run="2025-12-21T05:35:34.968225+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> <span class="dv">2</span><span class="op">/</span>s<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-124-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="81d39513" class="cell" data-time_run="2025-12-21T05:35:55.461522+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>t.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>t._backward()<span class="op">;</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-125-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="part-5-summary-building-the-value-class" class="level2">
<h2 class="anchored" data-anchor-id="part-5-summary-building-the-value-class">Part 5 Summary: Building the Value Class</h2>
<section id="core-components" class="level3">
<h3 class="anchored" data-anchor-id="core-components">Core Components</h3>
<ul>
<li><strong><code>data</code></strong>: The actual numerical value</li>
<li><strong><code>_prev</code></strong>: Set of parent nodes (builds computation graph)</li>
<li><strong><code>_op</code></strong>: Operation that created this value (for visualization)</li>
<li><strong><code>grad</code></strong>: Gradient (initialized to 0, accumulated during backprop)</li>
<li><strong><code>_backward</code></strong>: Function to propagate gradients (closure that remembers operands)</li>
</ul>
</section>
<section id="primitive-operations-with-_backward" class="level3">
<h3 class="anchored" data-anchor-id="primitive-operations-with-_backward">Primitive Operations (with <code>_backward</code>)</h3>
<ol type="1">
<li><strong>Addition (<code>__add__</code>)</strong>: Local derivative = 1 for both operands</li>
<li><strong>Multiplication (<code>__mul__</code>)</strong>: Local derivatives swap - <code>âˆ‚(a*b)/âˆ‚a = b</code>, <code>âˆ‚(a*b)/âˆ‚b = a</code></li>
<li><strong>Power (<code>__pow__</code>)</strong>: Power rule - <code>âˆ‚(x^n)/âˆ‚x = n * x^(n-1)</code></li>
</ol>
</section>
<section id="derived-operations-built-from-primitives" class="level3">
<h3 class="anchored" data-anchor-id="derived-operations-built-from-primitives">Derived Operations (built from primitives)</h3>
<ul>
<li><strong>Negation</strong>: <code>__neg__</code> via <code>* -1</code></li>
<li><strong>Subtraction</strong>: <code>__sub__</code> via <code>+ (negation)</code></li>
<li><strong>Division</strong>: <code>__truediv__</code> via <code>* (power -1)</code></li>
<li>All reverse operations (<code>__radd__</code>, <code>__rmul__</code>, etc.) for commutativity</li>
</ul>
</section>
<section id="key-pattern" class="level3">
<h3 class="anchored" data-anchor-id="key-pattern">Key Pattern</h3>
<p>Each operation creates a closure that â€œremembersâ€ its operands, enabling automatic gradient computation later.</p>
<p>Okay check if I have covered all cases for add, mul and pow</p>
<section id="reply-52" class="level5">
<h5 class="anchored" data-anchor-id="reply-52">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Let me check what you have:</p>
<p><strong>Add (+):</strong> - <code>__add__</code> with <code>_backward</code> âœ“ - <code>__radd__</code> âœ“</p>
<p>**Mul (*):** - <code>__mul__</code> with <code>_backward</code> âœ“ - <code>__rmul__</code> âœ“</p>
<p><strong>Pow (</strong>):** - <code>__pow__</code> with <code>_backward</code> âœ“</p>
<p><strong>Derived operations (using the above):</strong> - <code>__neg__</code> via <code>*</code> âœ“ - <code>__sub__</code> via <code>+</code> and <code>neg</code> âœ“ - <code>__rsub__</code> âœ“ - <code>__truediv__</code> via <code>*</code> and <code>**</code> âœ“ - <code>__rtruediv__</code> âœ“</p>
<p>Looks complete! All the derived operations will automatically get correct gradients because theyâ€™re built on primitives that have <code>_backward</code> implemented.</p>
<p>Ready to implement the automatic <code>backward()</code> method with topological sort?</p>
<p>okay can you collect Value class implementation and all the patch methods in next code cell.Keep class structure and patch_to methods as it is</p>
</section>
<section id="reply-53" class="level5">
<h5 class="anchored" data-anchor-id="reply-53">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb178"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb178-9"><a href="#cb178-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span>
<span id="cb178-10"><a href="#cb178-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-11"><a href="#cb178-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-12"><a href="#cb178-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-13"><a href="#cb178-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb178-14"><a href="#cb178-14" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb178-15"><a href="#cb178-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb178-16"><a href="#cb178-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> out.grad</span>
<span id="cb178-17"><a href="#cb178-17" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> out.grad</span>
<span id="cb178-18"><a href="#cb178-18" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb178-19"><a href="#cb178-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb178-20"><a href="#cb178-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-21"><a href="#cb178-21" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-22"><a href="#cb178-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-23"><a href="#cb178-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb178-24"><a href="#cb178-24" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb178-25"><a href="#cb178-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb178-26"><a href="#cb178-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb178-27"><a href="#cb178-27" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span>
<span id="cb178-28"><a href="#cb178-28" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb178-29"><a href="#cb178-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb178-30"><a href="#cb178-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-31"><a href="#cb178-31" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-32"><a href="#cb178-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__pow__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-33"><a href="#cb178-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">type</span>(other) <span class="kw">in</span> (<span class="bu">int</span>, <span class="bu">float</span>)</span>
<span id="cb178-34"><a href="#cb178-34" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">**</span>other, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">"**"</span>)</span>
<span id="cb178-35"><a href="#cb178-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb178-36"><a href="#cb178-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (other <span class="op">*</span> (<span class="va">self</span>.data <span class="op">**</span> (other<span class="op">-</span><span class="dv">1</span>))) <span class="op">*</span> out.grad</span>
<span id="cb178-37"><a href="#cb178-37" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb178-38"><a href="#cb178-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb178-39"><a href="#cb178-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-40"><a href="#cb178-40" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-41"><a href="#cb178-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__neg__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> <span class="va">self</span></span>
<span id="cb178-42"><a href="#cb178-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-43"><a href="#cb178-43" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-44"><a href="#cb178-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> (<span class="op">-</span>other)</span>
<span id="cb178-45"><a href="#cb178-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-46"><a href="#cb178-46" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-47"><a href="#cb178-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-48"><a href="#cb178-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb178-49"><a href="#cb178-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other<span class="op">**-</span><span class="dv">1</span></span>
<span id="cb178-50"><a href="#cb178-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-51"><a href="#cb178-51" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-52"><a href="#cb178-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> other</span>
<span id="cb178-53"><a href="#cb178-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-54"><a href="#cb178-54" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-55"><a href="#cb178-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other</span>
<span id="cb178-56"><a href="#cb178-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-57"><a href="#cb178-57" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-58"><a href="#cb178-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-59"><a href="#cb178-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb178-60"><a href="#cb178-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">-</span> <span class="va">self</span></span>
<span id="cb178-61"><a href="#cb178-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-62"><a href="#cb178-62" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-63"><a href="#cb178-63" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb178-64"><a href="#cb178-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb178-65"><a href="#cb178-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">/</span> <span class="va">self</span></span>
<span id="cb178-66"><a href="#cb178-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-67"><a href="#cb178-67" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb178-68"><a href="#cb178-68" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>): </span>
<span id="cb178-69"><a href="#cb178-69" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb178-70"><a href="#cb178-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div id="ed3cf863" class="cell" data-time_run="2025-12-21T05:38:52.560018+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb179-9"><a href="#cb179-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span>
<span id="cb179-10"><a href="#cb179-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-11"><a href="#cb179-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-12"><a href="#cb179-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-13"><a href="#cb179-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb179-14"><a href="#cb179-14" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb179-15"><a href="#cb179-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb179-16"><a href="#cb179-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> out.grad</span>
<span id="cb179-17"><a href="#cb179-17" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> out.grad</span>
<span id="cb179-18"><a href="#cb179-18" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb179-19"><a href="#cb179-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb179-20"><a href="#cb179-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-21"><a href="#cb179-21" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-22"><a href="#cb179-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-23"><a href="#cb179-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb179-24"><a href="#cb179-24" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb179-25"><a href="#cb179-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb179-26"><a href="#cb179-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb179-27"><a href="#cb179-27" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span>
<span id="cb179-28"><a href="#cb179-28" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb179-29"><a href="#cb179-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb179-30"><a href="#cb179-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-31"><a href="#cb179-31" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-32"><a href="#cb179-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__pow__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-33"><a href="#cb179-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">type</span>(other) <span class="kw">in</span> (<span class="bu">int</span>, <span class="bu">float</span>)</span>
<span id="cb179-34"><a href="#cb179-34" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">**</span>other, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">"**"</span>)</span>
<span id="cb179-35"><a href="#cb179-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb179-36"><a href="#cb179-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (other <span class="op">*</span> (<span class="va">self</span>.data <span class="op">**</span> (other<span class="op">-</span><span class="dv">1</span>))) <span class="op">*</span> out.grad</span>
<span id="cb179-37"><a href="#cb179-37" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb179-38"><a href="#cb179-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb179-39"><a href="#cb179-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-40"><a href="#cb179-40" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-41"><a href="#cb179-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__neg__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> <span class="va">self</span></span>
<span id="cb179-42"><a href="#cb179-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-43"><a href="#cb179-43" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-44"><a href="#cb179-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> (<span class="op">-</span>other)</span>
<span id="cb179-45"><a href="#cb179-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-46"><a href="#cb179-46" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-47"><a href="#cb179-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-48"><a href="#cb179-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb179-49"><a href="#cb179-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other<span class="op">**-</span><span class="dv">1</span></span>
<span id="cb179-50"><a href="#cb179-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-51"><a href="#cb179-51" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-52"><a href="#cb179-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> other</span>
<span id="cb179-53"><a href="#cb179-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-54"><a href="#cb179-54" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-55"><a href="#cb179-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other</span>
<span id="cb179-56"><a href="#cb179-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-57"><a href="#cb179-57" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-58"><a href="#cb179-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-59"><a href="#cb179-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb179-60"><a href="#cb179-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">-</span> <span class="va">self</span></span>
<span id="cb179-61"><a href="#cb179-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-62"><a href="#cb179-62" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-63"><a href="#cb179-63" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb179-64"><a href="#cb179-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb179-65"><a href="#cb179-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">/</span> <span class="va">self</span></span>
<span id="cb179-66"><a href="#cb179-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-67"><a href="#cb179-67" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb179-68"><a href="#cb179-68" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>): </span>
<span id="cb179-69"><a href="#cb179-69" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb179-70"><a href="#cb179-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Letâ€™s work towards topological sort and backward method. Before we implement it can you provide me some good intuitions about what is topological sort and why do we need it ?</p>
</section>
<section id="reply-54" class="level5">
<h5 class="anchored" data-anchor-id="reply-54">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Great question! Let me explain topological sort intuitively.</p>
<p><strong>What is it?</strong></p>
<p>Topological sort arranges nodes so that every node comes <em>after</em> all the nodes it depends on.</p>
<p><strong>Analogy: Getting dressed</strong></p>
<p>You canâ€™t put on shoes before socks! A valid order might be: 1. Underwear 2. Pants 3. Socks 4. Shoes 5. Shirt</p>
<p>This is a topological order â€” each item comes after its dependencies.</p>
<p><strong>Why do we need it for backpropagation?</strong></p>
<p>When we call <code>_backward()</code> on a node, it needs the <code>.grad</code> of its output to already be filled in.</p>
<p>So for your graph <code>a â†’ d â†’ e â†’ f</code>, we must call <code>_backward()</code> in the order: - <code>f._backward()</code> first (fills in <code>e.grad</code>) - <code>e._backward()</code> next (fills in <code>d.grad</code>, <code>c.grad</code>) - <code>d._backward()</code> last (fills in <code>a.grad</code>, <code>b.grad</code>)</p>
<p>Thatâ€™s <strong>reverse</strong> topological order â€” from output back to inputs.</p>
<p><strong>Does this make sense?</strong> Would you like to try sketching out how you might build a topological ordering of nodes?</p>
<p>Seriously :) , is this example Karpathy choose . Can you use his example</p>
</section>
<section id="reply-55" class="level5">
<h5 class="anchored" data-anchor-id="reply-55">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Ha! Fair point. Let me check what Karpathy usedâ€¦</p>
<p>From the transcript, he references this Wikipedia example for topological sort:</p>
<p><strong>A directed acyclic graph (DAG)</strong> where the nodes are laid out so that â€œall the edges go only from left to right.â€</p>
<p>He says: â€œWe maintain a set of visited nodes and then we are going through starting at some root node which for us is <code>o</code> (the output)â€¦ and starting at <code>o</code> we go through all of its children and we need to lay them out from left to right.â€</p>
<p>His key insight: <strong>â€œThis node that weâ€™re going to call it on like say <code>o</code> is only going to add itself to the topo list after all of the children have been processed.â€</strong></p>
<p>So the algorithm is: 1. Start at output node 2. Recursively visit all children first 3. Only <em>then</em> add yourself to the list</p>
<p>Want to try implementing this? The pattern is a depth-first search (DFS).</p>
<p>Can you help me visualize this ?</p>
</section>
<section id="reply-56" class="level5">
<h5 class="anchored" data-anchor-id="reply-56">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Sure! Letâ€™s visualize with your graph:</p>
<pre><code>a â”€â”€â”
    â”œâ”€â”€(*)--&gt; d â”€â”€â”
b â”€â”€â”˜             â”œâ”€â”€(+)--&gt; e â”€â”€â”
                  â”‚             â”œâ”€â”€(*)--&gt; f
c â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                â”‚
                    e â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<p><strong>Topological sort (forward order):</strong> <code>a, b, c, d, e, f</code></p>
<p>Each node comes <em>after</em> its dependencies.</p>
<p><strong>For backprop, we reverse it:</strong> <code>f, e, d, c, b, a</code></p>
<p>Now when we call <code>_backward()</code> in this order: 1. <code>f._backward()</code> â†’ fills <code>e.grad</code> âœ“ (e.grad was needed? Yes, set to 1 as base) 2. <code>e._backward()</code> â†’ fills <code>d.grad</code>, <code>c.grad</code> âœ“ (e.grad already filled) 3. <code>d._backward()</code> â†’ fills <code>a.grad</code>, <code>b.grad</code> âœ“ (d.grad already filled)</p>
<p><strong>The rule:</strong> Never call <code>_backward()</code> on a node until all nodes that use it have already been processed.</p>
<p>Want to try writing the <code>build_topo()</code> function now?</p>
<p>Can you give me some example of circular cases</p>
</section>
<section id="reply-57" class="level5">
<h5 class="anchored" data-anchor-id="reply-57">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good question! In our computation graphs, <strong>circular cases canâ€™t happen</strong> because weâ€™re building a <strong>DAG (Directed Acyclic Graph)</strong>.</p>
<p>Hereâ€™s why:</p>
<p><strong>How values are created:</strong> - Leaf nodes: <code>a = Value(2.0)</code> â€” no dependencies - Computed nodes: <code>c = a + b</code> â€” depends on nodes created <em>before</em> it</p>
<p><strong>Impossible circular example:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> b <span class="op">+</span> <span class="dv">1</span>  <span class="co"># Can't do this! 'a' already exists</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>You canâ€™t make <code>a</code> depend on <code>b</code> if <code>b</code> already depends on <code>a</code>, because <code>a</code> was created first.</p>
<p><strong>However, you CAN reuse a node multiple times:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb182"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>)</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a <span class="op">+</span> a  <span class="co"># Same node used twice â€” this is fine!</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This creates a graph where <code>a</code> has multiple â€œoutgoingâ€ edges, but no cycles.</p>
<p><strong>Does this clarify it?</strong> Ready to implement <code>build_topo()</code>?</p>
<p>Yes I am ready to implement topological sort. Can you search online show me different variations and help me build it step by step</p>
</section>
<section id="reply-58" class="level5">
<h5 class="anchored" data-anchor-id="reply-58">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Hereâ€™s what I found about topological sort:</p>
<p><strong>Two main approaches:</strong></p>
<ol type="1">
<li><p><a href="https://www.geeksforgeeks.org/dsa/topological-sorting/" title="Topological Sorting - GeeksforGeeks">*</a> <strong>DFS-based:</strong> â€œThe main idea is to perform a Depth First Search (DFS) on the Directed Acyclic Graph (DAG) and, for each vertex, push it onto a stack only after visiting all its adjacent vertices.â€</p></li>
<li><p><a href="https://usaco.guide/gold/toposort" title="Topological Sort Â· USACO Guide">*</a> <strong>BFS-based (Kahnâ€™s Algorithm):</strong> â€œThe BFS version is known as Kahnâ€™s Algorithm.â€</p></li>
</ol>
<p><strong>The DFS approach (what Karpathy uses):</strong></p>
<p><a href="https://iq.opengenus.org/topological-sorting-dfs/" title="Topological Sorting using Depth First Search (DFS)">*</a> <a href="https://iq.opengenus.org/topological-sorting-dfs/" title="Topological Sorting using Depth First Search (DFS)">*</a> â€œStep 1: Create a temporary stack. Step 2: Recursively call topological sorting for all its adjacent vertices, then push it to the stack (when all adjacent vertices are on stack). Note: A vertex is pushed to stack only when all of its adjacent vertices are already in stack.â€</p>
<hr>
<p><strong>For our <code>Value</code> class, the algorithm is:</strong></p>
<ol type="1">
<li>Start at the output node</li>
<li>Keep a <code>visited</code> set (to avoid processing a node twice)</li>
<li>For each node: first visit all children, <em>then</em> add yourself to the list</li>
</ol>
<p><strong>Letâ€™s start simple.</strong> Can you write a function <code>build_topo(v)</code> that: - Takes a <code>Value</code> node <code>v</code> - Returns a list of all nodes in topological order</p>
<p>What would be your first step?</p>
<div id="49f72712" class="cell" data-time_run="2025-12-21T07:29:50.612620+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb183-4"><a href="#cb183-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-5"><a href="#cb183-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb183-6"><a href="#cb183-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb183-7"><a href="#cb183-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb183-8"><a href="#cb183-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb183-9"><a href="#cb183-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb183-10"><a href="#cb183-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span><span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-127-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e8ebfc76" class="cell" data-time_run="2025-12-21T07:35:18.647620+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>{1}</code></pre>
</div>
</div>
<div id="9c42ced4" class="cell" data-time_run="2025-12-21T07:29:59.341671+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(<span class="va">self</span>):</span>
<span id="cb186-3"><a href="#cb186-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span>._prev</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a5d90820" class="cell" data-time_run="2025-12-21T08:23:32.556164+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visited = set()</span></span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> []</span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> ols: ols.insert(<span class="dv">0</span>, node)</span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span> : L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: build_topo(v))</span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span>
<span id="cb187-8"><a href="#cb187-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-9"><a href="#cb187-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-10"><a href="#cb187-10" aria-hidden="true" tabindex="-1"></a>L(build_topo(f)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['c','b','a','d','e','f']</code></pre>
</div>
</div>
<p>How does it look?</p>
</section>
<section id="reply-59" class="level5">
<h5 class="anchored" data-anchor-id="reply-59">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good start! Youâ€™re getting <code>['c','b','a','d','e','f']</code> which is close, but not quite right.</p>
<p><strong>The correct order should be:</strong> <code>['a','b','c','d','e','f']</code> (or some valid topological order where dependencies come before dependents)</p>
<p><strong>Two issues I see:</strong></p>
<ol type="1">
<li>Youâ€™re using <code>insert(0, node)</code> which adds to the <em>front</em> â€” but you want to add nodes <em>after</em> visiting their children</li>
<li>Youâ€™re not using a <code>visited</code> set, so you might process nodes multiple times</li>
</ol>
<p><strong>Hereâ€™s the key insight from DFS topological sort:</strong> - Visit all children first (recursively) - <em>Then</em> add yourself to the list</p>
<p>Try modifying your function to: 1. Add a <code>visited</code> set 2. Check if node is already visited 3. Recursively visit children 4. <em>Then</em> append the node</p>
<p>Want to give it another try?</p>
<p>Even with this order wouldnâ€™t it give same answer. Tell me case where this wouldnâ€™t work</p>
</section>
<section id="reply-60" class="level5">
<h5 class="anchored" data-anchor-id="reply-60">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Good question! Actually, for backprop (reversed), your order <code>['c','b','a','d','e','f']</code> becomes <code>['f','e','d','a','b','c']</code> which works fine here!</p>
<p><strong>But thereâ€™s a subtle issue:</strong> Your code adds the node <em>before</em> visiting children. Consider what happens without the <code>if node not in ols</code> check in a case like <code>f = e * e</code> â€” youâ€™d visit <code>e</code> twice.</p>
<p><strong>More importantly:</strong> Without a proper <code>visited</code> set, in a more complex graph you might recurse into the same subtree multiple times, which is inefficient.</p>
<p><strong>Try this diamond pattern:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb189"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> a <span class="op">*</span> <span class="dv">3</span>  </span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> d <span class="op">+</span> e</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Here <code>a</code> is used by both <code>d</code> and <code>e</code>. Run your <code>build_topo(g)</code> and see what order you get. Does <code>a</code> appear once or could there be issues?</p>
<div id="6a96ef07" class="cell" data-time_run="2025-12-21T08:33:12.983001+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb190"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> <span class="dv">2</span><span class="op">;</span> d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb190-3"><a href="#cb190-3" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> a <span class="op">*</span> <span class="dv">3</span><span class="op">;</span> e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb190-4"><a href="#cb190-4" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> d <span class="op">+</span> e<span class="op">;</span>g.label <span class="op">=</span> <span class="st">'g'</span></span>
<span id="cb190-5"><a href="#cb190-5" aria-hidden="true" tabindex="-1"></a>g</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-131-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="1eeac45f" class="cell" data-time_run="2025-12-21T08:33:17.075938+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> []</span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>L(build_topo(g)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['','d','a','','e','g']</code></pre>
</div>
</div>
<div id="e6ab23e8" class="cell" data-time_run="2025-12-21T10:52:32.437273+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> []</span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb193-3"><a href="#cb193-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span> : L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: build_topo(v))</span>
<span id="cb193-4"><a href="#cb193-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> ols: ols.append(node)</span>
<span id="cb193-5"><a href="#cb193-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="4685beac" class="cell" data-time_run="2025-12-21T10:50:51.570378+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb194"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> []</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>L(build_topo(g)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['','a','e','','d','g']</code></pre>
</div>
</div>
<div id="3da75642" class="cell" data-time_run="2025-12-21T10:52:34.253644+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb196"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb196-3"><a href="#cb196-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb196-4"><a href="#cb196-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-5"><a href="#cb196-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb196-6"><a href="#cb196-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb196-7"><a href="#cb196-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb196-8"><a href="#cb196-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb196-9"><a href="#cb196-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb196-10"><a href="#cb196-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span><span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-135-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8d14e897" class="cell" data-time_run="2025-12-21T10:52:35.068681+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>ols <span class="op">=</span> []</span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>L(build_topo(f)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['b','a','d','c','e','f']</code></pre>
</div>
</div>
<p>How about now?</p>
</section>
<section id="reply-61" class="level5">
<h5 class="anchored" data-anchor-id="reply-61">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Much better! Now youâ€™re getting <code>['b','a','d','c','e','f']</code> which is a valid topological order.</p>
<p><strong>However, thereâ€™s still one issue:</strong> Youâ€™re using a global <code>ols = []</code> list that needs to be reset before each call. Thatâ€™s not ideal.</p>
<p><strong>Better approach:</strong> Make <code>visited</code> and <code>topo</code> local to the function. Hereâ€™s the pattern:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb199"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(root):</span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>    topo <span class="op">=</span> []</span>
<span id="cb199-3"><a href="#cb199-3" aria-hidden="true" tabindex="-1"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb199-4"><a href="#cb199-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb199-5"><a href="#cb199-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb199-6"><a href="#cb199-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">in</span> visited: <span class="cf">return</span></span>
<span id="cb199-7"><a href="#cb199-7" aria-hidden="true" tabindex="-1"></a>        visited.add(node)</span>
<span id="cb199-8"><a href="#cb199-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> child <span class="kw">in</span> node._prev:</span>
<span id="cb199-9"><a href="#cb199-9" aria-hidden="true" tabindex="-1"></a>            dfs(child)</span>
<span id="cb199-10"><a href="#cb199-10" aria-hidden="true" tabindex="-1"></a>        topo.append(node)</span>
<span id="cb199-11"><a href="#cb199-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb199-12"><a href="#cb199-12" aria-hidden="true" tabindex="-1"></a>    dfs(root)</span>
<span id="cb199-13"><a href="#cb199-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> topo</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Can you try implementing this pattern? The key is the nested <code>dfs</code> function that captures <code>topo</code> and <code>visited</code>.</p>
<div id="0e1b7f55" class="cell" data-time_run="2025-12-21T10:57:54.088279+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb200"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>    ols <span class="op">=</span> []</span>
<span id="cb200-3"><a href="#cb200-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb200-4"><a href="#cb200-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span> : L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: dfs(v))</span>
<span id="cb200-5"><a href="#cb200-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> ols: ols.append(node)</span>
<span id="cb200-6"><a href="#cb200-6" aria-hidden="true" tabindex="-1"></a>    dfs(node)</span>
<span id="cb200-7"><a href="#cb200-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="ad4e0abc" class="cell" data-time_run="2025-12-21T10:57:55.492451+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>L(build_topo(f)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['b','a','d','c','e','f']</code></pre>
</div>
</div>
<p>How about now?</p>
</section>
<section id="reply-62" class="level5">
<h5 class="anchored" data-anchor-id="reply-62">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good! Your code works and produces the correct order.</p>
<p><strong>One small improvement:</strong> Youâ€™re checking <code>if node not in ols</code>, but using a <code>visited</code> set would be more efficient (checking set membership is O(1) vs O(n) for a list).</p>
<p>Try adding:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb203"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>visited <span class="op">=</span> <span class="bu">set</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>And then check <code>if node in visited: return</code> at the start of <code>dfs</code>, and add <code>visited.add(node)</code> before appending to <code>ols</code>.</p>
<p>Want to try that refinement?</p>
<div id="60e149ae" class="cell" data-time_run="2025-12-21T11:01:18.011572+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb204"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a>    ols <span class="op">=</span> []</span>
<span id="cb204-3"><a href="#cb204-3" aria-hidden="true" tabindex="-1"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb204-4"><a href="#cb204-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb204-5"><a href="#cb204-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span> : L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: dfs(v))</span>
<span id="cb204-6"><a href="#cb204-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">not</span> <span class="kw">in</span> visited: </span>
<span id="cb204-7"><a href="#cb204-7" aria-hidden="true" tabindex="-1"></a>            visited.add(node)</span>
<span id="cb204-8"><a href="#cb204-8" aria-hidden="true" tabindex="-1"></a>            ols.append(node)</span>
<span id="cb204-9"><a href="#cb204-9" aria-hidden="true" tabindex="-1"></a>    dfs(node)</span>
<span id="cb204-10"><a href="#cb204-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="0add6778" class="cell" data-time_run="2025-12-21T11:01:21.796532+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>L(build_topo(f)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['b','a','d','c','e','f']</code></pre>
</div>
</div>
<p>How about now? I have 2 set of references one in ols and another in visited</p>
</section>
<section id="reply-63" class="level5">
<h5 class="anchored" data-anchor-id="reply-63">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good observation! Youâ€™re right that youâ€™re maintaining two data structures tracking similar information.</p>
<p><strong>Small optimization:</strong> You can check <code>visited</code> <em>first</em> (before recursing), which prevents unnecessary recursive calls:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb207"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dfs(node):</span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> node <span class="kw">in</span> visited: <span class="cf">return</span>  <span class="co"># Early exit</span></span>
<span id="cb207-3"><a href="#cb207-3" aria-hidden="true" tabindex="-1"></a>    visited.add(node)</span>
<span id="cb207-4"><a href="#cb207-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span>: L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: dfs(v))</span>
<span id="cb207-5"><a href="#cb207-5" aria-hidden="true" tabindex="-1"></a>    ols.append(node)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This way, once a node is visited, you never recurse into it again. Try this version â€” does it still produce the correct order?</p>
<div id="46954e0e" class="cell" data-time_run="2025-12-21T11:04:36.369693+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb208"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb208-2"><a href="#cb208-2" aria-hidden="true" tabindex="-1"></a>    ols <span class="op">=</span> []</span>
<span id="cb208-3"><a href="#cb208-3" aria-hidden="true" tabindex="-1"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb208-4"><a href="#cb208-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb208-5"><a href="#cb208-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">in</span> visited: <span class="cf">return</span></span>
<span id="cb208-6"><a href="#cb208-6" aria-hidden="true" tabindex="-1"></a>        visited.add(node)</span>
<span id="cb208-7"><a href="#cb208-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span> : L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: dfs(v))</span>
<span id="cb208-8"><a href="#cb208-8" aria-hidden="true" tabindex="-1"></a>        ols.append(node)</span>
<span id="cb208-9"><a href="#cb208-9" aria-hidden="true" tabindex="-1"></a>    dfs(node)</span>
<span id="cb208-10"><a href="#cb208-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
</section>
<section id="part-6-summary-topological-sort-and-automatic-backpropagation" class="level2">
<h2 class="anchored" data-anchor-id="part-6-summary-topological-sort-and-automatic-backpropagation">Part 6 Summary: Topological Sort and Automatic Backpropagation</h2>
<section id="why-topological-sort" class="level3">
<h3 class="anchored" data-anchor-id="why-topological-sort">Why Topological Sort?</h3>
<ul>
<li><strong>Problem</strong>: Must call <code>_backward()</code> on nodes in correct order</li>
<li><strong>Requirement</strong>: Each node needs its outputâ€™s <code>.grad</code> already filled in</li>
<li><strong>Solution</strong>: Reverse topological order (output â†’ inputs)</li>
</ul>
</section>
<section id="algorithm-dfs-based" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-dfs-based">Algorithm (DFS-based)</h3>
<pre><code>1. Start at output node
2. Mark as visited (avoid reprocessing)
3. Recursively visit all children FIRST
4. THEN add yourself to the list
5. Reverse the list for backprop</code></pre>
</section>
<section id="the-backward-method" class="level3">
<h3 class="anchored" data-anchor-id="the-backward-method">The <code>backward()</code> Method</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb210"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(<span class="va">self</span>):</span>
<span id="cb210-2"><a href="#cb210-2" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">1.0</span>              <span class="co"># Base case: output affects itself by 1</span></span>
<span id="cb210-3"><a href="#cb210-3" aria-hidden="true" tabindex="-1"></a>    nodes <span class="op">=</span> build_topo(<span class="va">self</span>)      <span class="co"># Get topological order</span></span>
<span id="cb210-4"><a href="#cb210-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> node <span class="kw">in</span> <span class="bu">reversed</span>(nodes):  <span class="co"># Process in reverse</span></span>
<span id="cb210-5"><a href="#cb210-5" aria-hidden="true" tabindex="-1"></a>        node._backward()          <span class="co"># Call each node's gradient function</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="key-insight" class="level3">
<h3 class="anchored" data-anchor-id="key-insight">Key Insight</h3>
<p>The ordering ensures gradients flow from output to inputs, with each node receiving gradients from all paths before computing its own contribution.</p>
<div id="2c4546df" class="cell" data-time_run="2025-12-21T11:04:48.710460+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>L(build_topo(f)).<span class="bu">map</span>(<span class="kw">lambda</span> v : v.label)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) ['b','a','d','c','e','f']</code></pre>
</div>
</div>
<section id="reply-64" class="level5">
<h5 class="anchored" data-anchor-id="reply-64">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Your <code>build_topo</code> function works correctly and efficiently now. Youâ€™re getting the proper topological order: <code>['b','a','d','c','e','f']</code>.</p>
<p><strong>Now for the final step:</strong> Implement the <code>backward()</code> method that: 1. Sets <code>self.grad = 1.0</code> 2. Builds the topological order 3. Calls <code>_backward()</code> on each node in <strong>reverse</strong> order</p>
<p>Can you try implementing this as a method on the <code>Value</code> class?</p>
<div id="f5e952d0" class="cell" data-time_run="2025-12-21T11:10:39.573352+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="fl">2.0</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> Value(<span class="op">-</span><span class="fl">3.0</span>, label<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb213-3"><a href="#cb213-3" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">10.0</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb213-4"><a href="#cb213-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb213-5"><a href="#cb213-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> a <span class="op">*</span> b</span>
<span id="cb213-6"><a href="#cb213-6" aria-hidden="true" tabindex="-1"></a>d.label <span class="op">=</span> <span class="st">'d'</span></span>
<span id="cb213-7"><a href="#cb213-7" aria-hidden="true" tabindex="-1"></a>e <span class="op">=</span> d <span class="op">+</span> c</span>
<span id="cb213-8"><a href="#cb213-8" aria-hidden="true" tabindex="-1"></a>e.label <span class="op">=</span> <span class="st">'e'</span></span>
<span id="cb213-9"><a href="#cb213-9" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> e <span class="op">*</span> e</span>
<span id="cb213-10"><a href="#cb213-10" aria-hidden="true" tabindex="-1"></a>f.label <span class="op">=</span> <span class="st">'f'</span><span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-143-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="7e0ce469" class="cell" data-time_run="2025-12-21T11:11:37.525400+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb214"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a>L(<span class="bu">reversed</span>(build_topo(f)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#6) [Value(data=16.0, grad=0.0, _op='*', _prev={Value(data=4.0, grad=0.0, _op='+', _prev={Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='b'), Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a')}, label='d'), Value(data=10.0, grad=0.0, _op='', _prev=set(), label='c')}, label='e')}, label='f'),Value(data=4.0, grad=0.0, _op='+', _prev={Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='b'), Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a')}, label='d'), Value(data=10.0, grad=0.0, _op='', _prev=set(), label='c')}, label='e'),Value(data=10.0, grad=0.0, _op='', _prev=set(), label='c'),Value(data=-6.0, grad=0.0, _op='*', _prev={Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='b'), Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a')}, label='d'),Value(data=2.0, grad=0.0, _op='', _prev=set(), label='a'),Value(data=-3.0, grad=0.0, _op='', _prev=set(), label='b')]</code></pre>
</div>
</div>
<div id="451bd05e" class="cell" data-time_run="2025-12-21T11:12:51.605849+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb216-2"><a href="#cb216-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(<span class="va">self</span>): </span>
<span id="cb216-3"><a href="#cb216-3" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb216-4"><a href="#cb216-4" aria-hidden="true" tabindex="-1"></a>    nodes <span class="op">=</span> build_topo(<span class="va">self</span>)</span>
<span id="cb216-5"><a href="#cb216-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L(<span class="bu">reversed</span>(nodes)).<span class="bu">map</span>(<span class="kw">lambda</span> o: o._backward())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="62a8716d" class="cell" data-time_run="2025-12-21T11:12:54.723081+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a>f.backward()<span class="op">;</span> f</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-146-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What do you think ?</p>
</section>
<section id="reply-65" class="level5">
<h5 class="anchored" data-anchor-id="reply-65">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! Your <code>backward()</code> method works perfectly! Look at the gradients:</p>
<ul>
<li><code>f.grad = 1.0</code> âœ“</li>
<li><code>e.grad = 8.0</code> âœ“</li>
<li><code>d.grad = 8.0</code> âœ“</li>
<li><code>c.grad = 8.0</code> âœ“</li>
<li><code>a.grad = -24.0</code> âœ“</li>
<li><code>b.grad = 16.0</code> âœ“</li>
</ul>
<p>These match exactly what we calculated manually earlier!</p>
<p><strong>ğŸ‰ Congratulations!</strong> Youâ€™ve just built a working autograd engine from scratch. You now have: - Forward pass (building the computation graph) - Backward pass (automatic gradient computation) - All the basic operations with their derivatives</p>
<p>Want to test it with a fresh example to make sure everything works? Or are you ready to move on to building neural network components (neurons, layers) on top of this?</p>
<p>Did Karpathy covered building nn in this lecture or next one? Can you check transcript?</p>
</section>
<section id="reply-66" class="level5">
<h5 class="anchored" data-anchor-id="reply-66">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Let me check the transcriptâ€¦</p>
<p>Yes! Karpathy does cover building neural networks in <strong>this same lecture</strong> (Lesson 1).</p>
<p>Looking at the transcript, after implementing the autograd engine, he builds: 1. A <strong>single neuron</strong> with inputs, weights, and bias 2. A <strong>Layer</strong> of neurons 3. An <strong>MLP (Multi-Layer Perceptron)</strong> - stacking multiple layers</p>
<p>He also shows training the network on a tiny dataset (4 examples) to minimize a loss function.</p>
<p><strong>Would you like to:</strong> - <strong>A)</strong> Continue following this lecture and build the neural network components? - <strong>B)</strong> Take a break here and consolidate what youâ€™ve learned about autograd?</p>
<p>What sounds better to you?</p>
<p>Okay before doing that letâ€™s collect Value class , patch methods and build_repo together</p>
</section>
<section id="reply-67" class="level5">
<h5 class="anchored" data-anchor-id="reply-67">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Hereâ€™s everything collected together:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb218"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Value:</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, data, children<span class="op">=</span>(), op<span class="op">=</span><span class="st">''</span>, label<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'data'</span>, <span class="va">self</span>)</span>
<span id="cb218-4"><a href="#cb218-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._prev <span class="op">=</span> <span class="bu">set</span>(children)</span>
<span id="cb218-5"><a href="#cb218-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._op <span class="op">=</span> op</span>
<span id="cb218-6"><a href="#cb218-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb218-7"><a href="#cb218-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.label <span class="op">=</span> label <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb218-8"><a href="#cb218-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._backward <span class="op">=</span> <span class="kw">lambda</span>: <span class="va">None</span></span>
<span id="cb218-9"><a href="#cb218-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span> <span class="op">=</span> basic_repr(<span class="st">'data, grad, _op, _prev, label'</span>)</span>
<span id="cb218-10"><a href="#cb218-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-11"><a href="#cb218-11" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-12"><a href="#cb218-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__add__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-13"><a href="#cb218-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb218-14"><a href="#cb218-14" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">+</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"+"</span>)</span>
<span id="cb218-15"><a href="#cb218-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb218-16"><a href="#cb218-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> out.grad</span>
<span id="cb218-17"><a href="#cb218-17" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> out.grad</span>
<span id="cb218-18"><a href="#cb218-18" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb218-19"><a href="#cb218-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb218-20"><a href="#cb218-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-21"><a href="#cb218-21" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-22"><a href="#cb218-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__mul__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-23"><a href="#cb218-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb218-24"><a href="#cb218-24" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">*</span>other.data, children<span class="op">=</span>(<span class="va">self</span>, other), op<span class="op">=</span><span class="st">"*"</span>)</span>
<span id="cb218-25"><a href="#cb218-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb218-26"><a href="#cb218-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> other.data <span class="op">*</span> out.grad</span>
<span id="cb218-27"><a href="#cb218-27" aria-hidden="true" tabindex="-1"></a>        other.grad <span class="op">+=</span> <span class="va">self</span>.data <span class="op">*</span> out.grad</span>
<span id="cb218-28"><a href="#cb218-28" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb218-29"><a href="#cb218-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb218-30"><a href="#cb218-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-31"><a href="#cb218-31" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-32"><a href="#cb218-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__pow__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-33"><a href="#cb218-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">type</span>(other) <span class="kw">in</span> (<span class="bu">int</span>, <span class="bu">float</span>)</span>
<span id="cb218-34"><a href="#cb218-34" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(<span class="va">self</span>.data<span class="op">**</span>other, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">"**"</span>)</span>
<span id="cb218-35"><a href="#cb218-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb218-36"><a href="#cb218-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (other <span class="op">*</span> (<span class="va">self</span>.data <span class="op">**</span> (other<span class="op">-</span><span class="dv">1</span>))) <span class="op">*</span> out.grad</span>
<span id="cb218-37"><a href="#cb218-37" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb218-38"><a href="#cb218-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span>
<span id="cb218-39"><a href="#cb218-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-40"><a href="#cb218-40" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-41"><a href="#cb218-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__neg__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> <span class="va">self</span></span>
<span id="cb218-42"><a href="#cb218-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-43"><a href="#cb218-43" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-44"><a href="#cb218-44" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__sub__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> (<span class="op">-</span>other)</span>
<span id="cb218-45"><a href="#cb218-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-46"><a href="#cb218-46" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-47"><a href="#cb218-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__truediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-48"><a href="#cb218-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb218-49"><a href="#cb218-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other<span class="op">**-</span><span class="dv">1</span></span>
<span id="cb218-50"><a href="#cb218-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-51"><a href="#cb218-51" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-52"><a href="#cb218-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__radd__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">+</span> other</span>
<span id="cb218-53"><a href="#cb218-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-54"><a href="#cb218-54" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-55"><a href="#cb218-55" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rmul__</span>(<span class="va">self</span>, other): <span class="cf">return</span> <span class="va">self</span> <span class="op">*</span> other</span>
<span id="cb218-56"><a href="#cb218-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-57"><a href="#cb218-57" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-58"><a href="#cb218-58" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rsub__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-59"><a href="#cb218-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb218-60"><a href="#cb218-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">-</span> <span class="va">self</span></span>
<span id="cb218-61"><a href="#cb218-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-62"><a href="#cb218-62" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-63"><a href="#cb218-63" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__rtruediv__</span>(<span class="va">self</span>, other): </span>
<span id="cb218-64"><a href="#cb218-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(other, Value): other <span class="op">=</span> Value(other)</span>
<span id="cb218-65"><a href="#cb218-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> other <span class="op">/</span> <span class="va">self</span></span>
<span id="cb218-66"><a href="#cb218-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-67"><a href="#cb218-67" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-68"><a href="#cb218-68" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _repr_svg_(<span class="va">self</span>): </span>
<span id="cb218-69"><a href="#cb218-69" aria-hidden="true" tabindex="-1"></a>    svg <span class="op">=</span> draw_dot(<span class="va">self</span>)._repr_image_svg_xml()</span>
<span id="cb218-70"><a href="#cb218-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> svg.decode(<span class="st">'utf-8'</span>) <span class="cf">if</span> <span class="bu">isinstance</span>(svg, <span class="bu">bytes</span>) <span class="cf">else</span> svg</span>
<span id="cb218-71"><a href="#cb218-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-72"><a href="#cb218-72" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_topo(node):</span>
<span id="cb218-73"><a href="#cb218-73" aria-hidden="true" tabindex="-1"></a>    ols <span class="op">=</span> []</span>
<span id="cb218-74"><a href="#cb218-74" aria-hidden="true" tabindex="-1"></a>    visited <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb218-75"><a href="#cb218-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> dfs(node):</span>
<span id="cb218-76"><a href="#cb218-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> node <span class="kw">in</span> visited: <span class="cf">return</span></span>
<span id="cb218-77"><a href="#cb218-77" aria-hidden="true" tabindex="-1"></a>        visited.add(node)</span>
<span id="cb218-78"><a href="#cb218-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(node._prev) <span class="op">&gt;</span> <span class="dv">0</span>: L(node._prev).<span class="bu">map</span>(<span class="kw">lambda</span> v: dfs(v))</span>
<span id="cb218-79"><a href="#cb218-79" aria-hidden="true" tabindex="-1"></a>        ols.append(node)</span>
<span id="cb218-80"><a href="#cb218-80" aria-hidden="true" tabindex="-1"></a>    dfs(node)</span>
<span id="cb218-81"><a href="#cb218-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ols</span>
<span id="cb218-82"><a href="#cb218-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-83"><a href="#cb218-83" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb218-84"><a href="#cb218-84" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> backward(<span class="va">self</span>): </span>
<span id="cb218-85"><a href="#cb218-85" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.grad <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb218-86"><a href="#cb218-86" aria-hidden="true" tabindex="-1"></a>    nodes <span class="op">=</span> build_topo(<span class="va">self</span>)</span>
<span id="cb218-87"><a href="#cb218-87" aria-hidden="true" tabindex="-1"></a>    L(<span class="bu">reversed</span>(nodes)).<span class="bu">map</span>(<span class="kw">lambda</span> o: o._backward())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Ready to continue with building neural network components?</p>
<hr>
</section>
</section>
<section id="value.backward" class="level3">
<h3 class="anchored" data-anchor-id="value.backward">Value.backward</h3>
<blockquote class="blockquote">
<pre><code> Value.backward ()</code></pre>
</blockquote>
<hr>
</section>
<section id="build_topo" class="level3">
<h3 class="anchored" data-anchor-id="build_topo">build_topo</h3>
<blockquote class="blockquote">
<pre><code> build_topo (node)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__rtruediv__" class="level3">
<h3 class="anchored" data-anchor-id="value.__rtruediv__">Value.__rtruediv__</h3>
<blockquote class="blockquote">
<pre><code> Value.__rtruediv__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__rsub__" class="level3">
<h3 class="anchored" data-anchor-id="value.__rsub__">Value.__rsub__</h3>
<blockquote class="blockquote">
<pre><code> Value.__rsub__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__rmul__" class="level3">
<h3 class="anchored" data-anchor-id="value.__rmul__">Value.__rmul__</h3>
<blockquote class="blockquote">
<pre><code> Value.__rmul__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__radd__" class="level3">
<h3 class="anchored" data-anchor-id="value.__radd__">Value.__radd__</h3>
<blockquote class="blockquote">
<pre><code> Value.__radd__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__truediv__" class="level3">
<h3 class="anchored" data-anchor-id="value.__truediv__">Value.__truediv__</h3>
<blockquote class="blockquote">
<pre><code> Value.__truediv__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__sub__" class="level3">
<h3 class="anchored" data-anchor-id="value.__sub__">Value.__sub__</h3>
<blockquote class="blockquote">
<pre><code> Value.__sub__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__neg__" class="level3">
<h3 class="anchored" data-anchor-id="value.__neg__">Value.__neg__</h3>
<blockquote class="blockquote">
<pre><code> Value.__neg__ ()</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__pow__" class="level3">
<h3 class="anchored" data-anchor-id="value.__pow__">Value.__pow__</h3>
<blockquote class="blockquote">
<pre><code> Value.__pow__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__mul__" class="level3">
<h3 class="anchored" data-anchor-id="value.__mul__">Value.__mul__</h3>
<blockquote class="blockquote">
<pre><code> Value.__mul__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value.__add__" class="level3">
<h3 class="anchored" data-anchor-id="value.__add__">Value.__add__</h3>
<blockquote class="blockquote">
<pre><code> Value.__add__ (other)</code></pre>
</blockquote>
<hr>
</section>
<section id="value" class="level3">
<h3 class="anchored" data-anchor-id="value">Value</h3>
<blockquote class="blockquote">
<pre><code> Value (data, children=(), op='', label=None)</code></pre>
</blockquote>
<p><em>Initialize self. See help(type(self)) for accurate signature.</em></p>
</section>
</section>
<section id="part-7-summary-topological-sort-automatic-backward" class="level2">
<h2 class="anchored" data-anchor-id="part-7-summary-topological-sort-automatic-backward">Part 7 Summary: Topological Sort &amp; Automatic Backward</h2>
<p><strong>Why topological sort?</strong> - Must call <code>_backward()</code> on nodes in correct order - Each node needs its outputâ€™s <code>.grad</code> already filled in - Solution: reverse topological order (output â†’ inputs)</p>
<p><strong>Algorithm (DFS-based):</strong> 1. Start at output node 2. Recursively visit all children first 3. Then add yourself to the list 4. Reverse the list for backprop</p>
<p><strong><code>backward()</code> method:</strong> 1. Set <code>self.grad = 1.0</code> (base case) 2. Build topological order 3. Call <code>_backward()</code> on each node in reverse</p>
</section>
<section id="neural-network-implementation" class="level2">
<h2 class="anchored" data-anchor-id="neural-network-implementation">Neural Network Implementation</h2>
<p>Can you review the dialog so far and add notes with heading and subheadings in correct places. You can use &amp;<code>add_msg</code></p>
<section id="reply-68" class="level5">
<h5 class="anchored" data-anchor-id="reply-68">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Iâ€™ll add summary notes at key points in the dialog to help organize what weâ€™ve learned. Let me add them now:</p>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb232"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01Dqv4tLPYykBSD6oAwuPewa"</span><span class="fu">,</span></span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb232-4"><a href="#cb232-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb232-5"><a href="#cb232-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb232-6"><a href="#cb232-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 1: Understanding Derivatives</span><span class="ch">\n\n</span><span class="st">**Key Concepts:**</span><span class="ch">\n</span><span class="st">- Derivative = </span><span class="ch">\"</span><span class="st">sensitivity</span><span class="ch">\"</span><span class="st"> or </span><span class="ch">\"</span><span class="st">slope</span><span class="ch">\"</span><span class="st"> - how much output changes when input changes</span><span class="ch">\n</span><span class="st">- Numerical approximation: `(f(x+h) - f(x)) / h` for small h</span><span class="ch">\n</span><span class="st">- Sign tells direction: positive = increasing, negative = decreasing</span><span class="ch">\n</span><span class="st">- Zero derivative = critical point (min/max/inflection)</span><span class="ch">\n\n</span><span class="st">**Multiple inputs:**</span><span class="ch">\n</span><span class="st">- Each input has its own partial derivative</span><span class="ch">\n</span><span class="st">- For `d = a*b + c`: </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">a = b, </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">b = a, </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">c = 1"</span><span class="fu">,</span></span>
<span id="cb232-7"><a href="#cb232-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb232-8"><a href="#cb232-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb232-9"><a href="#cb232-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_c401c1cb"</span></span>
<span id="cb232-10"><a href="#cb232-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb232-11"><a href="#cb232-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb232-12"><a href="#cb232-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_a1bb1c58'"</span></span>
<span id="cb232-13"><a href="#cb232-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb233"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01DhNAKVP8kF5Uuqmb2WNbio"</span><span class="fu">,</span></span>
<span id="cb233-3"><a href="#cb233-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb233-4"><a href="#cb233-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb233-5"><a href="#cb233-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb233-6"><a href="#cb233-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 2: Building the Value Class</span><span class="ch">\n\n</span><span class="st">**Core components:**</span><span class="ch">\n</span><span class="st">- `data`: the actual number</span><span class="ch">\n</span><span class="st">- `_prev`: set of parent nodes (computation graph)</span><span class="ch">\n</span><span class="st">- `_op`: operation that created this value</span><span class="ch">\n</span><span class="st">- `grad`: gradient (initialized to 0)</span><span class="ch">\n</span><span class="st">- `_backward`: function to propagate gradients</span><span class="ch">\n\n</span><span class="st">**Operations implemented:**</span><span class="ch">\n</span><span class="st">- Addition, multiplication, power (primitives with _backward)</span><span class="ch">\n</span><span class="st">- Subtraction, division, negation (derived from primitives)"</span><span class="fu">,</span></span>
<span id="cb233-7"><a href="#cb233-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb233-8"><a href="#cb233-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb233-9"><a href="#cb233-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_a0eb9a3d"</span></span>
<span id="cb233-10"><a href="#cb233-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb233-11"><a href="#cb233-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb233-12"><a href="#cb233-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_fd0fca49'"</span></span>
<span id="cb233-13"><a href="#cb233-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb234"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb234-1"><a href="#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb234-2"><a href="#cb234-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01JS2B4GvizMBkVLe6rDyPt8"</span><span class="fu">,</span></span>
<span id="cb234-3"><a href="#cb234-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb234-4"><a href="#cb234-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb234-5"><a href="#cb234-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb234-6"><a href="#cb234-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 3: The Chain Rule &amp; Backpropagation</span><span class="ch">\n\n</span><span class="st">**Key insights:**</span><span class="ch">\n</span><span class="st">- **Local derivative**: how current node affects immediate next node</span><span class="ch">\n</span><span class="st">- **`.grad`**: accumulated impact on final output through entire chain</span><span class="ch">\n</span><span class="st">- **Chain rule formula**: `current_node.grad += next_node.grad * local_derivative`</span><span class="ch">\n</span><span class="st">- **`+=` is crucial**: nodes used multiple times accumulate gradients from all paths</span><span class="ch">\n\n</span><span class="st">**Example:** For `f = e * e` where `e = d + c`:</span><span class="ch">\n</span><span class="st">- Local: df/de = 2*e</span><span class="ch">\n</span><span class="st">- Chain: e.grad = f.grad * (2*e) = 1 * 8 = 8"</span><span class="fu">,</span></span>
<span id="cb234-7"><a href="#cb234-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb234-8"><a href="#cb234-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb234-9"><a href="#cb234-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_f9ef5060"</span></span>
<span id="cb234-10"><a href="#cb234-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb234-11"><a href="#cb234-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb234-12"><a href="#cb234-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_27fe5a9c'"</span></span>
<span id="cb234-13"><a href="#cb234-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb235"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01DHt7ZbaqbeUsDUwqMSared"</span><span class="fu">,</span></span>
<span id="cb235-3"><a href="#cb235-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb235-4"><a href="#cb235-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb235-5"><a href="#cb235-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb235-6"><a href="#cb235-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 4: Topological Sort &amp; Automatic Backward</span><span class="ch">\n\n</span><span class="st">**Why topological sort?**</span><span class="ch">\n</span><span class="st">- Must call `_backward()` on nodes in correct order</span><span class="ch">\n</span><span class="st">- Each node needs its output's `.grad` already filled in</span><span class="ch">\n</span><span class="st">- Solution: reverse topological order (output </span><span class="ch">\u2192</span><span class="st"> inputs)</span><span class="ch">\n\n</span><span class="st">**Algorithm (DFS-based):**</span><span class="ch">\n</span><span class="st">1. Start at output node</span><span class="ch">\n</span><span class="st">2. Recursively visit all children first</span><span class="ch">\n</span><span class="st">3. Then add yourself to the list</span><span class="ch">\n</span><span class="st">4. Reverse the list for backprop</span><span class="ch">\n\n</span><span class="st">**`backward()` method:**</span><span class="ch">\n</span><span class="st">1. Set `self.grad = 1.0` (base case)</span><span class="ch">\n</span><span class="st">2. Build topological order</span><span class="ch">\n</span><span class="st">3. Call `_backward()` on each node in reverse"</span><span class="fu">,</span></span>
<span id="cb235-7"><a href="#cb235-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb235-8"><a href="#cb235-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb235-9"><a href="#cb235-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_4acc85ae"</span></span>
<span id="cb235-10"><a href="#cb235-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb235-11"><a href="#cb235-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb235-12"><a href="#cb235-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_628a6872'"</span></span>
<span id="cb235-13"><a href="#cb235-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<p>Done! Iâ€™ve added summary notes at four key points in the dialog:</p>
<ol type="1">
<li>After understanding derivatives (Part 1)</li>
<li>After building the Value class (Part 2)</li>
<li>After understanding chain rule (Part 3)</li>
<li>After implementing topological sort (Part 4)</li>
</ol>
<p>These notes capture the main concepts and will help you review the material later. Ready to continue with building neural network components?</p>
<p>Okay letâ€™s start with neural network implementation similar to Karpathyâ€™s video</p>
</section>
<section id="reply-69" class="level5">
<h5 class="anchored" data-anchor-id="reply-69">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Letâ€™s start building a neuron, just like Karpathy does in the video.</p>
<p><strong>First, letâ€™s understand what a neuron does:</strong></p>
<p>A neuron takes multiple inputs (xâ‚, xâ‚‚, â€¦, xâ‚™) and computes:</p>
<pre><code>output = activation(wâ‚*xâ‚ + wâ‚‚*xâ‚‚ + ... + wâ‚™*xâ‚™ + b)</code></pre>
<p>Where: - <code>w</code> are weights (one per input) - <code>b</code> is a bias - <code>activation</code> is a non-linearity (weâ€™ll use tanh)</p>
<p><strong>Your first task:</strong></p>
<p>Can you create a <code>Neuron</code> class with an <code>__init__</code> method that: 1. Takes <code>nin</code> (number of inputs) as a parameter 2. Initializes random weights (one per input) as <code>Value</code> objects 3. Initializes a random bias as a <code>Value</code> object</p>
<p>Hint: Use <code>random.uniform(-1, 1)</code> for random initialization.</p>
<p>Give it a try!</p>
<div id="c18e0493" class="cell" data-time_run="2025-12-21T11:46:38.398899+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a>random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>0.19147626594921818</code></pre>
</div>
</div>
<div id="301b9b12" class="cell" data-time_run="2025-12-21T11:51:13.464943+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>nin<span class="op">=</span><span class="dv">10</span></span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a>ws <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"w</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>))</span>
<span id="cb239-3"><a href="#cb239-3" aria-hidden="true" tabindex="-1"></a>ws.<span class="bu">map</span>(<span class="kw">lambda</span> w: (w.label, w.data))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#10) [('w1', -0.948486074338641),('w2', -0.008456067812933954),('w3', 0.5628304200951046),('w4', -0.6129228608190591),('w5', -0.7202196525510294),('w6', 0.07249587854974138),('w7', -0.3880710320115148),('w8', -0.08875205626399096),('w9', 0.3373102763761886),('w10', -0.6840625809996499)]</code></pre>
</div>
</div>
<div id="ad5dbeda" class="cell" data-time_run="2025-12-21T11:52:43.164999+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Neuron:</span>
<span id="cb241-2"><a href="#cb241-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin):</span>
<span id="cb241-3"><a href="#cb241-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nin <span class="op">=</span> nin </span>
<span id="cb241-4"><a href="#cb241-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ws <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"w</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>))</span>
<span id="cb241-5"><a href="#cb241-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"b"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="eb15fff0" class="cell" data-time_run="2025-12-21T11:54:24.627310+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb242"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb242-1"><a href="#cb242-1" aria-hidden="true" tabindex="-1"></a>neuron <span class="op">=</span> Neuron(<span class="dv">4</span>)</span>
<span id="cb242-2"><a href="#cb242-2" aria-hidden="true" tabindex="-1"></a>neuron.b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-163-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="0fbfc054" class="cell" data-time_run="2025-12-21T11:54:51.163982+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>display(<span class="op">*</span>neuron.ws)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-164-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-164-output-2.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-164-output-3.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-164-output-4.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-70" class="level5">
<h5 class="anchored" data-anchor-id="reply-70">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! Your <code>Neuron</code> class looks great. Youâ€™ve successfully initialized the weights and bias as <code>Value</code> objects with random values.</p>
<p><strong>Next step:</strong> Implement the <code>__call__</code> method so the neuron can process inputs.</p>
<p>The neuron should: 1. Take a list of inputs <code>x</code> (same length as <code>nin</code>) 2. Compute <code>wâ‚*xâ‚ + wâ‚‚*xâ‚‚ + ... + wâ‚™*xâ‚™ + b</code> 3. Apply <code>tanh</code> activation</p>
<p><strong>Question:</strong> How would you compute the weighted sum? Think about using <code>zip</code> to pair up weights with inputs, then multiply and sum them.</p>
<p>Want to try implementing <code>__call__</code>?</p>
<div id="41f0f28d" class="cell" data-time_run="2025-12-21T12:01:08.289979+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb244"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>nin <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb244-2"><a href="#cb244-2" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> x: random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))<span class="op">;</span> xs</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#4) [-0.8871912590486137,-0.18112079481837196,0.6420082272720671,0.9095894053794102]</code></pre>
</div>
</div>
<div id="8c75d2b5" class="cell" data-time_run="2025-12-21T12:01:10.881394+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb246"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a>neuron <span class="op">=</span> Neuron(nin)<span class="op">;</span> neuron</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>&lt;__main__.Neuron at 0x74fc3ecf28a0&gt;</code></pre>
</div>
</div>
<div id="45786db1" class="cell" data-time_run="2025-12-21T12:10:48.361644+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>sm <span class="op">=</span> <span class="bu">sum</span>(x<span class="op">*</span>w <span class="cf">for</span> x, w <span class="kw">in</span> <span class="bu">zip</span>(xs, neuron.ws)) <span class="op">+</span> neuron.b<span class="op">;</span> sm</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-167-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>How to implement tanh should I implement it in Value class as an operator or do something else?</p>
</section>
<section id="reply-71" class="level5">
<h5 class="anchored" data-anchor-id="reply-71">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good question! You have two options:</p>
<p><strong>Option 1:</strong> Implement <code>tanh()</code> as a method on <code>Value</code> (like <code>__add__</code>, <code>__mul__</code>) - Pros: Clean, follows the pattern - Cons: Need to implement the backward pass for tanh</p>
<p><strong>Option 2:</strong> Use the mathematical definition: <code>tanh(x) = (e^(2x) - 1) / (e^(2x) + 1)</code> - Pros: Automatically gets correct gradients (chain rule through existing ops) - Cons: Creates a longer computation graph</p>
<p><strong>Option 3:</strong> Use Pythonâ€™s <code>math.tanh()</code> for the forward pass, but implement <code>_backward</code> for it - Pros: Simple forward, efficient - Cons: Still need to know the derivative of tanh</p>
<p>Karpathy implements it as a method (Option 3). The derivative of tanh is: <code>d(tanh(x))/dx = 1 - tanhÂ²(x)</code></p>
<p>Which approach would you like to try?</p>
<div id="89a6f156" class="cell" data-time_run="2025-12-21T12:11:50.555718+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="bd65734b" class="cell" data-time_run="2025-12-21T12:12:00.281157+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb250"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a>math.tanh(sm.data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>0.16829535554321645</code></pre>
</div>
</div>
<p>Value class implementation is clear to me. However I am not clear on backward pass. Was it manually calculating grad and assigning it to sm ?</p>
</section>
<section id="reply-72" class="level5">
<h5 class="anchored" data-anchor-id="reply-72">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good question! No, we wonâ€™t manually calculate the gradient for <code>sm</code>.</p>
<p>Hereâ€™s what happens:</p>
<p><strong>For <code>tanh</code>:</strong> - Forward: <code>output = tanh(sm)</code> - Backward: When we call <code>output.backward()</code>, it needs to fill in <code>sm.grad</code></p>
<p>The derivative rule is: if <code>output = tanh(sm)</code>, then <code>sm.grad += (1 - output.dataÂ²) * output.grad</code></p>
<p><strong>So we need to implement <code>tanh</code> as a method on <code>Value</code> with its <code>_backward</code> function:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb252"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb252-2"><a href="#cb252-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh(<span class="va">self</span>):</span>
<span id="cb252-3"><a href="#cb252-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> math.tanh(<span class="va">self</span>.data)</span>
<span id="cb252-4"><a href="#cb252-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(t, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">'tanh'</span>)</span>
<span id="cb252-5"><a href="#cb252-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb252-6"><a href="#cb252-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb252-7"><a href="#cb252-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (<span class="dv">1</span> <span class="op">-</span> t<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> out.grad</span>
<span id="cb252-8"><a href="#cb252-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb252-9"><a href="#cb252-9" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb252-10"><a href="#cb252-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Does this pattern make sense? Itâ€™s just like <code>__mul__</code> and <code>__add__</code>, but for the tanh operation.</p>
<p>Want to try implementing it?</p>
<div id="6b1f9b4c" class="cell" data-time_run="2025-12-21T12:14:24.719175+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb253-2"><a href="#cb253-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tanh(<span class="va">self</span>):</span>
<span id="cb253-3"><a href="#cb253-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> math.tanh(<span class="va">self</span>.data)</span>
<span id="cb253-4"><a href="#cb253-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(t, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">'tanh'</span>)</span>
<span id="cb253-5"><a href="#cb253-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb253-6"><a href="#cb253-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb253-7"><a href="#cb253-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (<span class="dv">1</span> <span class="op">-</span> t<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> out.grad</span>
<span id="cb253-8"><a href="#cb253-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb253-9"><a href="#cb253-9" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb253-10"><a href="#cb253-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Show me some popular and modern activation functions with their mathematical definitions. I will implement them myself</p>
</section>
<section id="reply-73" class="level5">
<h5 class="anchored" data-anchor-id="reply-73">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great! Here are some popular activation functions:</p>
<p><strong>1. ReLU (Rectified Linear Unit)</strong> - Formula: <code>f(x) = max(0, x)</code> - Derivative: <code>f'(x) = 1 if x &gt; 0, else 0</code></p>
<p><strong>2. Leaky ReLU</strong> - Formula: <code>f(x) = x if x &gt; 0, else Î±*x</code> (Î± typically 0.01) - Derivative: <code>f'(x) = 1 if x &gt; 0, else Î±</code></p>
<p><strong>3. Sigmoid</strong> - Formula: <code>f(x) = 1 / (1 + e^(-x))</code> - Derivative: <code>f'(x) = f(x) * (1 - f(x))</code></p>
<p><strong>4. Tanh</strong> (already done!) - Formula: <code>f(x) = (e^(2x) - 1) / (e^(2x) + 1)</code> - Derivative: <code>f'(x) = 1 - f(x)Â²</code></p>
<p><strong>5. GELU (Gaussian Error Linear Unit)</strong> - used in modern transformers - Formula: <code>f(x) = 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))</code> - Derivative: (complex, but can be computed)</p>
<p>Which ones would you like to implement first?</p>
<p>I will just implement them in same order</p>
</section>
<section id="reply-74" class="level5">
<h5 class="anchored" data-anchor-id="reply-74">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Letâ€™s start with <strong>ReLU</strong> since itâ€™s the simplest.</p>
<p><strong>ReLU (Rectified Linear Unit):</strong> - Forward: <code>f(x) = max(0, x)</code> â€” just returns x if positive, else 0 - Backward: <code>f'(x) = 1 if x &gt; 0, else 0</code> â€” gradient flows through only if input was positive</p>
<p>Try implementing it following the same pattern as <code>tanh</code>. The key difference is youâ€™ll use an <code>if</code> statement instead of <code>math.tanh()</code>.</p>
<p>Give it a shot!</p>
<div id="060af833" class="cell" data-time_run="2025-12-21T12:20:41.792935+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb254"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb254-1"><a href="#cb254-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb254-2"><a href="#cb254-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relu(<span class="va">self</span>):</span>
<span id="cb254-3"><a href="#cb254-3" aria-hidden="true" tabindex="-1"></a>    t  <span class="op">=</span> <span class="bu">max</span>(<span class="dv">0</span>, <span class="va">self</span>.data)</span>
<span id="cb254-4"><a href="#cb254-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(t, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb254-5"><a href="#cb254-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb254-6"><a href="#cb254-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb254-7"><a href="#cb254-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="va">self</span>.data <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>)<span class="op">*</span>out.grad</span>
<span id="cb254-8"><a href="#cb254-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb254-9"><a href="#cb254-9" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb254-10"><a href="#cb254-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="0308a2d4" class="cell" data-time_run="2025-12-21T12:21:09.899365+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb255"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="dv">3</span>, label<span class="op">=</span><span class="st">'a'</span>)<span class="op">;</span> a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-172-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="41a4b2f7" class="cell" data-time_run="2025-12-21T12:21:16.003324+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb256"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>a.relu()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-173-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="4b59f8a1" class="cell" data-time_run="2025-12-21T12:21:57.600670+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a>a.relu().backward()<span class="op">;</span> a</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-174-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Is this correct?</p>
</section>
<section id="reply-75" class="level5">
<h5 class="anchored" data-anchor-id="reply-75">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Almost! Thereâ€™s a small issue. Look at <code>a.grad = 2.0</code> â€” but you only called <code>backward()</code> once, so it should be <code>1.0</code>.</p>
<p><strong>The problem:</strong> You called <code>a.relu().backward()</code> twice (once in the previous cell), and gradients accumulated!</p>
<p>Try this fresh test:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb258"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb258-1"><a href="#cb258-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="dv">3</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb258-2"><a href="#cb258-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.relu()</span>
<span id="cb258-3"><a href="#cb258-3" aria-hidden="true" tabindex="-1"></a>b.backward()</span>
<span id="cb258-4"><a href="#cb258-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad)  <span class="co"># Should be 1.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Also test with a negative value:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb259"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="op">-</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb259-2"><a href="#cb259-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.relu()</span>
<span id="cb259-3"><a href="#cb259-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb259-4"><a href="#cb259-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try both and let me know what you get!</p>
<div id="afd24ebf" class="cell" data-time_run="2025-12-21T12:23:22.547132+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb260"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb260-1"><a href="#cb260-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="dv">3</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb260-2"><a href="#cb260-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.relu()</span>
<span id="cb260-3"><a href="#cb260-3" aria-hidden="true" tabindex="-1"></a>b.backward()</span>
<span id="cb260-4"><a href="#cb260-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad)  <span class="co"># Should be 1.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0</code></pre>
</div>
</div>
<div id="307a9a2f" class="cell" data-time_run="2025-12-21T12:23:34.386850+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb262"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb262-1"><a href="#cb262-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="op">-</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb262-2"><a href="#cb262-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.relu()</span>
<span id="cb262-3"><a href="#cb262-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb262-4"><a href="#cb262-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0</code></pre>
</div>
</div>
<p>Now?</p>
</section>
<section id="reply-76" class="level5">
<h5 class="anchored" data-anchor-id="reply-76">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! âœ“ ReLU is working correctly.</p>
<p><strong>Next up: Leaky ReLU</strong></p>
<p>This is almost identical to ReLU, but instead of returning 0 for negative values, it returns <code>Î±*x</code> (where Î± is typically 0.01).</p>
<ul>
<li>Forward: <code>f(x) = x if x &gt; 0, else Î±*x</code></li>
<li>Backward: <code>f'(x) = 1 if x &gt; 0, else Î±</code></li>
</ul>
<p>Can you implement <code>leaky_relu</code> with Î±=0.01 as the default?</p>
<div id="def8479b" class="cell" data-time_run="2025-12-21T12:48:38.089095+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb264"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb264-1"><a href="#cb264-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb264-2"><a href="#cb264-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> leaky_relu(<span class="va">self</span>, alpha<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb264-3"><a href="#cb264-3" aria-hidden="true" tabindex="-1"></a>    t  <span class="op">=</span> <span class="va">self</span>.data <span class="cf">if</span> <span class="va">self</span>.data <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> alpha<span class="op">*</span><span class="va">self</span>.data</span>
<span id="cb264-4"><a href="#cb264-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(t, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">'leaky_relu'</span>)</span>
<span id="cb264-5"><a href="#cb264-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb264-6"><a href="#cb264-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb264-7"><a href="#cb264-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> (<span class="dv">1</span> <span class="cf">if</span> <span class="va">self</span>.data <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> alpha)<span class="op">*</span>out.grad</span>
<span id="cb264-8"><a href="#cb264-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb264-9"><a href="#cb264-9" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb264-10"><a href="#cb264-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="66b0ef5a" class="cell" data-time_run="2025-12-21T12:48:54.442496+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb265"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> Value(<span class="dv">3</span>, label<span class="op">=</span><span class="st">'a'</span>)</span>
<span id="cb265-2"><a href="#cb265-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.leaky_relu()</span>
<span id="cb265-3"><a href="#cb265-3" aria-hidden="true" tabindex="-1"></a>b.backward()</span>
<span id="cb265-4"><a href="#cb265-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.grad)  <span class="co"># Should be 1.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0</code></pre>
</div>
</div>
<div id="0912fce4" class="cell" data-time_run="2025-12-21T12:49:09.605249+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb267"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="op">-</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb267-2"><a href="#cb267-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.leaky_relu()</span>
<span id="cb267-3"><a href="#cb267-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb267-4"><a href="#cb267-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.01</code></pre>
</div>
</div>
<div id="f5b4ea80" class="cell" data-time_run="2025-12-21T12:49:31.849139+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb269"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="op">-</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb269-2"><a href="#cb269-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.leaky_relu(<span class="fl">0.02</span>)</span>
<span id="cb269-3"><a href="#cb269-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb269-4"><a href="#cb269-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)  <span class="co"># Should be 0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.02</code></pre>
</div>
</div>
</section>
<section id="reply-77" class="level5">
<h5 class="anchored" data-anchor-id="reply-77">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! âœ“ Leaky ReLU is working perfectly. The gradient is 0.01 for negative inputs and 1.0 for positive inputs.</p>
<p><strong>Next: Sigmoid</strong></p>
<p>This oneâ€™s a bit more interesting: - Forward: <code>f(x) = 1 / (1 + e^(-x))</code> - Backward: <code>f'(x) = f(x) * (1 - f(x))</code></p>
<p>Notice the backward pass uses the <em>output</em> value, not the input â€” just like tanh!</p>
<p>Hint: Use <code>math.exp()</code> for e^x.</p>
<p>Give it a try!</p>
<div id="8e36ca19" class="cell" data-time_run="2025-12-21T13:07:03.040860+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb271"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb271-1"><a href="#cb271-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb271-2"><a href="#cb271-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(<span class="va">self</span>, alpha<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb271-3"><a href="#cb271-3" aria-hidden="true" tabindex="-1"></a>    t  <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>math.exp(<span class="op">-</span><span class="va">self</span>.data))</span>
<span id="cb271-4"><a href="#cb271-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> Value(t, children<span class="op">=</span>(<span class="va">self</span>,), op<span class="op">=</span><span class="st">'sigmoid'</span>)</span>
<span id="cb271-5"><a href="#cb271-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb271-6"><a href="#cb271-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _backward():</span>
<span id="cb271-7"><a href="#cb271-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.grad <span class="op">+=</span> t<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>t)<span class="op">*</span>out.grad</span>
<span id="cb271-8"><a href="#cb271-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb271-9"><a href="#cb271-9" aria-hidden="true" tabindex="-1"></a>    out._backward <span class="op">=</span> _backward</span>
<span id="cb271-10"><a href="#cb271-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="c4ba10c0" class="cell" data-time_run="2025-12-21T13:07:24.572404+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="dv">100</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb272-2"><a href="#cb272-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.sigmoid()</span>
<span id="cb272-3"><a href="#cb272-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb272-4"><a href="#cb272-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0</code></pre>
</div>
</div>
<div id="b8c1e6b0" class="cell" data-time_run="2025-12-21T13:07:45.346347+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb274"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>math.exp(<span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>0.36787944117144233</code></pre>
</div>
</div>
<div id="cea6d9c2" class="cell" data-time_run="2025-12-21T13:10:04.900417+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb276"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a>d</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-184-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="84e5872a" class="cell" data-time_run="2025-12-21T13:10:42.688841+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb277"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">0.4</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb277-2"><a href="#cb277-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.sigmoid()</span>
<span id="cb277-3"><a href="#cb277-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb277-4"><a href="#cb277-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.24026074574152914</code></pre>
</div>
</div>
<div id="78635795" class="cell" data-time_run="2025-12-21T13:18:47.439086+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb279"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a>d</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-186-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-78" class="level5">
<h5 class="anchored" data-anchor-id="reply-78">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! âœ“ Sigmoid is working correctly. You can see: - For large positive values (100), sigmoid â‰ˆ 1.0, so gradient â‰ˆ 0 - For values near 0 (0.4), you get a reasonable gradient (0.24)</p>
<p><strong>Last one: GELU</strong></p>
<p>This is the most complex. Itâ€™s used in modern transformers (GPT, BERT, etc.):</p>
<ul>
<li>Forward: <code>f(x) = 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))</code></li>
<li>Backward: Youâ€™ll need to apply the chain rule through this composition</li>
</ul>
<p>This one is tricky! Would you like to: - <strong>A)</strong> Try implementing it yourself (challenging!) - <strong>B)</strong> See a hint about how to break it down - <strong>C)</strong> Skip it for now and move back to finishing the Neuron class</p>
<p>What sounds good?</p>
<div id="1573fccc" class="cell" data-time_run="2025-12-21T13:27:40.977687+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb280"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Value)</span>
<span id="cb280-2"><a href="#cb280-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gelu(<span class="va">self</span>, alpha<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb280-3"><a href="#cb280-3" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="va">self</span></span>
<span id="cb280-4"><a href="#cb280-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> math.sqrt(<span class="dv">2</span><span class="op">/</span>math.pi)<span class="op">*</span>(x<span class="op">+</span><span class="fl">0.004715</span><span class="op">*</span>x.<span class="fu">__pow__</span>(<span class="dv">3</span>))</span>
<span id="cb280-5"><a href="#cb280-5" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> <span class="fl">0.5</span><span class="op">*</span>x<span class="op">*</span>a.tanh()</span>
<span id="cb280-6"><a href="#cb280-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="723054de" class="cell" data-time_run="2025-12-21T13:27:43.164522+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> Value(<span class="fl">0.4</span>, label<span class="op">=</span><span class="st">'c'</span>)</span>
<span id="cb281-2"><a href="#cb281-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> c.gelu()</span>
<span id="cb281-3"><a href="#cb281-3" aria-hidden="true" tabindex="-1"></a>d.backward()</span>
<span id="cb281-4"><a href="#cb281-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(c.grad)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.29915073570457174</code></pre>
</div>
</div>
</section>
</section>
<section id="part-8-summary-activation-functions" class="level2">
<h2 class="anchored" data-anchor-id="part-8-summary-activation-functions">Part 8 Summary: Activation Functions</h2>
<section id="implemented-activations" class="level3">
<h3 class="anchored" data-anchor-id="implemented-activations">Implemented Activations</h3>
<section id="tanh-hyperbolic-tangent" class="level4">
<h4 class="anchored" data-anchor-id="tanh-hyperbolic-tangent">1. Tanh (Hyperbolic Tangent)</h4>
<ul>
<li><strong>Forward</strong>: <code>tanh(x) = (e^(2x) - 1) / (e^(2x) + 1)</code></li>
<li><strong>Backward</strong>: <code>âˆ‚tanh/âˆ‚x = 1 - tanhÂ²(x)</code></li>
<li><strong>Range</strong>: [-1, 1]</li>
</ul>
</section>
<section id="relu-rectified-linear-unit" class="level4">
<h4 class="anchored" data-anchor-id="relu-rectified-linear-unit">2. ReLU (Rectified Linear Unit)</h4>
<ul>
<li><strong>Forward</strong>: <code>max(0, x)</code></li>
<li><strong>Backward</strong>: <code>1 if x &gt; 0, else 0</code></li>
<li><strong>Use case</strong>: Most common in modern networks</li>
</ul>
</section>
<section id="leaky-relu" class="level4">
<h4 class="anchored" data-anchor-id="leaky-relu">3. Leaky ReLU</h4>
<ul>
<li><strong>Forward</strong>: <code>x if x &gt; 0, else Î±*x</code> (Î± typically 0.01)</li>
<li><strong>Backward</strong>: <code>1 if x &gt; 0, else Î±</code></li>
<li><strong>Advantage</strong>: Prevents â€œdying ReLUâ€ problem</li>
</ul>
</section>
<section id="sigmoid" class="level4">
<h4 class="anchored" data-anchor-id="sigmoid">4. Sigmoid</h4>
<ul>
<li><strong>Forward</strong>: <code>1 / (1 + e^(-x))</code></li>
<li><strong>Backward</strong>: <code>Ïƒ(x) * (1 - Ïƒ(x))</code></li>
<li><strong>Range</strong>: [0, 1]</li>
</ul>
</section>
<section id="gelu-gaussian-error-linear-unit" class="level4">
<h4 class="anchored" data-anchor-id="gelu-gaussian-error-linear-unit">5. GELU (Gaussian Error Linear Unit)</h4>
<ul>
<li><strong>Implementation</strong>: Composed from existing operations (tanh, power, etc.)</li>
<li><strong>Advantage</strong>: Gradients flow automatically via chain rule</li>
<li><strong>Trade-off</strong>: Creates longer computation graph vs manual implementation</li>
</ul>
<div id="9a2f311d" class="cell" data-time_run="2025-12-21T13:27:46.587616+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a>d</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-189-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What do u think about this ?</p>
<section id="reply-79" class="level5">
<h5 class="anchored" data-anchor-id="reply-79">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Impressive! âœ“ Your GELU implementation is clever â€” you built it using existing operations (<code>tanh</code>, <code>__pow__</code>, <code>*</code>, <code>+</code>), so the backward pass happens automatically through the chain rule!</p>
<p>The gradient flows correctly through all those intermediate operations. This is actually the elegant approach â€” no need to manually derive the complex GELU derivative!</p>
<p><strong>Now, letâ€™s get back to the Neuron class.</strong> You had started implementing it earlier. Can you now add a <code>__call__</code> method that: 1. Takes inputs <code>x</code> (a list of numbers) 2. Computes the weighted sum: <code>sum(wi * xi for wi, xi in zip(self.ws, x)) + self.b</code> 3. Applies <code>tanh()</code> activation 4. Returns the result</p>
<p>Want to try adding that to your <code>Neuron</code> class?</p>
<p>Before doing that , tell me if this way of using gelu is efficient at scale? What are challenges of this approach vs deriving and encoding values like tanh or sigmoid?</p>
</section>
<section id="reply-80" class="level5">
<h5 class="anchored" data-anchor-id="reply-80">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great question! Youâ€™ve identified a key trade-off:</p>
<p><strong>Your GELU approach (composing operations):</strong> - âœ… <strong>Pros:</strong> No manual derivative needed, guaranteed correct gradients via chain rule - âŒ <strong>Cons:</strong> Creates a <em>much</em> longer computation graph (look at all those nested operations in your output!)</p>
<p><strong>Manual implementation (like tanh/sigmoid):</strong> - âœ… <strong>Pros:</strong> Single operation node, more efficient memory &amp; compute - âŒ <strong>Cons:</strong> Must manually derive and implement the derivative (error-prone)</p>
<p><strong>At scale:</strong> - Your GELU creates ~10+ nodes vs 1 node for tanh - In a neural net with millions of operations, this overhead adds up - Production libraries (PyTorch, JAX) use manual implementations with optimized kernels</p>
<p><strong>The trade-off:</strong> For learning/prototyping â†’ your approach is perfect! For production â†’ manual implementation wins</p>
<p>Does this make sense? Ready to continue with the Neuronâ€™s <code>__call__</code> method?</p>
</section>
<section id="reply-81" class="level5">
<h5 class="anchored" data-anchor-id="reply-81">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! Now letâ€™s implement the <code>__call__</code> method for your <code>Neuron</code> class.</p>
<p>You already figured out the weighted sum earlier:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb284"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="bu">sum</span>(x<span class="op">*</span>w <span class="cf">for</span> x, w <span class="kw">in</span> <span class="bu">zip</span>(xs, neuron.ws)) <span class="op">+</span> neuron.b</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Can you add a <code>__call__</code> method to your <code>Neuron</code> class that: 1. Takes <code>x</code> as input (list of values) 2. Computes that weighted sum 3. Applies <code>.tanh()</code> activation 4. Returns the result</p>
<p>Give it a try!</p>
<div id="0943c1d5" class="cell" data-time_run="2025-12-21T13:43:58.318214+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb285"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb285-2"><a href="#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>:Neuron, xs):</span>
<span id="cb285-3"><a href="#cb285-3" aria-hidden="true" tabindex="-1"></a>    sm <span class="op">=</span> <span class="bu">sum</span>(x<span class="op">*</span>w <span class="cf">for</span> x, w <span class="kw">in</span> <span class="bu">zip</span>(xs, <span class="va">self</span>.ws)) <span class="op">+</span> <span class="va">self</span>.b</span>
<span id="cb285-4"><a href="#cb285-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sm.tanh()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="6397b608" class="cell" data-time_run="2025-12-21T13:45:20.548925+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb286"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>nin <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>neuron <span class="op">=</span> Neuron(nin)</span>
<span id="cb286-3"><a href="#cb286-3" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> o: random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))<span class="op">;</span>xs</span>
<span id="cb286-4"><a href="#cb286-4" aria-hidden="true" tabindex="-1"></a>neuron(xs)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-191-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="reply-82" class="level5">
<h5 class="anchored" data-anchor-id="reply-82">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! âœ“ Your <code>Neuron</code> is working! You can see it computed the weighted sum and applied tanh, giving an output of about -0.51.</p>
<p><strong>Next step: Build a Layer</strong></p>
<p>A <code>Layer</code> is just a collection of neurons that all receive the same inputs. For example, if you have 3 neurons in a layer, each one independently processes the input and produces its own output.</p>
<p>Can you create a <code>Layer</code> class that: 1. Takes <code>nin</code> (number of inputs) and <code>nout</code> (number of neurons in the layer) 2. Creates <code>nout</code> neurons, each with <code>nin</code> inputs 3. Has a <code>__call__</code> method that runs all neurons on the input and returns a list of outputs</p>
<p>Want to give it a try?</p>
<div id="5421c761" class="cell" data-time_run="2025-12-21T13:49:12.079587+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>nin<span class="op">=</span><span class="dv">4</span></span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>nout<span class="op">=</span><span class="dv">3</span></span>
<span id="cb287-3"><a href="#cb287-3" aria-hidden="true" tabindex="-1"></a>nns <span class="op">=</span> L(<span class="bu">range</span>(nout)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Neuron(nin))<span class="op">;</span> display(<span class="op">*</span>nns)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;__main__.Neuron at 0x74fc3ec80ef0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>&lt;__main__.Neuron at 0x74fc3ec80950&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre><code>&lt;__main__.Neuron at 0x74fc3ec82870&gt;</code></pre>
</div>
</div>
<div id="3df6b96c" class="cell" data-time_run="2025-12-21T13:52:07.566531+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb291"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Layer:</span>
<span id="cb291-2"><a href="#cb291-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nout):</span>
<span id="cb291-3"><a href="#cb291-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nout'</span>)</span>
<span id="cb291-4"><a href="#cb291-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nns <span class="op">=</span> L(<span class="bu">range</span>(nout)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Neuron(nin))<span class="op">;</span> nns</span>
<span id="cb291-5"><a href="#cb291-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-6"><a href="#cb291-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs):</span>
<span id="cb291-7"><a href="#cb291-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron(xs))</span>
<span id="cb291-8"><a href="#cb291-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb291-9"><a href="#cb291-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span>basic_repr(<span class="st">'nin,nout'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="eadb1366" class="cell" data-time_run="2025-12-21T13:52:09.352050+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb292"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> Layer(<span class="dv">4</span>, <span class="dv">3</span>)<span class="op">;</span> l</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=4, nout=3)</code></pre>
</div>
</div>
<div id="5c79d4a3" class="cell" data-time_run="2025-12-21T13:53:28.184852+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb294"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>l(xs).<span class="bu">map</span>(<span class="kw">lambda</span> v: v.data)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#3) [0.5488652326563431,0.06952394048574781,-0.14063337482292246]</code></pre>
</div>
</div>
</section>
<section id="reply-83" class="level5">
<h5 class="anchored" data-anchor-id="reply-83">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Perfect! âœ“ Your <code>Layer</code> class works great! You can see itâ€™s producing 3 outputs (one from each neuron) when given the same 4 inputs.</p>
<p><strong>Final step: Build an MLP (Multi-Layer Perceptron)</strong></p>
<p>An MLP is just layers stacked together â€” the output of one layer becomes the input to the next.</p>
<p>For example, an MLP with architecture <code>[4, 3, 2, 1]</code> means: - 4 inputs â†’ Layer of 3 neurons â†’ Layer of 2 neurons â†’ Layer of 1 neuron â†’ 1 output</p>
<p>Can you create an <code>MLP</code> class that: 1. Takes <code>nin</code> and a list <code>nouts</code> (e.g., <code>[3, 2, 1]</code>) 2. Creates the appropriate layers 3. Has a <code>__call__</code> that chains them together</p>
<p>Hint: The first layer has <code>nin</code> inputs, then each subsequent layerâ€™s input size is the previous layerâ€™s output size.</p>
<p>Want to try it?</p>
<div id="31412830" class="cell" data-time_run="2025-12-21T14:09:04.494129+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb296"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb296-2"><a href="#cb296-2" aria-hidden="true" tabindex="-1"></a>nin<span class="op">=</span><span class="dv">4</span></span>
<span id="cb296-3"><a href="#cb296-3" aria-hidden="true" tabindex="-1"></a>nouts <span class="op">=</span> [<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb296-4"><a href="#cb296-4" aria-hidden="true" tabindex="-1"></a>lszs <span class="op">=</span> nouts[:]</span>
<span id="cb296-5"><a href="#cb296-5" aria-hidden="true" tabindex="-1"></a>lszs.insert(<span class="dv">0</span>, nin)<span class="op">;</span> lszs</span>
<span id="cb296-6"><a href="#cb296-6" aria-hidden="true" tabindex="-1"></a>L(<span class="bu">zip</span>(lszs[:<span class="op">-</span><span class="dv">1</span>], lszs[<span class="dv">1</span>:]))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(#4) [(4, 4),(4, 3),(3, 2),(2, 1)]</code></pre>
</div>
</div>
<div id="3e89601e" class="cell" data-time_run="2025-12-21T14:10:40.219339+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb298"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a>layers <span class="op">=</span> L(<span class="bu">zip</span>(lszs[:<span class="op">-</span><span class="dv">1</span>], lszs[<span class="dv">1</span>:])).starmap(Layer)<span class="op">;</span> layers</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#4) [Layer(nin=4, nout=4),Layer(nin=4, nout=3),Layer(nin=3, nout=2),Layer(nin=2, nout=1)]</code></pre>
</div>
</div>
<div id="855f2d06" class="cell" data-time_run="2025-12-21T14:11:04.336316+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb300"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP:</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nouts):</span>
<span id="cb300-3"><a href="#cb300-3" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nouts'</span>)</span>
<span id="cb300-4"><a href="#cb300-4" aria-hidden="true" tabindex="-1"></a>        lszs <span class="op">=</span> nouts[:]</span>
<span id="cb300-5"><a href="#cb300-5" aria-hidden="true" tabindex="-1"></a>        lszs.insert(<span class="dv">0</span>, nin)<span class="op">;</span> lszs</span>
<span id="cb300-6"><a href="#cb300-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> L(<span class="bu">zip</span>(lszs[:<span class="op">-</span><span class="dv">1</span>], lszs[<span class="dv">1</span>:])).starmap(Layer)<span class="op">;</span> layers</span>
<span id="cb300-7"><a href="#cb300-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-8"><a href="#cb300-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs):</span>
<span id="cb300-9"><a href="#cb300-9" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> xs</span>
<span id="cb300-10"><a href="#cb300-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers: o <span class="op">=</span> layer(o)</span>
<span id="cb300-11"><a href="#cb300-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o</span>
<span id="cb300-12"><a href="#cb300-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-13"><a href="#cb300-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="st">"-&gt;"</span>.join(<span class="bu">str</span>(l) <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="269b4e45" class="cell" data-time_run="2025-12-21T14:12:19.543599+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb301"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb301-1"><a href="#cb301-1" aria-hidden="true" tabindex="-1"></a>network <span class="op">=</span> MLP(<span class="dv">4</span>, [<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>])<span class="op">;</span> network</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=4, nout=4)-&gt;Layer(nin=4, nout=3)-&gt;Layer(nin=3, nout=2)-&gt;Layer(nin=2, nout=1)</code></pre>
</div>
</div>
<div id="f8f42157" class="cell" data-time_run="2025-12-21T14:12:54.461867+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb303"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb303-1"><a href="#cb303-1" aria-hidden="true" tabindex="-1"></a>network(xs)[<span class="dv">0</span>].data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>-0.5114512924987726</code></pre>
</div>
</div>
<p>a</p>
</section>
<section id="reply-84" class="level5">
<h5 class="anchored" data-anchor-id="reply-84">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Excellent! âœ“ Your MLP is working perfectly! You can see itâ€™s taking 4 inputs and passing them through the layers (4â†’4â†’3â†’2â†’1) to produce a single output value.</p>
<p><strong>ğŸ‰ Congratulations!</strong> Youâ€™ve now built: - âœ… A complete autograd engine (<code>Value</code> class with backpropagation) - âœ… Multiple activation functions (tanh, relu, leaky_relu, sigmoid, gelu) - âœ… Neural network components (Neuron, Layer, MLP)</p>
<p><strong>Whatâ€™s next?</strong></p>
<p>According to Karpathyâ€™s lecture, the next step is to: 1. Create a small dataset (like 4 training examples) 2. Define a loss function (mean squared error) 3. Train the network by calling <code>backward()</code> and updating weights</p>
<p>Would you like to continue with training the network, or would you prefer to take a break here?</p>
<div id="ad3de1c9" class="cell" data-time_run="2025-12-21T14:20:50.115576+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>]</span>
<span id="cb305-2"><a href="#cb305-2" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> <span class="bu">list</span>(L(xs).<span class="bu">map</span>(<span class="kw">lambda</span> x : x<span class="op">**</span><span class="dv">2</span>))<span class="op">;</span> ys</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>[1, 4, 9, 16]</code></pre>
</div>
</div>
<div id="2fbfab03" class="cell" data-time_run="2025-12-21T14:20:54.008791+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb307"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a>network <span class="op">=</span> MLP(<span class="dv">1</span>, [<span class="dv">4</span>,<span class="dv">1</span>])<span class="op">;</span> network</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=1, nout=4)-&gt;Layer(nin=4, nout=1)</code></pre>
</div>
</div>
<div id="06962f68" class="cell" data-time_run="2025-12-21T14:22:23.135073+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb309"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(network, xs, ys):</span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> network(xs)</span>
<span id="cb309-3"><a href="#cb309-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L(<span class="bu">zip</span>(preds, ys)).starmap(<span class="kw">lambda</span> pred, y: (pred<span class="op">-</span>y)<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="db1fa526" class="cell" data-time_run="2025-12-21T14:23:24.163748+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb310"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> mse(network, xs, ys)<span class="op">;</span> loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-204-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="548a7ea3" class="cell" data-time_run="2025-12-21T14:23:27.281469+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb311"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>loss.backward()<span class="op">;</span> loss</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<div>
<figure class="figure">
<p><img src="01_micrograd_files/figure-html/cell-205-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What do you think?</p>
</section>
<section id="reply-85" class="level5">
<h5 class="anchored" data-anchor-id="reply-85">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good start! Youâ€™ve created a dataset and computed a loss. However, I notice a few issues:</p>
<p><strong>Problems:</strong> 1. Your network expects a <strong>list</strong> of inputs for each example, but youâ€™re passing all 4 examples at once 2. MSE should compute loss for each example separately, then average</p>
<p><strong>The pattern should be:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb312"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> [[<span class="dv">1</span>], [<span class="dv">2</span>], [<span class="dv">3</span>], [<span class="dv">4</span>]]  <span class="co"># Each example is a list</span></span>
<span id="cb312-2"><a href="#cb312-2" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">9</span>, <span class="dv">16</span>]</span>
<span id="cb312-3"><a href="#cb312-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb312-4"><a href="#cb312-4" aria-hidden="true" tabindex="-1"></a><span class="co"># For each (x, y) pair:</span></span>
<span id="cb312-5"><a href="#cb312-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   - Get prediction: pred = network(x)</span></span>
<span id="cb312-6"><a href="#cb312-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   - Compute error: (pred - y)Â²</span></span>
<span id="cb312-7"><a href="#cb312-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Then sum/average all errors</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Want to try fixing the <code>mse</code> function to handle this correctly?</p>
<div id="eeda8a22" class="cell" data-time_run="2025-12-21T14:29:29.064151+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb313"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse(network, x, y):</span>
<span id="cb313-2"><a href="#cb313-2" aria-hidden="true" tabindex="-1"></a>    pred <span class="op">=</span> network(x)[<span class="dv">0</span>]</span>
<span id="cb313-3"><a href="#cb313-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (pred<span class="op">-</span>y)<span class="op">**</span><span class="dv">2</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="a2af1777" class="cell" data-time_run="2025-12-21T14:29:31.936465+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb314"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="co"># L(zip(xs, ys)).starmap(lambda x, y: mse(network, x, y)).mean()</span></span>
<span id="cb314-2"><a href="#cb314-2" aria-hidden="true" tabindex="-1"></a>network([<span class="dv">1</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#1) [Value(data=0.6971547240463388, grad=0.0, _op='tanh', _prev={Value(data=0.8617432007244408, grad=0.0, _op='+', _prev={Value(data=-0.49805255672493587, grad=-2.1791698426047215, _op='', _prev=set(), label='b'), Value(data=1.3597957574493766, grad=0.0, _op='+', _prev={Value(data=0.1142686228967522, grad=0.0, _op='*', _prev={Value(data=-0.5056188406401592, grad=0.0, _op='tanh', _prev={Value(data=-0.5568262425676664, grad=0.0, _op='+', _prev={Value(data=-0.6634698981423022, grad=0.5760582789977401, _op='', _prev=set(), label='b'), Value(data=0.10664365557463573, grad=0.0, _op='+', _prev={Value(data=0, grad=0.0, _op='', _prev=set(), label=''), Value(data=0.10664365557463573, grad=0.0, _op='*', _prev={Value(data=1, grad=0.0, _op='', _prev=set(), label=''), Value(data=0.10664365557463573, grad=0.6807961479064201, _op='', _prev=set(), label='w1')}, label='')}, label='')}, label='')}, label=''), Value(data=-0.2259975572747206, grad=1.416637709197454, _op='', _prev=set(), label='w4')}, label=''), Value(data=1.2455271345526244, grad=0.0, _op='+', _prev={Value(data=0.6192851650705841, grad=0.0, _op='+', _prev={Value(data=0.56019455132946, grad=0.0, _op='*', _prev={Value(data=-0.7036279278727451, grad=0.0, _op='tanh', _prev={Value(data=-0.8744498329846211, grad=0.0, _op='+', _prev={Value(data=0.09931762021220458, grad=1.6268377126766216, _op='', _prev=set(), label='b'), Value(data=-0.9737674531968257, grad=0.0, _op='+', _prev={Value(data=-0.9737674531968257, grad=0.0, _op='*', _prev={Value(data=-0.9737674531968257, grad=1.877120437703794, _op='', _prev=set(), label='w1'), Value(data=1, grad=0.0, _op='', _prev=set(), label='')}, label=''), Value(data=0, grad=0.0, _op='', _prev=set(), label='')}, label='')}, label='')}, label=''), Value(data=-0.7961516721246094, grad=2.4095103384545853, _op='', _prev=set(), label='w2')}, label=''), Value(data=0.05909061374112403, grad=0.0, _op='+', _prev={Value(data=0, grad=0.0, _op='', _prev=set(), label=''), Value(data=0.05909061374112403, grad=0.0, _op='*', _prev={Value(data=0.3278805572879451, grad=-0.6732511785603527, _op='', _prev=set(), label='w1'), Value(data=0.18021993810761577, grad=0.0, _op='tanh', _prev={Value(data=0.18221000062057713, grad=0.0, _op='+', _prev={Value(data=-0.5979145427017154, grad=-1.3826015486030616, _op='', _prev=set(), label='b'), Value(data=0.7801245433222925, grad=0.0, _op='+', _prev={Value(data=0, grad=0.0, _op='', _prev=set(), label=''), Value(data=0.7801245433222925, grad=0.0, _op='*', _prev={Value(data=0.7801245433222925, grad=-1.580116055546356, _op='', _prev=set(), label='w1'), Value(data=1, grad=0.0, _op='', _prev=set(), label='')}, label='')}, label='')}, label='')}, label='')}, label='')}, label='')}, label=''), Value(data=0.6262419694820404, grad=0.0, _op='*', _prev={Value(data=0.6417204031741875, grad=0.0, _op='tanh', _prev={Value(data=0.7610931594993728, grad=0.0, _op='+', _prev={Value(data=0.6437615557116572, grad=-2.1443312793236045, _op='', _prev=set(), label='b'), Value(data=0.11733160378771568, grad=0.0, _op='+', _prev={Value(data=0.11733160378771568, grad=0.0, _op='*', _prev={Value(data=1, grad=0.0, _op='', _prev=set(), label=''), Value(data=0.11733160378771568, grad=-2.5017198258775384, _op='', _prev=set(), label='w1')}, label=''), Value(data=0, grad=0.0, _op='', _prev=set(), label='')}, label='')}, label='')}, label=''), Value(data=0.9758797856269099, grad=-1.9977396428304754, _op='', _prev=set(), label='w3')}, label='')}, label='')}, label='')}, label='')}, label='')]</code></pre>
</div>
</div>
<div id="2f1158dd" class="cell" data-time_run="2025-12-21T14:50:20.440146+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb316"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> L(<span class="bu">zip</span>(xs, ys)).starmap(<span class="kw">lambda</span> x, y: mse(network, [x], y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys)<span class="op">;</span> loss.data</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>75.95850094956187</code></pre>
</div>
</div>
</section>
<section id="reply-86" class="level5">
<h5 class="anchored" data-anchor-id="reply-86">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Good! Your loss function now works correctly for individual examples, and youâ€™re computing the average loss across all 4 examples.</p>
<p>The loss is quite high (75.96) because the network hasnâ€™t been trained yet â€” the weights are random!</p>
<p><strong>Next step: Training loop</strong></p>
<p>To train, you need to: 1. Compute the loss 2. Call <code>loss.backward()</code> to get gradients 3. Update each weight: <code>w.data -= learning_rate * w.grad</code> 4. <strong>Important:</strong> Zero out all gradients before the next iteration</p>
<p>Want to try implementing a simple training loop? Start with just 1 step and see if the loss decreases.</p>
<div id="0d60d707" class="cell" data-time_run="2025-12-21T14:59:42.353852+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb318"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trainloop(network, xs, ys, lr<span class="op">=</span><span class="fl">0.03</span>):</span>
<span id="cb318-2"><a href="#cb318-2" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> L(<span class="bu">zip</span>(xs, ys)).starmap(<span class="kw">lambda</span> x, y: mse(network, [x], y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys)</span>
<span id="cb318-3"><a href="#cb318-3" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb318-4"><a href="#cb318-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> network.layers:</span>
<span id="cb318-5"><a href="#cb318-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> neurons <span class="kw">in</span> layer.nns:</span>
<span id="cb318-6"><a href="#cb318-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> w <span class="kw">in</span> neuron.ws: w.data <span class="op">-=</span> w.grad<span class="op">*</span>lr</span>
<span id="cb318-7"><a href="#cb318-7" aria-hidden="true" tabindex="-1"></a>            b.data <span class="op">-=</span> b.grad<span class="op">*</span>lr</span>
<span id="cb318-8"><a href="#cb318-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> network</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Should I just implement zero_grad at network level?</p>
</section>
<section id="reply-87" class="level5">
<h5 class="anchored" data-anchor-id="reply-87">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>Yes! Thatâ€™s the clean approach. Youâ€™ll want a <code>parameters()</code> method that collects all weights and biases from the network, then <code>zero_grad()</code> can iterate through them.</p>
<p>Karpathy does exactly this â€” he adds a <code>parameters()</code> method to each class: - <code>Neuron.parameters()</code> â†’ returns <code>self.ws + [self.b]</code> - <code>Layer.parameters()</code> â†’ collects from all neurons - <code>MLP.parameters()</code> â†’ collects from all layers</p>
<p>Then <code>zero_grad()</code> just does:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb319"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p <span class="kw">in</span> network.parameters():</span>
<span id="cb319-2"><a href="#cb319-2" aria-hidden="true" tabindex="-1"></a>    p.grad <span class="op">=</span> <span class="fl">0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Want to try implementing <code>parameters()</code> for each class first?</p>
<div id="e121bc6f" class="cell" data-time_run="2025-12-21T15:07:11.355206+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb320"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Neuron): <span class="cf">return</span> <span class="va">self</span>.ws <span class="op">+</span> [<span class="va">self</span>.b]</span>
<span id="cb320-3"><a href="#cb320-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-4"><a href="#cb320-4" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Layer)</span>
<span id="cb320-5"><a href="#cb320-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Layer): <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron.parameters()).concat()</span>
<span id="cb320-6"><a href="#cb320-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-7"><a href="#cb320-7" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb320-8"><a href="#cb320-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:MLP): <span class="cf">return</span> L(<span class="va">self</span>.layers).<span class="bu">map</span>(<span class="kw">lambda</span> layer: layer.parameters()).concat()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="c623865f" class="cell" data-time_run="2025-12-21T15:07:42.559935+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb321"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a>network.parameters()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>(#13) [Value(data=0.7801245433222925, grad=-1.580116055546356, _op='', _prev=set(), label='w1'),Value(data=-0.5979145427017154, grad=-1.3826015486030616, _op='', _prev=set(), label='b'),Value(data=-0.9737674531968257, grad=1.877120437703794, _op='', _prev=set(), label='w1'),Value(data=0.09931762021220458, grad=1.6268377126766216, _op='', _prev=set(), label='b'),Value(data=0.11733160378771568, grad=-2.5017198258775384, _op='', _prev=set(), label='w1'),Value(data=0.6437615557116572, grad=-2.1443312793236045, _op='', _prev=set(), label='b'),Value(data=0.10664365557463573, grad=0.6807961479064201, _op='', _prev=set(), label='w1'),Value(data=-0.6634698981423022, grad=0.5760582789977401, _op='', _prev=set(), label='b'),Value(data=0.3278805572879451, grad=-0.6732511785603527, _op='', _prev=set(), label='w1'),Value(data=-0.7961516721246094, grad=2.4095103384545853, _op='', _prev=set(), label='w2'),Value(data=0.9758797856269099, grad=-1.9977396428304754, _op='', _prev=set(), label='w3'),Value(data=-0.2259975572747206, grad=1.416637709197454, _op='', _prev=set(), label='w4'),Value(data=-0.49805255672493587, grad=-2.1791698426047215, _op='', _prev=set(), label='b')]</code></pre>
</div>
</div>
<p>Is this correct? Can you count it step by step</p>
</section>
<section id="reply-88" class="level5">
<h5 class="anchored" data-anchor-id="reply-88">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Let me count step by step:</p>
<p><strong>Expected count:</strong> - Layer 1: 1 input â†’ 4 neurons = 4 weights + 4 biases = <strong>8 parameters</strong> - Layer 2: 4 inputs â†’ 1 neuron = 4 weights + 1 bias = <strong>5 parameters</strong> - <strong>Total: 13 parameters</strong> âœ“</p>
<p><strong>Your output shows 13 parameters</strong> â€” thatâ€™s correct!</p>
<p>Now implement <code>zero_grad()</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb323"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb323-2"><a href="#cb323-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_grad(<span class="va">self</span>):</span>
<span id="cb323-3"><a href="#cb323-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.parameters():</span>
<span id="cb323-4"><a href="#cb323-4" aria-hidden="true" tabindex="-1"></a>        p.grad <span class="op">=</span> <span class="fl">0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try adding that and then we can fix your training loop!</p>
<div id="d9a63e75" class="cell" data-time_run="2025-12-21T15:16:28.118993+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb324-2"><a href="#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_grad(<span class="va">self</span>):</span>
<span id="cb324-3"><a href="#cb324-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.parameters(): p.grad <span class="op">=</span> <span class="fl">0.0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>It is also clear why you have to do zero_grad. Since you accumulate gradient in backward pass not calling zero will keep on diverging old gradient</p>
<p>Letâ€™s fix training loop I am thinking I should introduce epochs as additional parameter . On each epoch do network.zero_grad before remaining steps?</p>
</section>
<section id="reply-89" class="level5">
<h5 class="anchored" data-anchor-id="reply-89">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Exactly right! Your understanding is perfect.</p>
<p><strong>Training loop structure:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb325"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb325-2"><a href="#cb325-2" aria-hidden="true" tabindex="-1"></a>    network.zero_grad()        <span class="co"># Clear old gradients</span></span>
<span id="cb325-3"><a href="#cb325-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(...)    <span class="co"># Forward pass</span></span>
<span id="cb325-4"><a href="#cb325-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()             <span class="co"># Backward pass</span></span>
<span id="cb325-5"><a href="#cb325-5" aria-hidden="true" tabindex="-1"></a>    update_weights(...)         <span class="co"># Gradient descent step</span></span>
<span id="cb325-6"><a href="#cb325-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>The <code>zero_grad()</code> must happen <strong>before</strong> <code>backward()</code> each epoch, otherwise gradients keep accumulating from previous iterations.</p>
<p>Want to try implementing your training loop with this structure?</p>
<div id="1153c4f2" class="cell" data-time_run="2025-12-21T15:28:59.277703+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> trainloop(network, xs, ys, lr<span class="op">=</span><span class="fl">0.03</span>, num_epochs<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb326-3"><a href="#cb326-3" aria-hidden="true" tabindex="-1"></a>        network.zero_grad()</span>
<span id="cb326-4"><a href="#cb326-4" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> L(<span class="bu">zip</span>(xs, ys)).starmap(<span class="kw">lambda</span> x, y: mse(network, [x], y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys)</span>
<span id="cb326-5"><a href="#cb326-5" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb326-6"><a href="#cb326-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> p <span class="kw">in</span> network.parameters(): p.data <span class="op">-=</span> p.grad<span class="op">*</span>lr</span>
<span id="cb326-7"><a href="#cb326-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb326-8"><a href="#cb326-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> network</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="bf659f63" class="cell" data-time_run="2025-12-21T15:29:17.111380+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb327"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a>trainloop(network, xs, ys)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 75.95850094956187
Epoch 1, Loss: 75.09879738932773
Epoch 2, Loss: 74.9260470559913</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=1, nout=4)-&gt;Layer(nin=4, nout=1)</code></pre>
</div>
</div>
</section>
<section id="reply-90" class="level5">
<h5 class="anchored" data-anchor-id="reply-90">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>Great! Your training loop is working â€” the loss is decreasing from 75.96 â†’ 75.10 â†’ 74.93! ğŸ‰</p>
<p>The loss is still high because: 1. Only 3 epochs (try more!) 2. The problem is actually quite hard for this small network 3. Learning rate might need tuning</p>
<p><strong>Try:</strong> - Increase epochs to 100 or 1000 - Try different learning rates (0.01, 0.05, 0.1)</p>
<p>What happens to the loss with more training?</p>
<div id="be9e82f4" class="cell" data-time_run="2025-12-21T15:31:09.719608+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb330"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a>trainloop(network, xs, ys, num_epochs<span class="op">=</span><span class="dv">1000</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 74.51651570158768
Epoch 1, Loss: 74.51635632258545
Epoch 2, Loss: 74.51619999148454
Epoch 3, Loss: 74.51604662162586
Epoch 4, Loss: 74.51589612960666
Epoch 5, Loss: 74.5157484351289
Epoch 6, Loss: 74.51560346085606
Epoch 7, Loss: 74.51546113227774
Epoch 8, Loss: 74.51532137758173
Epoch 9, Loss: 74.51518412753285
Epoch 10, Loss: 74.51504931535843
Epoch 11, Loss: 74.51491687663957
Epoch 12, Loss: 74.5147867492085
Epoch 13, Loss: 74.51465887305082
Epoch 14, Loss: 74.51453319021323
Epoch 15, Loss: 74.51440964471563
Epoch 16, Loss: 74.51428818246787
Epoch 17, Loss: 74.51416875119057
Epoch 18, Loss: 74.51405130034001
Epoch 19, Loss: 74.51393578103665
Epoch 20, Loss: 74.51382214599708
Epoch 21, Loss: 74.5137103494695
Epoch 22, Loss: 74.51360034717209
Epoch 23, Loss: 74.51349209623444
Epoch 24, Loss: 74.51338555514174
Epoch 25, Loss: 74.51328068368159
Epoch 26, Loss: 74.51317744289335
Epoch 27, Loss: 74.51307579501967
Epoch 28, Loss: 74.51297570346054
Epoch 29, Loss: 74.51287713272916
Epoch 30, Loss: 74.51278004840987
Epoch 31, Loss: 74.51268441711818
Epoch 32, Loss: 74.51259020646225
Epoch 33, Loss: 74.51249738500645
Epoch 34, Loss: 74.5124059222361
Epoch 35, Loss: 74.51231578852412
Epoch 36, Loss: 74.51222695509898
Epoch 37, Loss: 74.51213939401396
Epoch 38, Loss: 74.51205307811783
Epoch 39, Loss: 74.51196798102673
Epoch 40, Loss: 74.51188407709724
Epoch 41, Loss: 74.51180134140061
Epoch 42, Loss: 74.51171974969793
Epoch 43, Loss: 74.51163927841658
Epoch 44, Loss: 74.51155990462732
Epoch 45, Loss: 74.51148160602257
Epoch 46, Loss: 74.51140436089551
Epoch 47, Loss: 74.51132814811986
Epoch 48, Loss: 74.51125294713076
Epoch 49, Loss: 74.51117873790606
Epoch 50, Loss: 74.5111055009487
Epoch 51, Loss: 74.51103321726947
Epoch 52, Loss: 74.51096186837064
Epoch 53, Loss: 74.51089143623015
Epoch 54, Loss: 74.51082190328644
Epoch 55, Loss: 74.51075325242371
Epoch 56, Loss: 74.51068546695807
Epoch 57, Loss: 74.51061853062377
Epoch 58, Loss: 74.51055242756036
Epoch 59, Loss: 74.51048714230001
Epoch 60, Loss: 74.51042265975555
Epoch 61, Loss: 74.51035896520872
Epoch 62, Loss: 74.51029604429904
Epoch 63, Loss: 74.51023388301293
Epoch 64, Loss: 74.51017246767337
Epoch 65, Loss: 74.5101117849298
Epoch 66, Loss: 74.51005182174846
Epoch 67, Loss: 74.50999256540302
Epoch 68, Loss: 74.50993400346559
Epoch 69, Loss: 74.50987612379804
Epoch 70, Loss: 74.50981891454353
Epoch 71, Loss: 74.50976236411853
Epoch 72, Loss: 74.50970646120481
Epoch 73, Loss: 74.50965119474206
Epoch 74, Loss: 74.50959655392047
Epoch 75, Loss: 74.50954252817377
Epoch 76, Loss: 74.50948910717229
Epoch 77, Loss: 74.50943628081644
Epoch 78, Loss: 74.50938403923041
Epoch 79, Loss: 74.50933237275586
Epoch 80, Loss: 74.50928127194607
Epoch 81, Loss: 74.50923072756008
Epoch 82, Loss: 74.50918073055726
Epoch 83, Loss: 74.50913127209176
Epoch 84, Loss: 74.50908234350739
Epoch 85, Loss: 74.50903393633253
Epoch 86, Loss: 74.50898604227521
Epoch 87, Loss: 74.50893865321844
Epoch 88, Loss: 74.50889176121554
Epoch 89, Loss: 74.5088453584857
Epoch 90, Loss: 74.5087994374098
Epoch 91, Loss: 74.50875399052603
Epoch 92, Loss: 74.50870901052603
Epoch 93, Loss: 74.50866449025087
Epoch 94, Loss: 74.50862042268723
Epoch 95, Loss: 74.5085768009638
Epoch 96, Loss: 74.50853361834763
Epoch 97, Loss: 74.50849086824073
Epoch 98, Loss: 74.50844854417662
Epoch 99, Loss: 74.50840663981714
Epoch 100, Loss: 74.50836514894927
Epoch 101, Loss: 74.50832406548201
Epoch 102, Loss: 74.50828338344348
Epoch 103, Loss: 74.5082430969779
Epoch 104, Loss: 74.50820320034295
Epoch 105, Loss: 74.50816368790683
Epoch 106, Loss: 74.50812455414584
Epoch 107, Loss: 74.50808579364158
Epoch 108, Loss: 74.50804740107864
Epoch 109, Loss: 74.50800937124204
Epoch 110, Loss: 74.50797169901487
Epoch 111, Loss: 74.50793437937608
Epoch 112, Loss: 74.50789740739819
Epoch 113, Loss: 74.50786077824513
Epoch 114, Loss: 74.50782448717008
Epoch 115, Loss: 74.50778852951356
Epoch 116, Loss: 74.50775290070123
Epoch 117, Loss: 74.50771759624216
Epoch 118, Loss: 74.50768261172675
Epoch 119, Loss: 74.50764794282506
Epoch 120, Loss: 74.5076135852849
Epoch 121, Loss: 74.50757953493014
Epoch 122, Loss: 74.50754578765903
Epoch 123, Loss: 74.50751233944253
Epoch 124, Loss: 74.50747918632267
Epoch 125, Loss: 74.50744632441109
Epoch 126, Loss: 74.50741374988745
Epoch 127, Loss: 74.50738145899788
Epoch 128, Loss: 74.50734944805372
Epoch 129, Loss: 74.50731771342991
Epoch 130, Loss: 74.50728625156378
Epoch 131, Loss: 74.50725505895366
Epoch 132, Loss: 74.50722413215752
Epoch 133, Loss: 74.50719346779178
Epoch 134, Loss: 74.50716306253007
Epoch 135, Loss: 74.507132913102
Epoch 136, Loss: 74.50710301629199
Epoch 137, Loss: 74.50707336893812
Epoch 138, Loss: 74.50704396793105
Epoch 139, Loss: 74.50701481021292
Epoch 140, Loss: 74.50698589277623
Epoch 141, Loss: 74.50695721266287
Epoch 142, Loss: 74.50692876696313
Epoch 143, Loss: 74.50690055281467
Epoch 144, Loss: 74.5068725674015
Epoch 145, Loss: 74.5068448079532
Epoch 146, Loss: 74.5068172717439
Epoch 147, Loss: 74.50678995609132
Epoch 148, Loss: 74.50676285835613
Epoch 149, Loss: 74.50673597594083
Epoch 150, Loss: 74.50670930628908
Epoch 151, Loss: 74.50668284688487
Epoch 152, Loss: 74.50665659525168
Epoch 153, Loss: 74.50663054895176
Epoch 154, Loss: 74.50660470558536
Epoch 155, Loss: 74.50657906278994
Epoch 156, Loss: 74.50655361823954
Epoch 157, Loss: 74.50652836964402
Epoch 158, Loss: 74.50650331474836
Epoch 159, Loss: 74.50647845133203
Epoch 160, Loss: 74.50645377720834
Epoch 161, Loss: 74.50642929022372
Epoch 162, Loss: 74.50640498825717
Epoch 163, Loss: 74.50638086921968
Epoch 164, Loss: 74.50635693105347
Epoch 165, Loss: 74.5063331717316
Epoch 166, Loss: 74.50630958925724
Epoch 167, Loss: 74.50628618166326
Epoch 168, Loss: 74.5062629470115
Epoch 169, Loss: 74.50623988339244
Epoch 170, Loss: 74.5062169889245
Epoch 171, Loss: 74.50619426175363
Epoch 172, Loss: 74.50617170005279
Epoch 173, Loss: 74.5061493020214
Epoch 174, Loss: 74.50612706588495
Epoch 175, Loss: 74.50610498989451
Epoch 176, Loss: 74.50608307232622
Epoch 177, Loss: 74.50606131148089
Epoch 178, Loss: 74.50603970568356
Epoch 179, Loss: 74.50601825328302
Epoch 180, Loss: 74.50599695265143
Epoch 181, Loss: 74.50597580218397
Epoch 182, Loss: 74.50595480029824
Epoch 183, Loss: 74.50593394543412
Epoch 184, Loss: 74.50591323605322
Epoch 185, Loss: 74.50589267063853
Epoch 186, Loss: 74.50587224769401
Epoch 187, Loss: 74.5058519657444
Epoch 188, Loss: 74.50583182333463
Epoch 189, Loss: 74.50581181902962
Epoch 190, Loss: 74.50579195141393
Epoch 191, Loss: 74.50577221909137
Epoch 192, Loss: 74.50575262068469
Epoch 193, Loss: 74.5057331548353
Epoch 194, Loss: 74.50571382020291
Epoch 195, Loss: 74.50569461546525
Epoch 196, Loss: 74.50567553931776
Epoch 197, Loss: 74.50565659047327
Epoch 198, Loss: 74.50563776766177
Epoch 199, Loss: 74.50561906963003
Epoch 200, Loss: 74.50560049514145
Epoch 201, Loss: 74.50558204297567
Epoch 202, Loss: 74.50556371192839
Epoch 203, Loss: 74.50554550081102
Epoch 204, Loss: 74.50552740845052
Epoch 205, Loss: 74.50550943368904
Epoch 206, Loss: 74.50549157538381
Epoch 207, Loss: 74.50547383240676
Epoch 208, Loss: 74.50545620364437
Epoch 209, Loss: 74.50543868799741
Epoch 210, Loss: 74.50542128438072
Epoch 211, Loss: 74.5054039917229
Epoch 212, Loss: 74.50538680896632
Epoch 213, Loss: 74.5053697350666
Epoch 214, Loss: 74.50535276899261
Epoch 215, Loss: 74.50533590972624
Epoch 216, Loss: 74.50531915626212
Epoch 217, Loss: 74.50530250760744
Epoch 218, Loss: 74.50528596278181
Epoch 219, Loss: 74.50526952081701
Epoch 220, Loss: 74.50525318075685
Epoch 221, Loss: 74.5052369416569
Epoch 222, Loss: 74.50522080258445
Epoch 223, Loss: 74.50520476261813
Epoch 224, Loss: 74.50518882084796
Epoch 225, Loss: 74.50517297637502
Epoch 226, Loss: 74.5051572283113
Epoch 227, Loss: 74.50514157577963
Epoch 228, Loss: 74.5051260179134
Epoch 229, Loss: 74.50511055385644
Epoch 230, Loss: 74.50509518276296
Epoch 231, Loss: 74.50507990379718
Epoch 232, Loss: 74.5050647161334
Epoch 233, Loss: 74.50504961895578
Epoch 234, Loss: 74.50503461145806
Epoch 235, Loss: 74.50501969284363
Epoch 236, Loss: 74.50500486232524
Epoch 237, Loss: 74.50499011912495
Epoch 238, Loss: 74.50497546247388
Epoch 239, Loss: 74.50496089161224
Epoch 240, Loss: 74.50494640578904
Epoch 241, Loss: 74.50493200426209
Epoch 242, Loss: 74.50491768629773
Epoch 243, Loss: 74.50490345117089
Epoch 244, Loss: 74.50488929816476
Epoch 245, Loss: 74.50487522657086
Epoch 246, Loss: 74.5048612356888
Epoch 247, Loss: 74.50484732482619
Epoch 248, Loss: 74.50483349329858
Epoch 249, Loss: 74.50481974042924
Epoch 250, Loss: 74.50480606554922
Epoch 251, Loss: 74.504792467997
Epoch 252, Loss: 74.50477894711862
Epoch 253, Loss: 74.50476550226743
Epoch 254, Loss: 74.50475213280404
Epoch 255, Loss: 74.50473883809624
Epoch 256, Loss: 74.50472561751882
Epoch 257, Loss: 74.50471247045354
Epoch 258, Loss: 74.50469939628903
Epoch 259, Loss: 74.50468639442066
Epoch 260, Loss: 74.50467346425049
Epoch 261, Loss: 74.50466060518714
Epoch 262, Loss: 74.50464781664573
Epoch 263, Loss: 74.50463509804777
Epoch 264, Loss: 74.50462244882105
Epoch 265, Loss: 74.50460986839964
Epoch 266, Loss: 74.50459735622371
Epoch 267, Loss: 74.50458491173951
Epoch 268, Loss: 74.50457253439926
Epoch 269, Loss: 74.50456022366106
Epoch 270, Loss: 74.50454797898881
Epoch 271, Loss: 74.50453579985222
Epoch 272, Loss: 74.50452368572658
Epoch 273, Loss: 74.50451163609281
Epoch 274, Loss: 74.50449965043734
Epoch 275, Loss: 74.504487728252
Epoch 276, Loss: 74.50447586903405
Epoch 277, Loss: 74.50446407228601
Epoch 278, Loss: 74.50445233751562
Epoch 279, Loss: 74.50444066423577
Epoch 280, Loss: 74.5044290519645
Epoch 281, Loss: 74.5044175002248
Epoch 282, Loss: 74.50440600854468
Epoch 283, Loss: 74.50439457645699
Epoch 284, Loss: 74.50438320349946
Epoch 285, Loss: 74.50437188921458
Epoch 286, Loss: 74.50436063314952
Epoch 287, Loss: 74.5043494348561
Epoch 288, Loss: 74.50433829389075
Epoch 289, Loss: 74.50432720981445
Epoch 290, Loss: 74.5043161821926
Epoch 291, Loss: 74.50430521059505
Epoch 292, Loss: 74.50429429459598
Epoch 293, Loss: 74.50428343377394
Epoch 294, Loss: 74.50427262771161
Epoch 295, Loss: 74.50426187599598
Epoch 296, Loss: 74.50425117821817
Epoch 297, Loss: 74.50424053397332
Epoch 298, Loss: 74.50422994286066
Epoch 299, Loss: 74.50421940448342
Epoch 300, Loss: 74.50420891844875
Epoch 301, Loss: 74.50419848436772
Epoch 302, Loss: 74.50418810185518
Epoch 303, Loss: 74.50417777052985
Epoch 304, Loss: 74.5041674900142
Epoch 305, Loss: 74.50415725993429
Epoch 306, Loss: 74.50414707992
Epoch 307, Loss: 74.50413694960471
Epoch 308, Loss: 74.50412686862543
Epoch 309, Loss: 74.50411683662266
Epoch 310, Loss: 74.5041068532404
Epoch 311, Loss: 74.50409691812608
Epoch 312, Loss: 74.50408703093058
Epoch 313, Loss: 74.50407719130803
Epoch 314, Loss: 74.504067398916
Epoch 315, Loss: 74.50405765341529
Epoch 316, Loss: 74.50404795446991
Epoch 317, Loss: 74.50403830174716
Epoch 318, Loss: 74.50402869491735
Epoch 319, Loss: 74.50401913365411
Epoch 320, Loss: 74.50400961763398
Epoch 321, Loss: 74.50400014653668
Epoch 322, Loss: 74.50399072004488
Epoch 323, Loss: 74.50398133784425
Epoch 324, Loss: 74.50397199962343
Epoch 325, Loss: 74.50396270507392
Epoch 326, Loss: 74.50395345389015
Epoch 327, Loss: 74.50394424576936
Epoch 328, Loss: 74.50393508041161
Epoch 329, Loss: 74.50392595751973
Epoch 330, Loss: 74.50391687679935
Epoch 331, Loss: 74.50390783795874
Epoch 332, Loss: 74.5038988407089
Epoch 333, Loss: 74.50388988476348
Epoch 334, Loss: 74.50388096983872
Epoch 335, Loss: 74.50387209565348
Epoch 336, Loss: 74.50386326192921
Epoch 337, Loss: 74.50385446838985
Epoch 338, Loss: 74.50384571476182
Epoch 339, Loss: 74.50383700077413
Epoch 340, Loss: 74.5038283261581
Epoch 341, Loss: 74.50381969064757
Epoch 342, Loss: 74.50381109397875
Epoch 343, Loss: 74.50380253589019
Epoch 344, Loss: 74.5037940161228
Epoch 345, Loss: 74.50378553441979
Epoch 346, Loss: 74.50377709052671
Epoch 347, Loss: 74.50376868419131
Epoch 348, Loss: 74.50376031516362
Epoch 349, Loss: 74.50375198319585
Epoch 350, Loss: 74.50374368804243
Epoch 351, Loss: 74.50373542945995
Epoch 352, Loss: 74.50372720720712
Epoch 353, Loss: 74.50371902104479
Epoch 354, Loss: 74.50371087073589
Epoch 355, Loss: 74.50370275604541
Epoch 356, Loss: 74.50369467674045
Epoch 357, Loss: 74.50368663259007
Epoch 358, Loss: 74.50367862336537
Epoch 359, Loss: 74.5036706488394
Epoch 360, Loss: 74.5036627087872
Epoch 361, Loss: 74.50365480298576
Epoch 362, Loss: 74.50364693121394
Epoch 363, Loss: 74.50363909325257
Epoch 364, Loss: 74.5036312888843
Epoch 365, Loss: 74.50362351789366
Epoch 366, Loss: 74.50361578006704
Epoch 367, Loss: 74.50360807519259
Epoch 368, Loss: 74.50360040306032
Epoch 369, Loss: 74.503592763462
Epoch 370, Loss: 74.50358515619116
Epoch 371, Loss: 74.50357758104306
Epoch 372, Loss: 74.50357003781471
Epoch 373, Loss: 74.50356252630482
Epoch 374, Loss: 74.50355504631378
Epoch 375, Loss: 74.50354759764363
Epoch 376, Loss: 74.50354018009813
Epoch 377, Loss: 74.5035327934826
Epoch 378, Loss: 74.50352543760405
Epoch 379, Loss: 74.50351811227104
Epoch 380, Loss: 74.50351081729373
Epoch 381, Loss: 74.50350355248386
Epoch 382, Loss: 74.50349631765474
Epoch 383, Loss: 74.50348911262114
Epoch 384, Loss: 74.50348193719945
Epoch 385, Loss: 74.50347479120751
Epoch 386, Loss: 74.50346767446469
Epoch 387, Loss: 74.50346058679177
Epoch 388, Loss: 74.50345352801105
Epoch 389, Loss: 74.50344649794624
Epoch 390, Loss: 74.50343949642253
Epoch 391, Loss: 74.50343252326645
Epoch 392, Loss: 74.50342557830602
Epoch 393, Loss: 74.50341866137057
Epoch 394, Loss: 74.50341177229085
Epoch 395, Loss: 74.50340491089896
Epoch 396, Loss: 74.50339807702835
Epoch 397, Loss: 74.50339127051377
Epoch 398, Loss: 74.50338449119135
Epoch 399, Loss: 74.50337773889848
Epoch 400, Loss: 74.50337101347387
Epoch 401, Loss: 74.50336431475746
Epoch 402, Loss: 74.50335764259054
Epoch 403, Loss: 74.5033509968156
Epoch 404, Loss: 74.50334437727638
Epoch 405, Loss: 74.50333778381784
Epoch 406, Loss: 74.50333121628623
Epoch 407, Loss: 74.5033246745289
Epoch 408, Loss: 74.50331815839446
Epoch 409, Loss: 74.50331166773269
Epoch 410, Loss: 74.50330520239457
Epoch 411, Loss: 74.50329876223219
Epoch 412, Loss: 74.5032923470988
Epoch 413, Loss: 74.50328595684883
Epoch 414, Loss: 74.50327959133779
Epoch 415, Loss: 74.50327325042232
Epoch 416, Loss: 74.50326693396019
Epoch 417, Loss: 74.50326064181024
Epoch 418, Loss: 74.50325437383238
Epoch 419, Loss: 74.50324812988764
Epoch 420, Loss: 74.50324190983804
Epoch 421, Loss: 74.50323571354673
Epoch 422, Loss: 74.5032295408779
Epoch 423, Loss: 74.5032233916967
Epoch 424, Loss: 74.50321726586938
Epoch 425, Loss: 74.50321116326315
Epoch 426, Loss: 74.50320508374627
Epoch 427, Loss: 74.50319902718797
Epoch 428, Loss: 74.50319299345847
Epoch 429, Loss: 74.50318698242894
Epoch 430, Loss: 74.50318099397158
Epoch 431, Loss: 74.50317502795949
Epoch 432, Loss: 74.50316908426673
Epoch 433, Loss: 74.50316316276835
Epoch 434, Loss: 74.50315726334023
Epoch 435, Loss: 74.5031513858593
Epoch 436, Loss: 74.50314553020328
Epoch 437, Loss: 74.50313969625091
Epoch 438, Loss: 74.50313388388173
Epoch 439, Loss: 74.50312809297621
Epoch 440, Loss: 74.50312232341574
Epoch 441, Loss: 74.50311657508252
Epoch 442, Loss: 74.50311084785963
Epoch 443, Loss: 74.50310514163102
Epoch 444, Loss: 74.50309945628149
Epoch 445, Loss: 74.5030937916967
Epoch 446, Loss: 74.50308814776308
Epoch 447, Loss: 74.50308252436794
Epoch 448, Loss: 74.50307692139943
Epoch 449, Loss: 74.50307133874642
Epoch 450, Loss: 74.50306577629867
Epoch 451, Loss: 74.50306023394671
Epoch 452, Loss: 74.50305471158185
Epoch 453, Loss: 74.50304920909619
Epoch 454, Loss: 74.50304372638259
Epoch 455, Loss: 74.50303826333473
Epoch 456, Loss: 74.50303281984695
Epoch 457, Loss: 74.50302739581446
Epoch 458, Loss: 74.50302199113315
Epoch 459, Loss: 74.50301660569967
Epoch 460, Loss: 74.50301123941139
Epoch 461, Loss: 74.50300589216644
Epoch 462, Loss: 74.50300056386362
Epoch 463, Loss: 74.5029952544025
Epoch 464, Loss: 74.50298996368335
Epoch 465, Loss: 74.50298469160711
Epoch 466, Loss: 74.50297943807541
Epoch 467, Loss: 74.50297420299066
Epoch 468, Loss: 74.50296898625581
Epoch 469, Loss: 74.50296378777462
Epoch 470, Loss: 74.50295860745148
Epoch 471, Loss: 74.5029534451914
Epoch 472, Loss: 74.50294830090012
Epoch 473, Loss: 74.50294317448397
Epoch 474, Loss: 74.50293806585
Epoch 475, Loss: 74.50293297490583
Epoch 476, Loss: 74.50292790155979
Epoch 477, Loss: 74.50292284572078
Epoch 478, Loss: 74.50291780729837
Epoch 479, Loss: 74.50291278620276
Epoch 480, Loss: 74.50290778234468
Epoch 481, Loss: 74.50290279563558
Epoch 482, Loss: 74.50289782598747
Epoch 483, Loss: 74.50289287331297
Epoch 484, Loss: 74.50288793752526
Epoch 485, Loss: 74.50288301853813
Epoch 486, Loss: 74.502878116266
Epoch 487, Loss: 74.50287323062382
Epoch 488, Loss: 74.50286836152713
Epoch 489, Loss: 74.50286350889205
Epoch 490, Loss: 74.50285867263523
Epoch 491, Loss: 74.50285385267392
Epoch 492, Loss: 74.50284904892592
Epoch 493, Loss: 74.5028442613096
Epoch 494, Loss: 74.50283948974383
Epoch 495, Loss: 74.50283473414805
Epoch 496, Loss: 74.50282999444224
Epoch 497, Loss: 74.50282527054688
Epoch 498, Loss: 74.50282056238305
Epoch 499, Loss: 74.50281586987231
Epoch 500, Loss: 74.50281119293672
Epoch 501, Loss: 74.50280653149889
Epoch 502, Loss: 74.50280188548194
Epoch 503, Loss: 74.50279725480948
Epoch 504, Loss: 74.50279263940564
Epoch 505, Loss: 74.50278803919505
Epoch 506, Loss: 74.5027834541028
Epoch 507, Loss: 74.50277888405452
Epoch 508, Loss: 74.50277432897634
Epoch 509, Loss: 74.50276978879478
Epoch 510, Loss: 74.50276526343693
Epoch 511, Loss: 74.50276075283031
Epoch 512, Loss: 74.50275625690296
Epoch 513, Loss: 74.50275177558329
Epoch 514, Loss: 74.50274730880031
Epoch 515, Loss: 74.50274285648338
Epoch 516, Loss: 74.50273841856236
Epoch 517, Loss: 74.50273399496754
Epoch 518, Loss: 74.50272958562971
Epoch 519, Loss: 74.50272519048005
Epoch 520, Loss: 74.50272080945021
Epoch 521, Loss: 74.50271644247228
Epoch 522, Loss: 74.50271208947876
Epoch 523, Loss: 74.5027077504026
Epoch 524, Loss: 74.5027034251772
Epoch 525, Loss: 74.50269911373633
Epoch 526, Loss: 74.50269481601423
Epoch 527, Loss: 74.50269053194552
Epoch 528, Loss: 74.50268626146527
Epoch 529, Loss: 74.50268200450896
Epoch 530, Loss: 74.50267776101245
Epoch 531, Loss: 74.502673530912
Epoch 532, Loss: 74.50266931414433
Epoch 533, Loss: 74.50266511064646
Epoch 534, Loss: 74.50266092035591
Epoch 535, Loss: 74.50265674321054
Epoch 536, Loss: 74.50265257914859
Epoch 537, Loss: 74.50264842810871
Epoch 538, Loss: 74.50264429002993
Epoch 539, Loss: 74.50264016485164
Epoch 540, Loss: 74.50263605251364
Epoch 541, Loss: 74.50263195295605
Epoch 542, Loss: 74.50262786611944
Epoch 543, Loss: 74.50262379194467
Epoch 544, Loss: 74.50261973037303
Epoch 545, Loss: 74.50261568134611
Epoch 546, Loss: 74.50261164480592
Epoch 547, Loss: 74.5026076206948
Epoch 548, Loss: 74.50260360895544
Epoch 549, Loss: 74.50259960953086
Epoch 550, Loss: 74.5025956223645
Epoch 551, Loss: 74.50259164740007
Epoch 552, Loss: 74.50258768458164
Epoch 553, Loss: 74.5025837338537
Epoch 554, Loss: 74.50257979516098
Epoch 555, Loss: 74.50257586844857
Epoch 556, Loss: 74.50257195366191
Epoch 557, Loss: 74.50256805074677
Epoch 558, Loss: 74.50256415964924
Epoch 559, Loss: 74.50256028031575
Epoch 560, Loss: 74.50255641269304
Epoch 561, Loss: 74.50255255672813
Epoch 562, Loss: 74.50254871236848
Epoch 563, Loss: 74.50254487956175
Epoch 564, Loss: 74.50254105825596
Epoch 565, Loss: 74.50253724839939
Epoch 566, Loss: 74.50253344994073
Epoch 567, Loss: 74.50252966282889
Epoch 568, Loss: 74.50252588701314
Epoch 569, Loss: 74.50252212244298
Epoch 570, Loss: 74.50251836906831
Epoch 571, Loss: 74.50251462683923
Epoch 572, Loss: 74.50251089570622
Epoch 573, Loss: 74.50250717562
Epoch 574, Loss: 74.50250346653155
Epoch 575, Loss: 74.50249976839224
Epoch 576, Loss: 74.50249608115365
Epoch 577, Loss: 74.50249240476768
Epoch 578, Loss: 74.50248873918646
Epoch 579, Loss: 74.50248508436246
Epoch 580, Loss: 74.50248144024843
Epoch 581, Loss: 74.50247780679734
Epoch 582, Loss: 74.5024741839625
Epoch 583, Loss: 74.50247057169742
Epoch 584, Loss: 74.50246696995593
Epoch 585, Loss: 74.50246337869217
Epoch 586, Loss: 74.50245979786042
Epoch 587, Loss: 74.50245622741538
Epoch 588, Loss: 74.50245266731187
Epoch 589, Loss: 74.50244911750507
Epoch 590, Loss: 74.50244557795037
Epoch 591, Loss: 74.50244204860343
Epoch 592, Loss: 74.50243852942017
Epoch 593, Loss: 74.50243502035677
Epoch 594, Loss: 74.50243152136963
Epoch 595, Loss: 74.50242803241544
Epoch 596, Loss: 74.50242455345112
Epoch 597, Loss: 74.50242108443382
Epoch 598, Loss: 74.50241762532096
Epoch 599, Loss: 74.50241417607019
Epoch 600, Loss: 74.5024107366394
Epoch 601, Loss: 74.50240730698673
Epoch 602, Loss: 74.50240388707056
Epoch 603, Loss: 74.50240047684947
Epoch 604, Loss: 74.50239707628234
Epoch 605, Loss: 74.5023936853282
Epoch 606, Loss: 74.5023903039464
Epoch 607, Loss: 74.50238693209643
Epoch 608, Loss: 74.50238356973807
Epoch 609, Loss: 74.50238021683134
Epoch 610, Loss: 74.5023768733364
Epoch 611, Loss: 74.5023735392137
Epoch 612, Loss: 74.50237021442392
Epoch 613, Loss: 74.50236689892792
Epoch 614, Loss: 74.50236359268679
Epoch 615, Loss: 74.50236029566186
Epoch 616, Loss: 74.50235700781462
Epoch 617, Loss: 74.50235372910687
Epoch 618, Loss: 74.50235045950052
Epoch 619, Loss: 74.50234719895775
Epoch 620, Loss: 74.50234394744093
Epoch 621, Loss: 74.50234070491263
Epoch 622, Loss: 74.50233747133568
Epoch 623, Loss: 74.502334246673
Epoch 624, Loss: 74.50233103088786
Epoch 625, Loss: 74.50232782394362
Epoch 626, Loss: 74.50232462580388
Epoch 627, Loss: 74.50232143643247
Epoch 628, Loss: 74.50231825579334
Epoch 629, Loss: 74.50231508385073
Epoch 630, Loss: 74.50231192056903
Epoch 631, Loss: 74.50230876591279
Epoch 632, Loss: 74.50230561984681
Epoch 633, Loss: 74.50230248233603
Epoch 634, Loss: 74.50229935334565
Epoch 635, Loss: 74.502296232841
Epoch 636, Loss: 74.5022931207876
Epoch 637, Loss: 74.50229001715121
Epoch 638, Loss: 74.50228692189769
Epoch 639, Loss: 74.50228383499318
Epoch 640, Loss: 74.5022807564039
Epoch 641, Loss: 74.50227768609636
Epoch 642, Loss: 74.50227462403714
Epoch 643, Loss: 74.5022715701931
Epoch 644, Loss: 74.50226852453122
Epoch 645, Loss: 74.50226548701865
Epoch 646, Loss: 74.50226245762275
Epoch 647, Loss: 74.50225943631102
Epoch 648, Loss: 74.50225642305118
Epoch 649, Loss: 74.50225341781108
Epoch 650, Loss: 74.50225042055874
Epoch 651, Loss: 74.50224743126238
Epoch 652, Loss: 74.50224444989034
Epoch 653, Loss: 74.50224147641121
Epoch 654, Loss: 74.50223851079367
Epoch 655, Loss: 74.5022355530066
Epoch 656, Loss: 74.50223260301902
Epoch 657, Loss: 74.50222966080014
Epoch 658, Loss: 74.5022267263193
Epoch 659, Loss: 74.50222379954603
Epoch 660, Loss: 74.50222088045001
Epoch 661, Loss: 74.50221796900112
Epoch 662, Loss: 74.50221506516931
Epoch 663, Loss: 74.50221216892473
Epoch 664, Loss: 74.50220928023772
Epoch 665, Loss: 74.50220639907873
Epoch 666, Loss: 74.50220352541837
Epoch 667, Loss: 74.50220065922744
Epoch 668, Loss: 74.50219780047682
Epoch 669, Loss: 74.50219494913762
Epoch 670, Loss: 74.50219210518102
Epoch 671, Loss: 74.50218926857846
Epoch 672, Loss: 74.5021864393014
Epoch 673, Loss: 74.50218361732152
Epoch 674, Loss: 74.50218080261065
Epoch 675, Loss: 74.50217799514073
Epoch 676, Loss: 74.50217519488386
Epoch 677, Loss: 74.50217240181229
Epoch 678, Loss: 74.50216961589842
Epoch 679, Loss: 74.50216683711476
Epoch 680, Loss: 74.50216406543397
Epoch 681, Loss: 74.50216130082889
Epoch 682, Loss: 74.50215854327244
Epoch 683, Loss: 74.50215579273771
Epoch 684, Loss: 74.50215304919793
Epoch 685, Loss: 74.50215031262644
Epoch 686, Loss: 74.50214758299674
Epoch 687, Loss: 74.50214486028247
Epoch 688, Loss: 74.50214214445737
Epoch 689, Loss: 74.50213943549535
Epoch 690, Loss: 74.50213673337042
Epoch 691, Loss: 74.50213403805674
Epoch 692, Loss: 74.50213134952858
Epoch 693, Loss: 74.50212866776039
Epoch 694, Loss: 74.50212599272669
Epoch 695, Loss: 74.50212332440215
Epoch 696, Loss: 74.50212066276156
Epoch 697, Loss: 74.50211800777986
Epoch 698, Loss: 74.50211535943208
Epoch 699, Loss: 74.50211271769342
Epoch 700, Loss: 74.50211008253916
Epoch 701, Loss: 74.50210745394475
Epoch 702, Loss: 74.50210483188566
Epoch 703, Loss: 74.50210221633762
Epoch 704, Loss: 74.50209960727638
Epoch 705, Loss: 74.50209700467786
Epoch 706, Loss: 74.50209440851808
Epoch 707, Loss: 74.50209181877317
Epoch 708, Loss: 74.50208923541942
Epoch 709, Loss: 74.50208665843317
Epoch 710, Loss: 74.50208408779095
Epoch 711, Loss: 74.50208152346931
Epoch 712, Loss: 74.50207896544504
Epoch 713, Loss: 74.50207641369494
Epoch 714, Loss: 74.50207386819598
Epoch 715, Loss: 74.50207132892518
Epoch 716, Loss: 74.50206879585977
Epoch 717, Loss: 74.502066268977
Epoch 718, Loss: 74.5020637482543
Epoch 719, Loss: 74.50206123366915
Epoch 720, Loss: 74.50205872519916
Epoch 721, Loss: 74.5020562228221
Epoch 722, Loss: 74.50205372651577
Epoch 723, Loss: 74.50205123625811
Epoch 724, Loss: 74.50204875202716
Epoch 725, Loss: 74.50204627380111
Epoch 726, Loss: 74.50204380155817
Epoch 727, Loss: 74.50204133527676
Epoch 728, Loss: 74.5020388749353
Epoch 729, Loss: 74.50203642051238
Epoch 730, Loss: 74.50203397198669
Epoch 731, Loss: 74.50203152933699
Epoch 732, Loss: 74.50202909254216
Epoch 733, Loss: 74.50202666158118
Epoch 734, Loss: 74.50202423643313
Epoch 735, Loss: 74.50202181707719
Epoch 736, Loss: 74.50201940349265
Epoch 737, Loss: 74.50201699565888
Epoch 738, Loss: 74.50201459355536
Epoch 739, Loss: 74.50201219716165
Epoch 740, Loss: 74.50200980645745
Epoch 741, Loss: 74.50200742142249
Epoch 742, Loss: 74.50200504203667
Epoch 743, Loss: 74.50200266827991
Epoch 744, Loss: 74.5020003001323
Epoch 745, Loss: 74.50199793757396
Epoch 746, Loss: 74.50199558058515
Epoch 747, Loss: 74.50199322914618
Epoch 748, Loss: 74.50199088323751
Epoch 749, Loss: 74.50198854283963
Epoch 750, Loss: 74.50198620793316
Epoch 751, Loss: 74.5019838784988
Epoch 752, Loss: 74.50198155451734
Epoch 753, Loss: 74.50197923596966
Epoch 754, Loss: 74.50197692283673
Epoch 755, Loss: 74.50197461509961
Epoch 756, Loss: 74.50197231273944
Epoch 757, Loss: 74.50197001573747
Epoch 758, Loss: 74.501967724075
Epoch 759, Loss: 74.50196543773347
Epoch 760, Loss: 74.50196315669433
Epoch 761, Loss: 74.50196088093921
Epoch 762, Loss: 74.50195861044972
Epoch 763, Loss: 74.50195634520766
Epoch 764, Loss: 74.50195408519485
Epoch 765, Loss: 74.5019518303932
Epoch 766, Loss: 74.50194958078472
Epoch 767, Loss: 74.50194733635146
Epoch 768, Loss: 74.50194509707566
Epoch 769, Loss: 74.50194286293949
Epoch 770, Loss: 74.50194063392533
Epoch 771, Loss: 74.50193841001557
Epoch 772, Loss: 74.5019361911927
Epoch 773, Loss: 74.5019339774393
Epoch 774, Loss: 74.50193176873802
Epoch 775, Loss: 74.50192956507158
Epoch 776, Loss: 74.50192736642279
Epoch 777, Loss: 74.50192517277456
Epoch 778, Loss: 74.50192298410983
Epoch 779, Loss: 74.50192080041165
Epoch 780, Loss: 74.50191862166312
Epoch 781, Loss: 74.50191644784746
Epoch 782, Loss: 74.50191427894794
Epoch 783, Loss: 74.50191211494788
Epoch 784, Loss: 74.50190995583071
Epoch 785, Loss: 74.50190780157996
Epoch 786, Loss: 74.50190565217918
Epoch 787, Loss: 74.50190350761198
Epoch 788, Loss: 74.50190136786212
Epoch 789, Loss: 74.50189923291339
Epoch 790, Loss: 74.50189710274962
Epoch 791, Loss: 74.50189497735478
Epoch 792, Loss: 74.50189285671286
Epoch 793, Loss: 74.50189074080794
Epoch 794, Loss: 74.50188862962418
Epoch 795, Loss: 74.5018865231458
Epoch 796, Loss: 74.50188442135706
Epoch 797, Loss: 74.50188232424236
Epoch 798, Loss: 74.50188023178612
Epoch 799, Loss: 74.50187814397282
Epoch 800, Loss: 74.50187606078704
Epoch 801, Loss: 74.50187398221343
Epoch 802, Loss: 74.50187190823667
Epoch 803, Loss: 74.50186983884154
Epoch 804, Loss: 74.5018677740129
Epoch 805, Loss: 74.50186571373561
Epoch 806, Loss: 74.5018636579947
Epoch 807, Loss: 74.50186160677517
Epoch 808, Loss: 74.50185956006212
Epoch 809, Loss: 74.50185751784073
Epoch 810, Loss: 74.50185548009625
Epoch 811, Loss: 74.50185344681394
Epoch 812, Loss: 74.50185141797921
Epoch 813, Loss: 74.50184939357744
Epoch 814, Loss: 74.50184737359416
Epoch 815, Loss: 74.50184535801492
Epoch 816, Loss: 74.5018433468253
Epoch 817, Loss: 74.50184134001103
Epoch 818, Loss: 74.50183933755778
Epoch 819, Loss: 74.50183733945144
Epoch 820, Loss: 74.50183534567782
Epoch 821, Loss: 74.50183335622286
Epoch 822, Loss: 74.50183137107257
Epoch 823, Loss: 74.50182939021295
Epoch 824, Loss: 74.50182741363012
Epoch 825, Loss: 74.50182544131029
Epoch 826, Loss: 74.50182347323965
Epoch 827, Loss: 74.50182150940448
Epoch 828, Loss: 74.50181954979116
Epoch 829, Loss: 74.50181759438607
Epoch 830, Loss: 74.50181564317566
Epoch 831, Loss: 74.50181369614647
Epoch 832, Loss: 74.5018117532851
Epoch 833, Loss: 74.50180981457814
Epoch 834, Loss: 74.50180788001231
Epoch 835, Loss: 74.50180594957435
Epoch 836, Loss: 74.50180402325107
Epoch 837, Loss: 74.50180210102933
Epoch 838, Loss: 74.50180018289603
Epoch 839, Loss: 74.5017982688382
Epoch 840, Loss: 74.50179635884281
Epoch 841, Loss: 74.50179445289695
Epoch 842, Loss: 74.5017925509878
Epoch 843, Loss: 74.5017906531025
Epoch 844, Loss: 74.50178875922833
Epoch 845, Loss: 74.5017868693526
Epoch 846, Loss: 74.50178498346263
Epoch 847, Loss: 74.50178310154585
Epoch 848, Loss: 74.50178122358972
Epoch 849, Loss: 74.50177934958174
Epoch 850, Loss: 74.50177747950949
Epoch 851, Loss: 74.50177561336056
Epoch 852, Loss: 74.50177375112267
Epoch 853, Loss: 74.5017718927835
Epoch 854, Loss: 74.50177003833085
Epoch 855, Loss: 74.5017681877525
Epoch 856, Loss: 74.50176634103639
Epoch 857, Loss: 74.50176449817037
Epoch 858, Loss: 74.50176265914249
Epoch 859, Loss: 74.50176082394071
Epoch 860, Loss: 74.50175899255316
Epoch 861, Loss: 74.50175716496793
Epoch 862, Loss: 74.50175534117318
Epoch 863, Loss: 74.50175352115718
Epoch 864, Loss: 74.50175170490819
Epoch 865, Loss: 74.5017498924145
Epoch 866, Loss: 74.50174808366448
Epoch 867, Loss: 74.50174627864658
Epoch 868, Loss: 74.50174447734925
Epoch 869, Loss: 74.501742679761
Epoch 870, Loss: 74.50174088587038
Epoch 871, Loss: 74.501739095666
Epoch 872, Loss: 74.5017373091365
Epoch 873, Loss: 74.50173552627061
Epoch 874, Loss: 74.50173374705706
Epoch 875, Loss: 74.50173197148463
Epoch 876, Loss: 74.50173019954218
Epoch 877, Loss: 74.50172843121857
Epoch 878, Loss: 74.50172666650275
Epoch 879, Loss: 74.50172490538365
Epoch 880, Loss: 74.50172314785036
Epoch 881, Loss: 74.50172139389187
Epoch 882, Loss: 74.50171964349734
Epoch 883, Loss: 74.50171789665589
Epoch 884, Loss: 74.50171615335672
Epoch 885, Loss: 74.5017144135891
Epoch 886, Loss: 74.50171267734225
Epoch 887, Loss: 74.50171094460558
Epoch 888, Loss: 74.50170921536836
Epoch 889, Loss: 74.50170748962009
Epoch 890, Loss: 74.50170576735019
Epoch 891, Loss: 74.50170404854813
Epoch 892, Loss: 74.50170233320351
Epoch 893, Loss: 74.50170062130584
Epoch 894, Loss: 74.50169891284482
Epoch 895, Loss: 74.50169720781005
Epoch 896, Loss: 74.50169550619127
Epoch 897, Loss: 74.50169380797823
Epoch 898, Loss: 74.50169211316069
Epoch 899, Loss: 74.50169042172848
Epoch 900, Loss: 74.5016887336715
Epoch 901, Loss: 74.50168704897965
Epoch 902, Loss: 74.50168536764288
Epoch 903, Loss: 74.50168368965116
Epoch 904, Loss: 74.50168201499456
Epoch 905, Loss: 74.5016803436631
Epoch 906, Loss: 74.50167867564693
Epoch 907, Loss: 74.50167701093616
Epoch 908, Loss: 74.50167534952104
Epoch 909, Loss: 74.50167369139173
Epoch 910, Loss: 74.50167203653851
Epoch 911, Loss: 74.5016703849517
Epoch 912, Loss: 74.50166873662164
Epoch 913, Loss: 74.50166709153869
Epoch 914, Loss: 74.50166544969332
Epoch 915, Loss: 74.5016638110759
Epoch 916, Loss: 74.50166217567698
Epoch 917, Loss: 74.50166054348709
Epoch 918, Loss: 74.50165891449677
Epoch 919, Loss: 74.50165728869665
Epoch 920, Loss: 74.50165566607735
Epoch 921, Loss: 74.50165404662954
Epoch 922, Loss: 74.50165243034397
Epoch 923, Loss: 74.50165081721136
Epoch 924, Loss: 74.5016492072225
Epoch 925, Loss: 74.50164760036822
Epoch 926, Loss: 74.50164599663935
Epoch 927, Loss: 74.50164439602682
Epoch 928, Loss: 74.50164279852154
Epoch 929, Loss: 74.50164120411446
Epoch 930, Loss: 74.50163961279661
Epoch 931, Loss: 74.50163802455901
Epoch 932, Loss: 74.50163643939271
Epoch 933, Loss: 74.50163485728882
Epoch 934, Loss: 74.50163327823849
Epoch 935, Loss: 74.50163170223288
Epoch 936, Loss: 74.5016301292632
Epoch 937, Loss: 74.5016285593207
Epoch 938, Loss: 74.50162699239661
Epoch 939, Loss: 74.5016254284823
Epoch 940, Loss: 74.50162386756904
Epoch 941, Loss: 74.50162230964824
Epoch 942, Loss: 74.50162075471131
Epoch 943, Loss: 74.50161920274967
Epoch 944, Loss: 74.50161765375479
Epoch 945, Loss: 74.5016161077182
Epoch 946, Loss: 74.50161456463141
Epoch 947, Loss: 74.50161302448599
Epoch 948, Loss: 74.50161148727356
Epoch 949, Loss: 74.50160995298575
Epoch 950, Loss: 74.50160842161418
Epoch 951, Loss: 74.50160689315058
Epoch 952, Loss: 74.5016053675867
Epoch 953, Loss: 74.50160384491427
Epoch 954, Loss: 74.50160232512508
Epoch 955, Loss: 74.50160080821095
Epoch 956, Loss: 74.50159929416373
Epoch 957, Loss: 74.50159778297532
Epoch 958, Loss: 74.5015962746376
Epoch 959, Loss: 74.50159476914254
Epoch 960, Loss: 74.50159326648213
Epoch 961, Loss: 74.50159176664833
Epoch 962, Loss: 74.5015902696332
Epoch 963, Loss: 74.5015887754288
Epoch 964, Loss: 74.50158728402724
Epoch 965, Loss: 74.50158579542062
Epoch 966, Loss: 74.50158430960109
Epoch 967, Loss: 74.50158282656085
Epoch 968, Loss: 74.50158134629208
Epoch 969, Loss: 74.50157986878708
Epoch 970, Loss: 74.50157839403805
Epoch 971, Loss: 74.50157692203733
Epoch 972, Loss: 74.50157545277726
Epoch 973, Loss: 74.50157398625014
Epoch 974, Loss: 74.5015725224484
Epoch 975, Loss: 74.50157106136444
Epoch 976, Loss: 74.5015696029907
Epoch 977, Loss: 74.50156814731966
Epoch 978, Loss: 74.50156669434377
Epoch 979, Loss: 74.5015652440556
Epoch 980, Loss: 74.5015637964477
Epoch 981, Loss: 74.50156235151263
Epoch 982, Loss: 74.501560909243
Epoch 983, Loss: 74.50155946963145
Epoch 984, Loss: 74.50155803267063
Epoch 985, Loss: 74.50155659835326
Epoch 986, Loss: 74.50155516667199
Epoch 987, Loss: 74.50155373761963
Epoch 988, Loss: 74.5015523111889
Epoch 989, Loss: 74.50155088737262
Epoch 990, Loss: 74.5015494661636
Epoch 991, Loss: 74.5015480475547
Epoch 992, Loss: 74.50154663153877
Epoch 993, Loss: 74.50154521810873
Epoch 994, Loss: 74.5015438072575
Epoch 995, Loss: 74.50154239897803
Epoch 996, Loss: 74.50154099326329
Epoch 997, Loss: 74.50153959010629
Epoch 998, Loss: 74.50153818950005
Epoch 999, Loss: 74.50153679143763</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=1, nout=4)-&gt;Layer(nin=4, nout=1)</code></pre>
</div>
</div>
<div id="06bc7133" class="cell" data-time_run="2025-12-21T15:32:02.671341+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb333"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb333-1"><a href="#cb333-1" aria-hidden="true" tabindex="-1"></a>trainloop(network, xs, ys, lr<span class="op">=</span><span class="fl">0.3</span>, num_epochs<span class="op">=</span><span class="dv">1000</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 74.50153539591211
Epoch 1, Loss: 74.50152152262905
Epoch 2, Loss: 74.50150789809553
Epoch 3, Loss: 74.50149451567381
Epoch 4, Loss: 74.50148136896051
Epoch 5, Loss: 74.50146845177625
Epoch 6, Loss: 74.50145575815596
Epoch 7, Loss: 74.50144328233964
Epoch 8, Loss: 74.50143101876367
Epoch 9, Loss: 74.50141896205247
Epoch 10, Loss: 74.5014071070106
Epoch 11, Loss: 74.50139544861534
Epoch 12, Loss: 74.50138398200946
Epoch 13, Loss: 74.50137270249454
Epoch 14, Loss: 74.50136160552452
Epoch 15, Loss: 74.50135068669954
Epoch 16, Loss: 74.50133994176012
Epoch 17, Loss: 74.50132936658159
Epoch 18, Loss: 74.50131895716885
Epoch 19, Loss: 74.5013087096512
Epoch 20, Loss: 74.50129862027768
Epoch 21, Loss: 74.50128868541236
Epoch 22, Loss: 74.50127890153001
Epoch 23, Loss: 74.50126926521193
Epoch 24, Loss: 74.5012597731419
Epoch 25, Loss: 74.5012504221024
Epoch 26, Loss: 74.50124120897098
Epoch 27, Loss: 74.50123213071676
Epoch 28, Loss: 74.50122318439705
Epoch 29, Loss: 74.50121436715423
Epoch 30, Loss: 74.50120567621268
Epoch 31, Loss: 74.5011971088758
Epoch 32, Loss: 74.50118866252333
Epoch 33, Loss: 74.50118033460855
Epoch 34, Loss: 74.50117212265577
Epoch 35, Loss: 74.50116402425792
Epoch 36, Loss: 74.50115603707403
Epoch 37, Loss: 74.50114815882716
Epoch 38, Loss: 74.50114038730213
Epoch 39, Loss: 74.50113272034345
Epoch 40, Loss: 74.50112515585329
Epoch 41, Loss: 74.50111769178963
Epoch 42, Loss: 74.5011103261644
Epoch 43, Loss: 74.50110305704162
Epoch 44, Loss: 74.50109588253585
Epoch 45, Loss: 74.50108880081048
Epoch 46, Loss: 74.50108181007607
Epoch 47, Loss: 74.50107490858903
Epoch 48, Loss: 74.50106809465
Epoch 49, Loss: 74.50106136660254
Epoch 50, Loss: 74.50105472283174
Epoch 51, Loss: 74.50104816176295
Epoch 52, Loss: 74.50104168186056
Epoch 53, Loss: 74.50103528162673
Epoch 54, Loss: 74.50102895960026
Epoch 55, Loss: 74.50102271435549
Epoch 56, Loss: 74.50101654450128
Epoch 57, Loss: 74.50101044867982
Epoch 58, Loss: 74.50100442556581
Epoch 59, Loss: 74.50099847386534
Epoch 60, Loss: 74.50099259231513
Epoch 61, Loss: 74.5009867796814
Epoch 62, Loss: 74.50098103475929
Epoch 63, Loss: 74.50097535637178
Epoch 64, Loss: 74.50096974336904
Epoch 65, Loss: 74.50096419462758
Epoch 66, Loss: 74.50095870904953
Epoch 67, Loss: 74.50095328556185
Epoch 68, Loss: 74.50094792311572
Epoch 69, Loss: 74.5009426206858
Epoch 70, Loss: 74.50093737726968
Epoch 71, Loss: 74.50093219188702
Epoch 72, Loss: 74.50092706357917
Epoch 73, Loss: 74.50092199140849
Epoch 74, Loss: 74.50091697445778
Epoch 75, Loss: 74.50091201182966
Epoch 76, Loss: 74.50090710264618
Epoch 77, Loss: 74.50090224604816
Epoch 78, Loss: 74.50089744119477
Epoch 79, Loss: 74.50089268726303
Epoch 80, Loss: 74.50088798344727
Epoch 81, Loss: 74.50088332895882
Epoch 82, Loss: 74.50087872302542
Epoch 83, Loss: 74.50087416489086
Epoch 84, Loss: 74.5008696538146
Epoch 85, Loss: 74.50086518907125
Epoch 86, Loss: 74.50086076995035
Epoch 87, Loss: 74.5008563957558
Epoch 88, Loss: 74.50085206580569
Epoch 89, Loss: 74.50084777943178
Epoch 90, Loss: 74.50084353597926
Epoch 91, Loss: 74.50083933480636
Epoch 92, Loss: 74.50083517528405
Epoch 93, Loss: 74.50083105679576
Epoch 94, Loss: 74.50082697873697
Epoch 95, Loss: 74.50082294051498
Epoch 96, Loss: 74.50081894154872
Epoch 97, Loss: 74.50081498126828
Epoch 98, Loss: 74.50081105911475
Epoch 99, Loss: 74.50080717453996
Epoch 100, Loss: 74.50080332700618
Epoch 101, Loss: 74.50079951598592
Epoch 102, Loss: 74.50079574096165
Epoch 103, Loss: 74.50079200142555
Epoch 104, Loss: 74.50078829687936
Epoch 105, Loss: 74.50078462683408
Epoch 106, Loss: 74.50078099080977
Epoch 107, Loss: 74.5007773883354
Epoch 108, Loss: 74.50077381894857
Epoch 109, Loss: 74.5007702821953
Epoch 110, Loss: 74.50076677762998
Epoch 111, Loss: 74.50076330481498
Epoch 112, Loss: 74.50075986332062
Epoch 113, Loss: 74.50075645272496
Epoch 114, Loss: 74.50075307261355
Epoch 115, Loss: 74.50074972257934
Epoch 116, Loss: 74.50074640222255
Epoch 117, Loss: 74.50074311115041
Epoch 118, Loss: 74.50073984897702
Epoch 119, Loss: 74.50073661532333
Epoch 120, Loss: 74.50073340981677
Epoch 121, Loss: 74.50073023209137
Epoch 122, Loss: 74.50072708178735
Epoch 123, Loss: 74.5007239585512
Epoch 124, Loss: 74.50072086203544
Epoch 125, Loss: 74.50071779189848
Epoch 126, Loss: 74.50071474780461
Epoch 127, Loss: 74.5007117294237
Epoch 128, Loss: 74.50070873643125
Epoch 129, Loss: 74.50070576850818
Epoch 130, Loss: 74.50070282534071
Epoch 131, Loss: 74.5006999066203
Epoch 132, Loss: 74.50069701204353
Epoch 133, Loss: 74.50069414131193
Epoch 134, Loss: 74.500691294132
Epoch 135, Loss: 74.500688470215
Epoch 136, Loss: 74.50068566927688
Epoch 137, Loss: 74.50068289103822
Epoch 138, Loss: 74.50068013522414
Epoch 139, Loss: 74.5006774015641
Epoch 140, Loss: 74.50067468979198
Epoch 141, Loss: 74.50067199964585
Epoch 142, Loss: 74.50066933086798
Epoch 143, Loss: 74.5006666832047
Epoch 144, Loss: 74.50066405640634
Epoch 145, Loss: 74.50066145022717
Epoch 146, Loss: 74.50065886442529
Epoch 147, Loss: 74.50065629876258
Epoch 148, Loss: 74.5006537530046
Epoch 149, Loss: 74.50065122692054
Epoch 150, Loss: 74.50064872028317
Epoch 151, Loss: 74.50064623286872
Epoch 152, Loss: 74.50064376445684
Epoch 153, Loss: 74.50064131483057
Epoch 154, Loss: 74.50063888377619
Epoch 155, Loss: 74.50063647108325
Epoch 156, Loss: 74.50063407654446
Epoch 157, Loss: 74.50063169995562
Epoch 158, Loss: 74.50062934111563
Epoch 159, Loss: 74.5006269998263
Epoch 160, Loss: 74.50062467589247
Epoch 161, Loss: 74.50062236912183
Epoch 162, Loss: 74.50062007932486
Epoch 163, Loss: 74.50061780631488
Epoch 164, Loss: 74.50061554990793
Epoch 165, Loss: 74.50061330992268
Epoch 166, Loss: 74.5006110861805
Epoch 167, Loss: 74.50060887850526
Epoch 168, Loss: 74.50060668672349
Epoch 169, Loss: 74.50060451066406
Epoch 170, Loss: 74.50060235015843
Epoch 171, Loss: 74.50060020504033
Epoch 172, Loss: 74.50059807514597
Epoch 173, Loss: 74.50059596031379
Epoch 174, Loss: 74.50059386038456
Epoch 175, Loss: 74.50059177520126
Epoch 176, Loss: 74.50058970460907
Epoch 177, Loss: 74.50058764845535
Epoch 178, Loss: 74.50058560658957
Epoch 179, Loss: 74.50058357886329
Epoch 180, Loss: 74.5005815651301
Epoch 181, Loss: 74.50057956524563
Epoch 182, Loss: 74.5005775790675
Epoch 183, Loss: 74.50057560645521
Epoch 184, Loss: 74.50057364727026
Epoch 185, Loss: 74.50057170137596
Epoch 186, Loss: 74.50056976863752
Epoch 187, Loss: 74.50056784892195
Epoch 188, Loss: 74.50056594209802
Epoch 189, Loss: 74.5005640480363
Epoch 190, Loss: 74.50056216660904
Epoch 191, Loss: 74.50056029769026
Epoch 192, Loss: 74.50055844115556
Epoch 193, Loss: 74.50055659688228
Epoch 194, Loss: 74.50055476474927
Epoch 195, Loss: 74.50055294463706
Epoch 196, Loss: 74.50055113642773
Epoch 197, Loss: 74.50054934000485
Epoch 198, Loss: 74.50054755525355
Epoch 199, Loss: 74.50054578206039
Epoch 200, Loss: 74.50054402031347
Epoch 201, Loss: 74.50054226990228
Epoch 202, Loss: 74.50054053071777
Epoch 203, Loss: 74.50053880265224
Epoch 204, Loss: 74.50053708559938
Epoch 205, Loss: 74.50053537945423
Epoch 206, Loss: 74.50053368411317
Epoch 207, Loss: 74.50053199947388
Epoch 208, Loss: 74.50053032543534
Epoch 209, Loss: 74.50052866189776
Epoch 210, Loss: 74.50052700876266
Epoch 211, Loss: 74.50052536593275
Epoch 212, Loss: 74.50052373331192
Epoch 213, Loss: 74.50052211080532
Epoch 214, Loss: 74.50052049831923
Epoch 215, Loss: 74.50051889576109
Epoch 216, Loss: 74.50051730303946
Epoch 217, Loss: 74.50051572006407
Epoch 218, Loss: 74.5005141467457
Epoch 219, Loss: 74.50051258299624
Epoch 220, Loss: 74.50051102872862
Epoch 221, Loss: 74.5005094838569
Epoch 222, Loss: 74.50050794829609
Epoch 223, Loss: 74.50050642196224
Epoch 224, Loss: 74.50050490477247
Epoch 225, Loss: 74.5005033966448
Epoch 226, Loss: 74.5005018974983
Epoch 227, Loss: 74.50050040725293
Epoch 228, Loss: 74.50049892582967
Epoch 229, Loss: 74.50049745315039
Epoch 230, Loss: 74.50049598913787
Epoch 231, Loss: 74.50049453371587
Epoch 232, Loss: 74.50049308680896
Epoch 233, Loss: 74.50049164834262
Epoch 234, Loss: 74.50049021824317
Epoch 235, Loss: 74.50048879643785
Epoch 236, Loss: 74.50048738285471
Epoch 237, Loss: 74.50048597742261
Epoch 238, Loss: 74.50048458007123
Epoch 239, Loss: 74.50048319073109
Epoch 240, Loss: 74.50048180933346
Epoch 241, Loss: 74.50048043581045
Epoch 242, Loss: 74.50047907009485
Epoch 243, Loss: 74.50047771212034
Epoch 244, Loss: 74.50047636182126
Epoch 245, Loss: 74.5004750191327
Epoch 246, Loss: 74.50047368399049
Epoch 247, Loss: 74.50047235633119
Epoch 248, Loss: 74.50047103609207
Epoch 249, Loss: 74.50046972321105
Epoch 250, Loss: 74.50046841762683
Epoch 251, Loss: 74.50046711927871
Epoch 252, Loss: 74.50046582810671
Epoch 253, Loss: 74.5004645440515
Epoch 254, Loss: 74.50046326705436
Epoch 255, Loss: 74.50046199705724
Epoch 256, Loss: 74.50046073400279
Epoch 257, Loss: 74.50045947783418
Epoch 258, Loss: 74.50045822849529
Epoch 259, Loss: 74.50045698593053
Epoch 260, Loss: 74.50045575008495
Epoch 261, Loss: 74.50045452090421
Epoch 262, Loss: 74.50045329833452
Epoch 263, Loss: 74.5004520823227
Epoch 264, Loss: 74.50045087281609
Epoch 265, Loss: 74.50044966976265
Epoch 266, Loss: 74.50044847311085
Epoch 267, Loss: 74.50044728280974
Epoch 268, Loss: 74.5004460988089
Epoch 269, Loss: 74.50044492105839
Epoch 270, Loss: 74.5004437495089
Epoch 271, Loss: 74.50044258411155
Epoch 272, Loss: 74.50044142481802
Epoch 273, Loss: 74.50044027158046
Epoch 274, Loss: 74.50043912435152
Epoch 275, Loss: 74.5004379830844
Epoch 276, Loss: 74.50043684773271
Epoch 277, Loss: 74.5004357182506
Epoch 278, Loss: 74.50043459459265
Epoch 279, Loss: 74.50043347671394
Epoch 280, Loss: 74.50043236456996
Epoch 281, Loss: 74.5004312581167
Epoch 282, Loss: 74.50043015731063
Epoch 283, Loss: 74.5004290621086
Epoch 284, Loss: 74.50042797246789
Epoch 285, Loss: 74.50042688834627
Epoch 286, Loss: 74.50042580970192
Epoch 287, Loss: 74.50042473649343
Epoch 288, Loss: 74.50042366867979
Epoch 289, Loss: 74.50042260622044
Epoch 290, Loss: 74.50042154907518
Epoch 291, Loss: 74.50042049720429
Epoch 292, Loss: 74.50041945056833
Epoch 293, Loss: 74.50041840912834
Epoch 294, Loss: 74.50041737284575
Epoch 295, Loss: 74.50041634168228
Epoch 296, Loss: 74.50041531560015
Epoch 297, Loss: 74.50041429456185
Epoch 298, Loss: 74.50041327853029
Epoch 299, Loss: 74.50041226746873
Epoch 300, Loss: 74.50041126134082
Epoch 301, Loss: 74.50041026011047
Epoch 302, Loss: 74.50040926374206
Epoch 303, Loss: 74.50040827220023
Epoch 304, Loss: 74.50040728545002
Epoch 305, Loss: 74.50040630345674
Epoch 306, Loss: 74.5004053261861
Epoch 307, Loss: 74.50040435360411
Epoch 308, Loss: 74.50040338567709
Epoch 309, Loss: 74.50040242237172
Epoch 310, Loss: 74.50040146365495
Epoch 311, Loss: 74.50040050949409
Epoch 312, Loss: 74.50039955985673
Epoch 313, Loss: 74.50039861471078
Epoch 314, Loss: 74.50039767402444
Epoch 315, Loss: 74.50039673776625
Epoch 316, Loss: 74.50039580590499
Epoch 317, Loss: 74.50039487840976
Epoch 318, Loss: 74.50039395524993
Epoch 319, Loss: 74.50039303639522
Epoch 320, Loss: 74.50039212181552
Epoch 321, Loss: 74.50039121148112
Epoch 322, Loss: 74.50039030536249
Epoch 323, Loss: 74.50038940343043
Epoch 324, Loss: 74.50038850565599
Epoch 325, Loss: 74.50038761201046
Epoch 326, Loss: 74.50038672246546
Epoch 327, Loss: 74.5003858369928
Epoch 328, Loss: 74.50038495556461
Epoch 329, Loss: 74.50038407815323
Epoch 330, Loss: 74.50038320473122
Epoch 331, Loss: 74.5003823352715
Epoch 332, Loss: 74.50038146974711
Epoch 333, Loss: 74.50038060813144
Epoch 334, Loss: 74.50037975039803
Epoch 335, Loss: 74.50037889652071
Epoch 336, Loss: 74.50037804647357
Epoch 337, Loss: 74.50037720023084
Epoch 338, Loss: 74.50037635776708
Epoch 339, Loss: 74.500375519057
Epoch 340, Loss: 74.50037468407558
Epoch 341, Loss: 74.50037385279803
Epoch 342, Loss: 74.50037302519974
Epoch 343, Loss: 74.50037220125633
Epoch 344, Loss: 74.50037138094362
Epoch 345, Loss: 74.50037056423773
Epoch 346, Loss: 74.50036975111486
Epoch 347, Loss: 74.50036894155153
Epoch 348, Loss: 74.50036813552437
Epoch 349, Loss: 74.5003673330103
Epoch 350, Loss: 74.50036653398638
Epoch 351, Loss: 74.5003657384299
Epoch 352, Loss: 74.50036494631834
Epoch 353, Loss: 74.50036415762936
Epoch 354, Loss: 74.50036337234083
Epoch 355, Loss: 74.5003625904308
Epoch 356, Loss: 74.50036181187755
Epoch 357, Loss: 74.50036103665944
Epoch 358, Loss: 74.50036026475513
Epoch 359, Loss: 74.50035949614343
Epoch 360, Loss: 74.50035873080328
Epoch 361, Loss: 74.50035796871387
Epoch 362, Loss: 74.50035720985451
Epoch 363, Loss: 74.5003564542047
Epoch 364, Loss: 74.50035570174416
Epoch 365, Loss: 74.5003549524527
Epoch 366, Loss: 74.50035420631035
Epoch 367, Loss: 74.50035346329732
Epoch 368, Loss: 74.50035272339395
Epoch 369, Loss: 74.50035198658075
Epoch 370, Loss: 74.50035125283841
Epoch 371, Loss: 74.50035052214778
Epoch 372, Loss: 74.50034979448986
Epoch 373, Loss: 74.50034906984577
Epoch 374, Loss: 74.5003483481969
Epoch 375, Loss: 74.50034762952463
Epoch 376, Loss: 74.50034691381065
Epoch 377, Loss: 74.50034620103668
Epoch 378, Loss: 74.50034549118469
Epoch 379, Loss: 74.5003447842367
Epoch 380, Loss: 74.50034408017497
Epoch 381, Loss: 74.50034337898185
Epoch 382, Loss: 74.50034268063982
Epoch 383, Loss: 74.50034198513154
Epoch 384, Loss: 74.5003412924398
Epoch 385, Loss: 74.50034060254752
Epoch 386, Loss: 74.50033991543778
Epoch 387, Loss: 74.50033923109376
Epoch 388, Loss: 74.50033854949879
Epoch 389, Loss: 74.50033787063634
Epoch 390, Loss: 74.50033719449004
Epoch 391, Loss: 74.50033652104361
Epoch 392, Loss: 74.50033585028089
Epoch 393, Loss: 74.50033518218588
Epoch 394, Loss: 74.5003345167427
Epoch 395, Loss: 74.50033385393562
Epoch 396, Loss: 74.50033319374894
Epoch 397, Loss: 74.50033253616719
Epoch 398, Loss: 74.500331881175
Epoch 399, Loss: 74.50033122875709
Epoch 400, Loss: 74.5003305788983
Epoch 401, Loss: 74.50032993158361
Epoch 402, Loss: 74.5003292867981
Epoch 403, Loss: 74.50032864452703
Epoch 404, Loss: 74.50032800475564
Epoch 405, Loss: 74.50032736746942
Epoch 406, Loss: 74.5003267326539
Epoch 407, Loss: 74.50032610029473
Epoch 408, Loss: 74.50032547037769
Epoch 409, Loss: 74.50032484288869
Epoch 410, Loss: 74.50032421781367
Epoch 411, Loss: 74.50032359513872
Epoch 412, Loss: 74.50032297485012
Epoch 413, Loss: 74.5003223569341
Epoch 414, Loss: 74.50032174137712
Epoch 415, Loss: 74.50032112816567
Epoch 416, Loss: 74.50032051728638
Epoch 417, Loss: 74.50031990872597
Epoch 418, Loss: 74.50031930247127
Epoch 419, Loss: 74.50031869850918
Epoch 420, Loss: 74.50031809682673
Epoch 421, Loss: 74.50031749741105
Epoch 422, Loss: 74.50031690024933
Epoch 423, Loss: 74.50031630532891
Epoch 424, Loss: 74.50031571263717
Epoch 425, Loss: 74.50031512216164
Epoch 426, Loss: 74.50031453388988
Epoch 427, Loss: 74.50031394780959
Epoch 428, Loss: 74.50031336390853
Epoch 429, Loss: 74.50031278217463
Epoch 430, Loss: 74.50031220259577
Epoch 431, Loss: 74.50031162516004
Epoch 432, Loss: 74.50031104985555
Epoch 433, Loss: 74.50031047667055
Epoch 434, Loss: 74.50030990559333
Epoch 435, Loss: 74.5003093366123
Epoch 436, Loss: 74.50030876971593
Epoch 437, Loss: 74.50030820489279
Epoch 438, Loss: 74.50030764213152
Epoch 439, Loss: 74.50030708142086
Epoch 440, Loss: 74.50030652274961
Epoch 441, Loss: 74.50030596610667
Epoch 442, Loss: 74.50030541148101
Epoch 443, Loss: 74.5003048588617
Epoch 444, Loss: 74.50030430823787
Epoch 445, Loss: 74.50030375959871
Epoch 446, Loss: 74.50030321293352
Epoch 447, Loss: 74.50030266823168
Epoch 448, Loss: 74.50030212548262
Epoch 449, Loss: 74.50030158467585
Epoch 450, Loss: 74.500301045801
Epoch 451, Loss: 74.50030050884766
Epoch 452, Loss: 74.50029997380565
Epoch 453, Loss: 74.50029944066475
Epoch 454, Loss: 74.50029890941485
Epoch 455, Loss: 74.5002983800459
Epoch 456, Loss: 74.50029785254793
Epoch 457, Loss: 74.50029732691105
Epoch 458, Loss: 74.50029680312542
Epoch 459, Loss: 74.50029628118129
Epoch 460, Loss: 74.50029576106894
Epoch 461, Loss: 74.50029524277876
Epoch 462, Loss: 74.50029472630119
Epoch 463, Loss: 74.50029421162674
Epoch 464, Loss: 74.50029369874599
Epoch 465, Loss: 74.50029318764956
Epoch 466, Loss: 74.50029267832818
Epoch 467, Loss: 74.50029217077258
Epoch 468, Loss: 74.50029166497364
Epoch 469, Loss: 74.50029116092225
Epoch 470, Loss: 74.50029065860933
Epoch 471, Loss: 74.50029015802593
Epoch 472, Loss: 74.50028965916314
Epoch 473, Loss: 74.50028916201208
Epoch 474, Loss: 74.50028866656399
Epoch 475, Loss: 74.5002881728101
Epoch 476, Loss: 74.50028768074175
Epoch 477, Loss: 74.50028719035033
Epoch 478, Loss: 74.50028670162727
Epoch 479, Loss: 74.50028621456408
Epoch 480, Loss: 74.50028572915234
Epoch 481, Loss: 74.50028524538362
Epoch 482, Loss: 74.5002847632496
Epoch 483, Loss: 74.50028428274204
Epoch 484, Loss: 74.50028380385271
Epoch 485, Loss: 74.50028332657344
Epoch 486, Loss: 74.50028285089613
Epoch 487, Loss: 74.50028237681272
Epoch 488, Loss: 74.50028190431523
Epoch 489, Loss: 74.5002814333957
Epoch 490, Loss: 74.50028096404624
Epoch 491, Loss: 74.50028049625904
Epoch 492, Loss: 74.50028003002626
Epoch 493, Loss: 74.50027956534022
Epoch 494, Loss: 74.5002791021932
Epoch 495, Loss: 74.50027864057759
Epoch 496, Loss: 74.5002781804858
Epoch 497, Loss: 74.50027772191027
Epoch 498, Loss: 74.50027726484356
Epoch 499, Loss: 74.50027680927822
Epoch 500, Loss: 74.50027635520684
Epoch 501, Loss: 74.5002759026221
Epoch 502, Loss: 74.50027545151676
Epoch 503, Loss: 74.5002750018835
Epoch 504, Loss: 74.50027455371517
Epoch 505, Loss: 74.50027410700461
Epoch 506, Loss: 74.50027366174473
Epoch 507, Loss: 74.50027321792847
Epoch 508, Loss: 74.50027277554881
Epoch 509, Loss: 74.50027233459882
Epoch 510, Loss: 74.50027189507152
Epoch 511, Loss: 74.50027145696009
Epoch 512, Loss: 74.5002710202577
Epoch 513, Loss: 74.50027058495752
Epoch 514, Loss: 74.50027015105283
Epoch 515, Loss: 74.50026971853697
Epoch 516, Loss: 74.50026928740323
Epoch 517, Loss: 74.50026885764501
Epoch 518, Loss: 74.50026842925574
Epoch 519, Loss: 74.50026800222889
Epoch 520, Loss: 74.50026757655797
Epoch 521, Loss: 74.50026715223655
Epoch 522, Loss: 74.50026672925821
Epoch 523, Loss: 74.50026630761658
Epoch 524, Loss: 74.50026588730532
Epoch 525, Loss: 74.50026546831816
Epoch 526, Loss: 74.50026505064888
Epoch 527, Loss: 74.50026463429123
Epoch 528, Loss: 74.50026421923906
Epoch 529, Loss: 74.5002638054862
Epoch 530, Loss: 74.50026339302663
Epoch 531, Loss: 74.50026298185426
Epoch 532, Loss: 74.50026257196308
Epoch 533, Loss: 74.50026216334709
Epoch 534, Loss: 74.50026175600038
Epoch 535, Loss: 74.50026134991703
Epoch 536, Loss: 74.50026094509116
Epoch 537, Loss: 74.50026054151698
Epoch 538, Loss: 74.50026013918864
Epoch 539, Loss: 74.5002597381004
Epoch 540, Loss: 74.50025933824656
Epoch 541, Loss: 74.5002589396214
Epoch 542, Loss: 74.50025854221929
Epoch 543, Loss: 74.50025814603458
Epoch 544, Loss: 74.50025775106172
Epoch 545, Loss: 74.50025735729515
Epoch 546, Loss: 74.50025696472933
Epoch 547, Loss: 74.50025657335878
Epoch 548, Loss: 74.50025618317807
Epoch 549, Loss: 74.50025579418178
Epoch 550, Loss: 74.50025540636452
Epoch 551, Loss: 74.50025501972092
Epoch 552, Loss: 74.50025463424569
Epoch 553, Loss: 74.50025424993353
Epoch 554, Loss: 74.50025386677918
Epoch 555, Loss: 74.50025348477743
Epoch 556, Loss: 74.50025310392304
Epoch 557, Loss: 74.50025272421092
Epoch 558, Loss: 74.5002523456359
Epoch 559, Loss: 74.50025196819288
Epoch 560, Loss: 74.5002515918768
Epoch 561, Loss: 74.50025121668261
Epoch 562, Loss: 74.50025084260531
Epoch 563, Loss: 74.50025046963992
Epoch 564, Loss: 74.5002500977815
Epoch 565, Loss: 74.50024972702509
Epoch 566, Loss: 74.50024935736585
Epoch 567, Loss: 74.50024898879889
Epoch 568, Loss: 74.50024862131937
Epoch 569, Loss: 74.50024825492248
Epoch 570, Loss: 74.50024788960349
Epoch 571, Loss: 74.5002475253576
Epoch 572, Loss: 74.5002471621801
Epoch 573, Loss: 74.50024680006632
Epoch 574, Loss: 74.50024643901158
Epoch 575, Loss: 74.50024607901122
Epoch 576, Loss: 74.50024572006069
Epoch 577, Loss: 74.50024536215531
Epoch 578, Loss: 74.5002450052906
Epoch 579, Loss: 74.50024464946199
Epoch 580, Loss: 74.50024429466501
Epoch 581, Loss: 74.50024394089513
Epoch 582, Loss: 74.50024358814792
Epoch 583, Loss: 74.50024323641898
Epoch 584, Loss: 74.50024288570388
Epoch 585, Loss: 74.50024253599824
Epoch 586, Loss: 74.50024218729772
Epoch 587, Loss: 74.50024183959798
Epoch 588, Loss: 74.50024149289474
Epoch 589, Loss: 74.5002411471837
Epoch 590, Loss: 74.50024080246062
Epoch 591, Loss: 74.50024045872127
Epoch 592, Loss: 74.50024011596143
Epoch 593, Loss: 74.50023977417695
Epoch 594, Loss: 74.50023943336365
Epoch 595, Loss: 74.5002390935174
Epoch 596, Loss: 74.50023875463407
Epoch 597, Loss: 74.50023841670964
Epoch 598, Loss: 74.50023807973997
Epoch 599, Loss: 74.50023774372106
Epoch 600, Loss: 74.50023740864887
Epoch 601, Loss: 74.50023707451945
Epoch 602, Loss: 74.50023674132878
Epoch 603, Loss: 74.50023640907293
Epoch 604, Loss: 74.50023607774794
Epoch 605, Loss: 74.50023574734996
Epoch 606, Loss: 74.50023541787507
Epoch 607, Loss: 74.5002350893194
Epoch 608, Loss: 74.50023476167915
Epoch 609, Loss: 74.50023443495044
Epoch 610, Loss: 74.50023410912954
Epoch 611, Loss: 74.5002337842126
Epoch 612, Loss: 74.50023346019591
Epoch 613, Loss: 74.50023313707574
Epoch 614, Loss: 74.50023281484835
Epoch 615, Loss: 74.50023249351004
Epoch 616, Loss: 74.50023217305716
Epoch 617, Loss: 74.50023185348604
Epoch 618, Loss: 74.50023153479304
Epoch 619, Loss: 74.50023121697458
Epoch 620, Loss: 74.50023090002702
Epoch 621, Loss: 74.50023058394683
Epoch 622, Loss: 74.50023026873042
Epoch 623, Loss: 74.50022995437426
Epoch 624, Loss: 74.50022964087484
Epoch 625, Loss: 74.50022932822867
Epoch 626, Loss: 74.50022901643226
Epoch 627, Loss: 74.50022870548216
Epoch 628, Loss: 74.5002283953749
Epoch 629, Loss: 74.50022808610711
Epoch 630, Loss: 74.50022777767535
Epoch 631, Loss: 74.50022747007625
Epoch 632, Loss: 74.50022716330642
Epoch 633, Loss: 74.50022685736255
Epoch 634, Loss: 74.50022655224126
Epoch 635, Loss: 74.50022624793927
Epoch 636, Loss: 74.50022594445326
Epoch 637, Loss: 74.50022564178002
Epoch 638, Loss: 74.5002253399162
Epoch 639, Loss: 74.50022503885862
Epoch 640, Loss: 74.50022473860402
Epoch 641, Loss: 74.5002244391492
Epoch 642, Loss: 74.50022414049099
Epoch 643, Loss: 74.50022384262618
Epoch 644, Loss: 74.50022354555165
Epoch 645, Loss: 74.50022324926422
Epoch 646, Loss: 74.50022295376081
Epoch 647, Loss: 74.50022265903829
Epoch 648, Loss: 74.50022236509356
Epoch 649, Loss: 74.50022207192355
Epoch 650, Loss: 74.50022177952522
Epoch 651, Loss: 74.50022148789552
Epoch 652, Loss: 74.50022119703138
Epoch 653, Loss: 74.50022090692985
Epoch 654, Loss: 74.50022061758793
Epoch 655, Loss: 74.50022032900259
Epoch 656, Loss: 74.50022004117093
Epoch 657, Loss: 74.50021975408995
Epoch 658, Loss: 74.50021946775675
Epoch 659, Loss: 74.5002191821684
Epoch 660, Loss: 74.50021889732199
Epoch 661, Loss: 74.50021861321463
Epoch 662, Loss: 74.50021832984348
Epoch 663, Loss: 74.50021804720565
Epoch 664, Loss: 74.50021776529832
Epoch 665, Loss: 74.50021748411864
Epoch 666, Loss: 74.50021720366381
Epoch 667, Loss: 74.50021692393102
Epoch 668, Loss: 74.50021664491751
Epoch 669, Loss: 74.50021636662048
Epoch 670, Loss: 74.5002160890372
Epoch 671, Loss: 74.5002158121649
Epoch 672, Loss: 74.50021553600087
Epoch 673, Loss: 74.5002152605424
Epoch 674, Loss: 74.50021498578677
Epoch 675, Loss: 74.50021471173133
Epoch 676, Loss: 74.50021443837336
Epoch 677, Loss: 74.50021416571025
Epoch 678, Loss: 74.5002138937393
Epoch 679, Loss: 74.50021362245792
Epoch 680, Loss: 74.50021335186347
Epoch 681, Loss: 74.50021308195336
Epoch 682, Loss: 74.50021281272498
Epoch 683, Loss: 74.50021254417578
Epoch 684, Loss: 74.50021227630316
Epoch 685, Loss: 74.50021200910457
Epoch 686, Loss: 74.5002117425775
Epoch 687, Loss: 74.5002114767194
Epoch 688, Loss: 74.50021121152776
Epoch 689, Loss: 74.50021094700006
Epoch 690, Loss: 74.50021068313383
Epoch 691, Loss: 74.50021041992657
Epoch 692, Loss: 74.50021015737586
Epoch 693, Loss: 74.5002098954792
Epoch 694, Loss: 74.50020963423418
Epoch 695, Loss: 74.50020937363834
Epoch 696, Loss: 74.5002091136893
Epoch 697, Loss: 74.50020885438462
Epoch 698, Loss: 74.50020859572194
Epoch 699, Loss: 74.50020833769885
Epoch 700, Loss: 74.50020808031299
Epoch 701, Loss: 74.50020782356202
Epoch 702, Loss: 74.50020756744358
Epoch 703, Loss: 74.50020731195532
Epoch 704, Loss: 74.50020705709494
Epoch 705, Loss: 74.50020680286013
Epoch 706, Loss: 74.50020654924859
Epoch 707, Loss: 74.50020629625801
Epoch 708, Loss: 74.50020604388612
Epoch 709, Loss: 74.50020579213067
Epoch 710, Loss: 74.50020554098938
Epoch 711, Loss: 74.50020529046003
Epoch 712, Loss: 74.50020504054038
Epoch 713, Loss: 74.50020479122819
Epoch 714, Loss: 74.50020454252126
Epoch 715, Loss: 74.50020429441741
Epoch 716, Loss: 74.5002040469144
Epoch 717, Loss: 74.5002038000101
Epoch 718, Loss: 74.5002035537023
Epoch 719, Loss: 74.50020330798887
Epoch 720, Loss: 74.50020306286766
Epoch 721, Loss: 74.5002028183365
Epoch 722, Loss: 74.50020257439333
Epoch 723, Loss: 74.50020233103594
Epoch 724, Loss: 74.50020208826228
Epoch 725, Loss: 74.50020184607027
Epoch 726, Loss: 74.50020160445779
Epoch 727, Loss: 74.50020136342275
Epoch 728, Loss: 74.50020112296309
Epoch 729, Loss: 74.50020088307679
Epoch 730, Loss: 74.50020064376176
Epoch 731, Loss: 74.50020040501599
Epoch 732, Loss: 74.50020016683743
Epoch 733, Loss: 74.50019992922407
Epoch 734, Loss: 74.5001996921739
Epoch 735, Loss: 74.50019945568492
Epoch 736, Loss: 74.50019921975513
Epoch 737, Loss: 74.50019898438259
Epoch 738, Loss: 74.50019874956526
Epoch 739, Loss: 74.50019851530125
Epoch 740, Loss: 74.50019828158857
Epoch 741, Loss: 74.50019804842526
Epoch 742, Loss: 74.5001978158094
Epoch 743, Loss: 74.50019758373908
Epoch 744, Loss: 74.50019735221237
Epoch 745, Loss: 74.50019712122737
Epoch 746, Loss: 74.50019689078216
Epoch 747, Loss: 74.50019666087488
Epoch 748, Loss: 74.50019643150364
Epoch 749, Loss: 74.50019620266656
Epoch 750, Loss: 74.50019597436177
Epoch 751, Loss: 74.50019574658742
Epoch 752, Loss: 74.50019551934167
Epoch 753, Loss: 74.50019529262269
Epoch 754, Loss: 74.50019506642866
Epoch 755, Loss: 74.5001948407577
Epoch 756, Loss: 74.50019461560805
Epoch 757, Loss: 74.5001943909779
Epoch 758, Loss: 74.50019416686544
Epoch 759, Loss: 74.50019394326891
Epoch 760, Loss: 74.5001937201865
Epoch 761, Loss: 74.50019349761644
Epoch 762, Loss: 74.50019327555698
Epoch 763, Loss: 74.50019305400637
Epoch 764, Loss: 74.50019283296285
Epoch 765, Loss: 74.5001926124247
Epoch 766, Loss: 74.50019239239016
Epoch 767, Loss: 74.50019217285754
Epoch 768, Loss: 74.5001919538251
Epoch 769, Loss: 74.50019173529112
Epoch 770, Loss: 74.50019151725394
Epoch 771, Loss: 74.50019129971184
Epoch 772, Loss: 74.50019108266316
Epoch 773, Loss: 74.5001908661062
Epoch 774, Loss: 74.50019065003929
Epoch 775, Loss: 74.5001904344608
Epoch 776, Loss: 74.50019021936905
Epoch 777, Loss: 74.50019000476237
Epoch 778, Loss: 74.50018979063917
Epoch 779, Loss: 74.5001895769978
Epoch 780, Loss: 74.50018936383663
Epoch 781, Loss: 74.50018915115405
Epoch 782, Loss: 74.50018893894844
Epoch 783, Loss: 74.50018872721819
Epoch 784, Loss: 74.50018851596172
Epoch 785, Loss: 74.50018830517746
Epoch 786, Loss: 74.5001880948638
Epoch 787, Loss: 74.50018788501917
Epoch 788, Loss: 74.50018767564202
Epoch 789, Loss: 74.50018746673078
Epoch 790, Loss: 74.50018725828387
Epoch 791, Loss: 74.50018705029977
Epoch 792, Loss: 74.50018684277694
Epoch 793, Loss: 74.50018663571386
Epoch 794, Loss: 74.500186429109
Epoch 795, Loss: 74.50018622296079
Epoch 796, Loss: 74.5001860172678
Epoch 797, Loss: 74.50018581202845
Epoch 798, Loss: 74.50018560724129
Epoch 799, Loss: 74.5001854029048
Epoch 800, Loss: 74.50018519901752
Epoch 801, Loss: 74.50018499557794
Epoch 802, Loss: 74.50018479258462
Epoch 803, Loss: 74.50018459003607
Epoch 804, Loss: 74.50018438793083
Epoch 805, Loss: 74.50018418626745
Epoch 806, Loss: 74.50018398504449
Epoch 807, Loss: 74.5001837842605
Epoch 808, Loss: 74.50018358391407
Epoch 809, Loss: 74.50018338400372
Epoch 810, Loss: 74.50018318452807
Epoch 811, Loss: 74.50018298548571
Epoch 812, Loss: 74.5001827868752
Epoch 813, Loss: 74.50018258869515
Epoch 814, Loss: 74.50018239094416
Epoch 815, Loss: 74.50018219362083
Epoch 816, Loss: 74.50018199672378
Epoch 817, Loss: 74.50018180025165
Epoch 818, Loss: 74.50018160420304
Epoch 819, Loss: 74.50018140857661
Epoch 820, Loss: 74.50018121337096
Epoch 821, Loss: 74.50018101858475
Epoch 822, Loss: 74.50018082421666
Epoch 823, Loss: 74.5001806302653
Epoch 824, Loss: 74.50018043672937
Epoch 825, Loss: 74.5001802436075
Epoch 826, Loss: 74.50018005089838
Epoch 827, Loss: 74.50017985860069
Epoch 828, Loss: 74.50017966671311
Epoch 829, Loss: 74.50017947523435
Epoch 830, Loss: 74.50017928416307
Epoch 831, Loss: 74.50017909349799
Epoch 832, Loss: 74.50017890323782
Epoch 833, Loss: 74.50017871338127
Epoch 834, Loss: 74.50017852392705
Epoch 835, Loss: 74.50017833487388
Epoch 836, Loss: 74.50017814622049
Epoch 837, Loss: 74.50017795796563
Epoch 838, Loss: 74.50017777010801
Epoch 839, Loss: 74.50017758264642
Epoch 840, Loss: 74.50017739557953
Epoch 841, Loss: 74.50017720890618
Epoch 842, Loss: 74.50017702262508
Epoch 843, Loss: 74.50017683673502
Epoch 844, Loss: 74.50017665123475
Epoch 845, Loss: 74.50017646612307
Epoch 846, Loss: 74.50017628139872
Epoch 847, Loss: 74.50017609706052
Epoch 848, Loss: 74.50017591310726
Epoch 849, Loss: 74.50017572953772
Epoch 850, Loss: 74.5001755463507
Epoch 851, Loss: 74.50017536354503
Epoch 852, Loss: 74.50017518111949
Epoch 853, Loss: 74.50017499907293
Epoch 854, Loss: 74.50017481740412
Epoch 855, Loss: 74.50017463611194
Epoch 856, Loss: 74.50017445519518
Epoch 857, Loss: 74.5001742746527
Epoch 858, Loss: 74.50017409448333
Epoch 859, Loss: 74.5001739146859
Epoch 860, Loss: 74.5001737352593
Epoch 861, Loss: 74.50017355620234
Epoch 862, Loss: 74.5001733775139
Epoch 863, Loss: 74.50017319919284
Epoch 864, Loss: 74.50017302123806
Epoch 865, Loss: 74.50017284364836
Epoch 866, Loss: 74.50017266642269
Epoch 867, Loss: 74.50017248955989
Epoch 868, Loss: 74.50017231305885
Epoch 869, Loss: 74.5001721369185
Epoch 870, Loss: 74.50017196113767
Epoch 871, Loss: 74.50017178571532
Epoch 872, Loss: 74.50017161065034
Epoch 873, Loss: 74.50017143594161
Epoch 874, Loss: 74.50017126158808
Epoch 875, Loss: 74.50017108758864
Epoch 876, Loss: 74.50017091394224
Epoch 877, Loss: 74.50017074064776
Epoch 878, Loss: 74.5001705677042
Epoch 879, Loss: 74.50017039511044
Epoch 880, Loss: 74.50017022286545
Epoch 881, Loss: 74.50017005096817
Epoch 882, Loss: 74.50016987941751
Epoch 883, Loss: 74.50016970821248
Epoch 884, Loss: 74.50016953735201
Epoch 885, Loss: 74.50016936683504
Epoch 886, Loss: 74.50016919666056
Epoch 887, Loss: 74.50016902682755
Epoch 888, Loss: 74.50016885733496
Epoch 889, Loss: 74.50016868818179
Epoch 890, Loss: 74.500168519367
Epoch 891, Loss: 74.5001683508896
Epoch 892, Loss: 74.50016818274854
Epoch 893, Loss: 74.50016801494284
Epoch 894, Loss: 74.5001678474715
Epoch 895, Loss: 74.50016768033353
Epoch 896, Loss: 74.50016751352791
Epoch 897, Loss: 74.50016734705366
Epoch 898, Loss: 74.50016718090983
Epoch 899, Loss: 74.50016701509536
Epoch 900, Loss: 74.50016684960933
Epoch 901, Loss: 74.50016668445076
Epoch 902, Loss: 74.50016651961866
Epoch 903, Loss: 74.50016635511209
Epoch 904, Loss: 74.50016619093005
Epoch 905, Loss: 74.50016602707161
Epoch 906, Loss: 74.5001658635358
Epoch 907, Loss: 74.50016570032169
Epoch 908, Loss: 74.5001655374283
Epoch 909, Loss: 74.5001653748547
Epoch 910, Loss: 74.50016521259995
Epoch 911, Loss: 74.50016505066311
Epoch 912, Loss: 74.50016488904328
Epoch 913, Loss: 74.50016472773946
Epoch 914, Loss: 74.50016456675078
Epoch 915, Loss: 74.50016440607631
Epoch 916, Loss: 74.50016424571511
Epoch 917, Loss: 74.50016408566628
Epoch 918, Loss: 74.50016392592892
Epoch 919, Loss: 74.5001637665021
Epoch 920, Loss: 74.50016360738492
Epoch 921, Loss: 74.50016344857647
Epoch 922, Loss: 74.50016329007588
Epoch 923, Loss: 74.50016313188223
Epoch 924, Loss: 74.50016297399465
Epoch 925, Loss: 74.50016281641224
Epoch 926, Loss: 74.50016265913413
Epoch 927, Loss: 74.50016250215941
Epoch 928, Loss: 74.50016234548724
Epoch 929, Loss: 74.50016218911671
Epoch 930, Loss: 74.50016203304698
Epoch 931, Loss: 74.50016187727715
Epoch 932, Loss: 74.5001617218064
Epoch 933, Loss: 74.50016156663384
Epoch 934, Loss: 74.50016141175863
Epoch 935, Loss: 74.50016125717988
Epoch 936, Loss: 74.50016110289677
Epoch 937, Loss: 74.50016094890846
Epoch 938, Loss: 74.5001607952141
Epoch 939, Loss: 74.50016064181283
Epoch 940, Loss: 74.50016048870383
Epoch 941, Loss: 74.50016033588626
Epoch 942, Loss: 74.5001601833593
Epoch 943, Loss: 74.5001600311221
Epoch 944, Loss: 74.50015987917385
Epoch 945, Loss: 74.50015972751373
Epoch 946, Loss: 74.50015957614092
Epoch 947, Loss: 74.5001594250546
Epoch 948, Loss: 74.50015927425395
Epoch 949, Loss: 74.50015912373817
Epoch 950, Loss: 74.50015897350646
Epoch 951, Loss: 74.50015882355802
Epoch 952, Loss: 74.50015867389203
Epoch 953, Loss: 74.5001585245077
Epoch 954, Loss: 74.50015837540424
Epoch 955, Loss: 74.50015822658085
Epoch 956, Loss: 74.50015807803676
Epoch 957, Loss: 74.50015792977118
Epoch 958, Loss: 74.50015778178332
Epoch 959, Loss: 74.50015763407238
Epoch 960, Loss: 74.50015748663762
Epoch 961, Loss: 74.50015733947826
Epoch 962, Loss: 74.50015719259352
Epoch 963, Loss: 74.5001570459826
Epoch 964, Loss: 74.50015689964481
Epoch 965, Loss: 74.50015675357932
Epoch 966, Loss: 74.5001566077854
Epoch 967, Loss: 74.50015646226228
Epoch 968, Loss: 74.50015631700924
Epoch 969, Loss: 74.5001561720255
Epoch 970, Loss: 74.5001560273103
Epoch 971, Loss: 74.50015588286293
Epoch 972, Loss: 74.50015573868262
Epoch 973, Loss: 74.50015559476863
Epoch 974, Loss: 74.50015545112025
Epoch 975, Loss: 74.50015530773672
Epoch 976, Loss: 74.50015516461731
Epoch 977, Loss: 74.50015502176132
Epoch 978, Loss: 74.50015487916797
Epoch 979, Loss: 74.50015473683656
Epoch 980, Loss: 74.5001545947664
Epoch 981, Loss: 74.50015445295675
Epoch 982, Loss: 74.50015431140687
Epoch 983, Loss: 74.50015417011609
Epoch 984, Loss: 74.50015402908366
Epoch 985, Loss: 74.50015388830889
Epoch 986, Loss: 74.50015374779109
Epoch 987, Loss: 74.50015360752953
Epoch 988, Loss: 74.50015346752352
Epoch 989, Loss: 74.50015332777237
Epoch 990, Loss: 74.50015318827536
Epoch 991, Loss: 74.50015304903185
Epoch 992, Loss: 74.50015291004107
Epoch 993, Loss: 74.50015277130242
Epoch 994, Loss: 74.50015263281516
Epoch 995, Loss: 74.5001524945786
Epoch 996, Loss: 74.50015235659211
Epoch 997, Loss: 74.50015221885496
Epoch 998, Loss: 74.50015208136651
Epoch 999, Loss: 74.50015194412609</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="0">
<pre><code>Layer(nin=1, nout=4)-&gt;Layer(nin=4, nout=1)</code></pre>
</div>
</div>
</section>
<section id="reply-91" class="level5">
<h5 class="anchored" data-anchor-id="reply-91">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>I notice the loss is decreasing, but very slowly now! With learning rate 0.3, you went from 74.50 â†’ 74.50015 over 1000 epochs - thatâ€™s progress, but itâ€™s getting stuck.</p>
<p><strong>The problem:</strong> Your network is trying to learn <code>y = xÂ²</code> with only 4 data points, which is actually quite hard for this architecture.</p>
<p><strong>A few observations:</strong></p>
<p>âš ï¸ <strong>Important:</strong> The context window is getting full - some earlier messages have been removed. Weâ€™ve covered a lot!</p>
<p><strong>What would you like to do next?</strong></p>
<ol type="1">
<li><strong>Test the network</strong> - see what predictions it makes for your 4 inputs</li>
<li><strong>Try a different problem</strong> - maybe something linear first?</li>
<li><strong>Experiment with architecture</strong> - different layer sizes?</li>
<li><strong>Take a break</strong> - weâ€™ve built a complete autograd engine and neural network from scratch! ğŸ‰</li>
</ol>
<p>What sounds most interesting to you?</p>
<p>Can you setup a complete linear problem with training code for me to just run and check a working training example</p>
</section>
<section id="reply-92" class="level5">
<h5 class="anchored" data-anchor-id="reply-92">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>âš ï¸ <strong>Important notice:</strong> The dialog has grown quite large - some earlier messages have been removed to fit in the context window. Originally there were 320 messages; now there are 213 messages.</p>
<hr>
<p>Sure! Hereâ€™s a simple linear problem (<code>y = 2x + 3</code>) with complete training code:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb336"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple linear problem: y = 2x + 3</span></span>
<span id="cb336-2"><a href="#cb336-2" aria-hidden="true" tabindex="-1"></a>xs_train <span class="op">=</span> [[<span class="dv">1</span>], [<span class="dv">2</span>], [<span class="dv">3</span>], [<span class="dv">4</span>]]</span>
<span id="cb336-3"><a href="#cb336-3" aria-hidden="true" tabindex="-1"></a>ys_train <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>]</span>
<span id="cb336-4"><a href="#cb336-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-5"><a href="#cb336-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a simple network (1 input -&gt; 1 output)</span></span>
<span id="cb336-6"><a href="#cb336-6" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MLP(<span class="dv">1</span>, [<span class="dv">1</span>])</span>
<span id="cb336-7"><a href="#cb336-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-8"><a href="#cb336-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train</span></span>
<span id="cb336-9"><a href="#cb336-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb336-10"><a href="#cb336-10" aria-hidden="true" tabindex="-1"></a>    net.zero_grad()</span>
<span id="cb336-11"><a href="#cb336-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> L(<span class="bu">zip</span>(xs_train, ys_train)).starmap(<span class="kw">lambda</span> x, y: mse(net, x, y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys_train)</span>
<span id="cb336-12"><a href="#cb336-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb336-13"><a href="#cb336-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> net.parameters(): p.data <span class="op">-=</span> p.grad <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb336-14"><a href="#cb336-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb336-15"><a href="#cb336-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb336-16"><a href="#cb336-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb336-17"><a href="#cb336-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb336-18"><a href="#cb336-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predictions:"</span>)</span>
<span id="cb336-19"><a href="#cb336-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x, y_true <span class="kw">in</span> <span class="bu">zip</span>(xs_train, ys_train):</span>
<span id="cb336-20"><a href="#cb336-20" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> net(x)[<span class="dv">0</span>].data</span>
<span id="cb336-21"><a href="#cb336-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x=</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, true=</span><span class="sc">{</span>y_true<span class="sc">}</span><span class="ss">, pred=</span><span class="sc">{</span>y_pred<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Try running this and see how well it learns the linear relationship!</p>
<div id="2a856682" class="cell" data-time_run="2025-12-21T15:35:30.998514+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb337"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb337-1"><a href="#cb337-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple linear problem: y = 2x + 3</span></span>
<span id="cb337-2"><a href="#cb337-2" aria-hidden="true" tabindex="-1"></a>xs_train <span class="op">=</span> [[<span class="dv">1</span>], [<span class="dv">2</span>], [<span class="dv">3</span>], [<span class="dv">4</span>]]</span>
<span id="cb337-3"><a href="#cb337-3" aria-hidden="true" tabindex="-1"></a>ys_train <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>]</span>
<span id="cb337-4"><a href="#cb337-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-5"><a href="#cb337-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a simple network (1 input -&gt; 1 output)</span></span>
<span id="cb337-6"><a href="#cb337-6" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MLP(<span class="dv">1</span>, [<span class="dv">1</span>])</span>
<span id="cb337-7"><a href="#cb337-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-8"><a href="#cb337-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train</span></span>
<span id="cb337-9"><a href="#cb337-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb337-10"><a href="#cb337-10" aria-hidden="true" tabindex="-1"></a>    net.zero_grad()</span>
<span id="cb337-11"><a href="#cb337-11" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> L(<span class="bu">zip</span>(xs_train, ys_train)).starmap(<span class="kw">lambda</span> x, y: mse(net, x, y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys_train)</span>
<span id="cb337-12"><a href="#cb337-12" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb337-13"><a href="#cb337-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> net.parameters(): p.data <span class="op">-=</span> p.grad <span class="op">*</span> <span class="fl">0.1</span></span>
<span id="cb337-14"><a href="#cb337-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb337-15"><a href="#cb337-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb337-16"><a href="#cb337-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb337-17"><a href="#cb337-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Test predictions</span></span>
<span id="cb337-18"><a href="#cb337-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predictions:"</span>)</span>
<span id="cb337-19"><a href="#cb337-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x, y_true <span class="kw">in</span> <span class="bu">zip</span>(xs_train, ys_train):</span>
<span id="cb337-20"><a href="#cb337-20" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> net(x)[<span class="dv">0</span>].data</span>
<span id="cb337-21"><a href="#cb337-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x=</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, true=</span><span class="sc">{</span>y_true<span class="sc">}</span><span class="ss">, pred=</span><span class="sc">{</span>y_pred<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 85.13472630860366
Epoch 10, Loss: 54.10668094362828
Epoch 20, Loss: 54.05509771904781
Epoch 30, Loss: 54.03744077614793
Epoch 40, Loss: 54.0284348353409
Epoch 50, Loss: 54.0229532715185
Epoch 60, Loss: 54.01925903762041
Epoch 70, Loss: 54.0165976185952
Epoch 80, Loss: 54.01458759448133
Epoch 90, Loss: 54.01301512373654
Epoch 100, Loss: 54.01175090717999
Epoch 110, Loss: 54.01071211559944
Epoch 120, Loss: 54.009843209237836
Epoch 130, Loss: 54.00910554100244
Epoch 140, Loss: 54.00847138031941
Epoch 150, Loss: 54.007920308482134
Epoch 160, Loss: 54.00743695500452
Epoch 170, Loss: 54.0070095265735
Epoch 180, Loss: 54.00662882247987
Epoch 190, Loss: 54.00628755852661
Epoch 200, Loss: 54.00597989218531
Epoch 210, Loss: 54.0057010823746
Epoch 220, Loss: 54.00544724131629
Epoch 230, Loss: 54.005215150634015
Epoch 240, Loss: 54.005002123082264
Epoch 250, Loss: 54.004805897213814
Epoch 260, Loss: 54.004624556175976
Epoch 270, Loss: 54.00445646442073
Epoch 280, Loss: 54.00430021787935
Epoch 290, Loss: 54.00415460437216
Epoch 300, Loss: 54.00401857188056
Epoch 310, Loss: 54.00389120291691
Epoch 320, Loss: 54.00377169366702
Epoch 330, Loss: 54.003659336898764
Epoch 340, Loss: 54.00355350786656
Epoch 350, Loss: 54.00345365261592
Epoch 360, Loss: 54.003359278224224
Epoch 370, Loss: 54.00326994461382
Epoch 380, Loss: 54.00318525764918
Epoch 390, Loss: 54.003104863289366
Epoch 400, Loss: 54.00302844261181
Epoch 410, Loss: 54.00295570755988
Epoch 420, Loss: 54.00288639729396
Epoch 430, Loss: 54.00282027504872
Epoch 440, Loss: 54.002757125416
Epoch 450, Loss: 54.002696751988054
Epoch 460, Loss: 54.00263897530614
Epoch 470, Loss: 54.0025836310695
Epoch 480, Loss: 54.00253056856679
Epoch 490, Loss: 54.00247964929862
Epoch 500, Loss: 54.00243074576424
Epoch 510, Loss: 54.00238374039014
Epoch 520, Loss: 54.002338524581766
Epoch 530, Loss: 54.002294997881705
Epoch 540, Loss: 54.00225306722105
Epoch 550, Loss: 54.0022126462519
Epoch 560, Loss: 54.002173654751005
Epoch 570, Loss: 54.0021360180858
Epoch 580, Loss: 54.00209966673543
Epoch 590, Loss: 54.002064535860185
Epoch 600, Loss: 54.002030564913674
Epoch 610, Loss: 54.00199769729312
Epoch 620, Loss: 54.001965880023164
Epoch 630, Loss: 54.00193506346967
Epoch 640, Loss: 54.00190520108027
Epoch 650, Loss: 54.001876249148594
Epoch 660, Loss: 54.001848166599984
Epoch 670, Loss: 54.0018209147962
Epoch 680, Loss: 54.00179445735732
Epoch 690, Loss: 54.00176875999894
Epoch 700, Loss: 54.00174379038343
Epoch 710, Loss: 54.001719517983574
Epoch 720, Loss: 54.001695913957526
Epoch 730, Loss: 54.00167295103401
Epoch 740, Loss: 54.0016506034068
Epoch 750, Loss: 54.001628846637615
Epoch 760, Loss: 54.00160765756654
Epoch 770, Loss: 54.0015870142295
Epoch 780, Loss: 54.001566895782034
Epoch 790, Loss: 54.001547282428774
Epoch 800, Loss: 54.001528155358244
Epoch 810, Loss: 54.00150949668246
Epoch 820, Loss: 54.001491289380866
Epoch 830, Loss: 54.001473517248414
Epoch 840, Loss: 54.001456164847234
Epoch 850, Loss: 54.00143921746175
Epoch 860, Loss: 54.00142266105688
Epoch 870, Loss: 54.001406482239176
Epoch 880, Loss: 54.00139066822051
Epoch 890, Loss: 54.00137520678424
Epoch 900, Loss: 54.00136008625367
Epoch 910, Loss: 54.00134529546244
Epoch 920, Loss: 54.00133082372703
Epoch 930, Loss: 54.00131666082086
Epoch 940, Loss: 54.00130279695013
Epoch 950, Loss: 54.00128922273113
Epoch 960, Loss: 54.001275929169026
Epoch 970, Loss: 54.00126290763791
Epoch 980, Loss: 54.00125014986202
Epoch 990, Loss: 54.00123764789815

Predictions:
x=1, true=5, pred=1.00
x=2, true=7, pred=1.00
x=3, true=9, pred=1.00
x=4, true=11, pred=1.00</code></pre>
</div>
</div>
<p>Still not working check if something is wrong ?</p>
</section>
<section id="reply-93" class="level5">
<h5 class="anchored" data-anchor-id="reply-93">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ </p>
<p>I see the problem! Look at your predictions â€” theyâ€™re all <code>1.00</code>. Thatâ€™s because <strong>tanh outputs are bounded between -1 and 1</strong>, but your targets are 5, 7, 9, 11!</p>
<p>The network is saturating at tanhâ€™s maximum value.</p>
<p><strong>Two solutions:</strong></p>
<ol type="1">
<li><strong>Scale your targets</strong> to be in [-1, 1] range</li>
<li><strong>Remove tanh activation</strong> on the output layer (linear output)</li>
</ol>
<p>For regression problems, option 2 is more common. Would you like to try modifying your <code>Neuron</code> class to optionally skip the activation?</p>
<hr>
<p>âš ï¸ <strong>Note:</strong> The dialog has grown too large for the context window. Some earlier messages have been removed. Originally there were 322 messages; now there are 208.</p>
<p>Please provide me updated Neuron with option 2. Provide complete code with training which I can run directly. Please keep patch style methods</p>
</section>
<section id="reply-94" class="level5">
<h5 class="anchored" data-anchor-id="reply-94">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>âš ï¸ <strong>Important:</strong> The dialog has grown too large - some earlier messages have been removed. Originally there were 323 messages; now there are 208.</p>
<hr>
<p>Hereâ€™s the updated code with an optional <code>nonlin</code> parameter:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb339"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Neuron:</span>
<span id="cb339-2"><a href="#cb339-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nonlin<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb339-3"><a href="#cb339-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nin <span class="op">=</span> nin </span>
<span id="cb339-4"><a href="#cb339-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nonlin <span class="op">=</span> nonlin</span>
<span id="cb339-5"><a href="#cb339-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ws <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"w</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>))</span>
<span id="cb339-6"><a href="#cb339-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"b"</span>)</span>
<span id="cb339-7"><a href="#cb339-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-8"><a href="#cb339-8" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb339-9"><a href="#cb339-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>:Neuron, xs):</span>
<span id="cb339-10"><a href="#cb339-10" aria-hidden="true" tabindex="-1"></a>    sm <span class="op">=</span> <span class="bu">sum</span>(x<span class="op">*</span>w <span class="cf">for</span> x, w <span class="kw">in</span> <span class="bu">zip</span>(xs, <span class="va">self</span>.ws)) <span class="op">+</span> <span class="va">self</span>.b</span>
<span id="cb339-11"><a href="#cb339-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sm.tanh() <span class="cf">if</span> <span class="va">self</span>.nonlin <span class="cf">else</span> sm</span>
<span id="cb339-12"><a href="#cb339-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-13"><a href="#cb339-13" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb339-14"><a href="#cb339-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Neuron): <span class="cf">return</span> <span class="va">self</span>.ws <span class="op">+</span> [<span class="va">self</span>.b]</span>
<span id="cb339-15"><a href="#cb339-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-16"><a href="#cb339-16" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Layer:</span>
<span id="cb339-17"><a href="#cb339-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nout, <span class="op">**</span>kwargs):</span>
<span id="cb339-18"><a href="#cb339-18" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nout'</span>)</span>
<span id="cb339-19"><a href="#cb339-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nns <span class="op">=</span> L(<span class="bu">range</span>(nout)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Neuron(nin, <span class="op">**</span>kwargs))</span>
<span id="cb339-20"><a href="#cb339-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs): <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron(xs))</span>
<span id="cb339-21"><a href="#cb339-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span>basic_repr(<span class="st">'nin,nout'</span>)</span>
<span id="cb339-22"><a href="#cb339-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-23"><a href="#cb339-23" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Layer)</span>
<span id="cb339-24"><a href="#cb339-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Layer): <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron.parameters()).concat()</span>
<span id="cb339-25"><a href="#cb339-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-26"><a href="#cb339-26" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP:</span>
<span id="cb339-27"><a href="#cb339-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nouts):</span>
<span id="cb339-28"><a href="#cb339-28" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nouts'</span>)</span>
<span id="cb339-29"><a href="#cb339-29" aria-hidden="true" tabindex="-1"></a>        lszs <span class="op">=</span> nouts[:]</span>
<span id="cb339-30"><a href="#cb339-30" aria-hidden="true" tabindex="-1"></a>        lszs.insert(<span class="dv">0</span>, nin)</span>
<span id="cb339-31"><a href="#cb339-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># All layers use tanh except the last (output) layer</span></span>
<span id="cb339-32"><a href="#cb339-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> L(<span class="bu">zip</span>(lszs[:<span class="op">-</span><span class="dv">2</span>], lszs[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])).starmap(Layer) <span class="op">+</span> [Layer(lszs[<span class="op">-</span><span class="dv">2</span>], lszs[<span class="op">-</span><span class="dv">1</span>], nonlin<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb339-33"><a href="#cb339-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs):</span>
<span id="cb339-34"><a href="#cb339-34" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> xs</span>
<span id="cb339-35"><a href="#cb339-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers: o <span class="op">=</span> layer(o)</span>
<span id="cb339-36"><a href="#cb339-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o</span>
<span id="cb339-37"><a href="#cb339-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="st">"-&gt;"</span>.join(<span class="bu">str</span>(l) <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers)</span>
<span id="cb339-38"><a href="#cb339-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-39"><a href="#cb339-39" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb339-40"><a href="#cb339-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:MLP): <span class="cf">return</span> L(<span class="va">self</span>.layers).<span class="bu">map</span>(<span class="kw">lambda</span> layer: layer.parameters()).concat()</span>
<span id="cb339-41"><a href="#cb339-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-42"><a href="#cb339-42" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb339-43"><a href="#cb339-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_grad(<span class="va">self</span>):</span>
<span id="cb339-44"><a href="#cb339-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.parameters(): p.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb339-45"><a href="#cb339-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-46"><a href="#cb339-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Training code</span></span>
<span id="cb339-47"><a href="#cb339-47" aria-hidden="true" tabindex="-1"></a>xs_train <span class="op">=</span> [[<span class="dv">1</span>], [<span class="dv">2</span>], [<span class="dv">3</span>], [<span class="dv">4</span>]]</span>
<span id="cb339-48"><a href="#cb339-48" aria-hidden="true" tabindex="-1"></a>ys_train <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>]</span>
<span id="cb339-49"><a href="#cb339-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-50"><a href="#cb339-50" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MLP(<span class="dv">1</span>, [<span class="dv">8</span>, <span class="dv">1</span>])  <span class="co"># 1 input -&gt; 8 hidden -&gt; 1 output (linear)</span></span>
<span id="cb339-51"><a href="#cb339-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-52"><a href="#cb339-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb339-53"><a href="#cb339-53" aria-hidden="true" tabindex="-1"></a>    net.zero_grad()</span>
<span id="cb339-54"><a href="#cb339-54" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> L(<span class="bu">zip</span>(xs_train, ys_train)).starmap(<span class="kw">lambda</span> x, y: mse(net, x, y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys_train)</span>
<span id="cb339-55"><a href="#cb339-55" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb339-56"><a href="#cb339-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> net.parameters(): p.data <span class="op">-=</span> p.grad <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb339-57"><a href="#cb339-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb339-58"><a href="#cb339-58" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb339-59"><a href="#cb339-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb339-60"><a href="#cb339-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predictions:"</span>)</span>
<span id="cb339-61"><a href="#cb339-61" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x, y_true <span class="kw">in</span> <span class="bu">zip</span>(xs_train, ys_train):</span>
<span id="cb339-62"><a href="#cb339-62" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> net(x)[<span class="dv">0</span>].data</span>
<span id="cb339-63"><a href="#cb339-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x=</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, true=</span><span class="sc">{</span>y_true<span class="sc">}</span><span class="ss">, pred=</span><span class="sc">{</span>y_pred<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Run this and see if it learns better!</p>
<div id="615d6a65" class="cell" data-time_run="2025-12-21T15:41:35.266736+00:00">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb340"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Neuron:</span>
<span id="cb340-2"><a href="#cb340-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nonlin<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb340-3"><a href="#cb340-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nin <span class="op">=</span> nin </span>
<span id="cb340-4"><a href="#cb340-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nonlin <span class="op">=</span> nonlin</span>
<span id="cb340-5"><a href="#cb340-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ws <span class="op">=</span> L(<span class="bu">range</span>(nin)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"w</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>))</span>
<span id="cb340-6"><a href="#cb340-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.b <span class="op">=</span> Value(random.uniform(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>), label<span class="op">=</span><span class="ss">f"b"</span>)</span>
<span id="cb340-7"><a href="#cb340-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-8"><a href="#cb340-8" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb340-9"><a href="#cb340-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>:Neuron, xs):</span>
<span id="cb340-10"><a href="#cb340-10" aria-hidden="true" tabindex="-1"></a>    sm <span class="op">=</span> <span class="bu">sum</span>(x<span class="op">*</span>w <span class="cf">for</span> x, w <span class="kw">in</span> <span class="bu">zip</span>(xs, <span class="va">self</span>.ws)) <span class="op">+</span> <span class="va">self</span>.b</span>
<span id="cb340-11"><a href="#cb340-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sm.tanh() <span class="cf">if</span> <span class="va">self</span>.nonlin <span class="cf">else</span> sm</span>
<span id="cb340-12"><a href="#cb340-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-13"><a href="#cb340-13" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Neuron)</span>
<span id="cb340-14"><a href="#cb340-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Neuron): <span class="cf">return</span> <span class="va">self</span>.ws <span class="op">+</span> [<span class="va">self</span>.b]</span>
<span id="cb340-15"><a href="#cb340-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-16"><a href="#cb340-16" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Layer:</span>
<span id="cb340-17"><a href="#cb340-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nout, <span class="op">**</span>kwargs):</span>
<span id="cb340-18"><a href="#cb340-18" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nout'</span>)</span>
<span id="cb340-19"><a href="#cb340-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nns <span class="op">=</span> L(<span class="bu">range</span>(nout)).<span class="bu">map</span>(<span class="kw">lambda</span> i: Neuron(nin, <span class="op">**</span>kwargs))</span>
<span id="cb340-20"><a href="#cb340-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs): <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron(xs))</span>
<span id="cb340-21"><a href="#cb340-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">__repr__</span><span class="op">=</span>basic_repr(<span class="st">'nin,nout'</span>)</span>
<span id="cb340-22"><a href="#cb340-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-23"><a href="#cb340-23" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(Layer)</span>
<span id="cb340-24"><a href="#cb340-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:Layer): <span class="cf">return</span> L(<span class="va">self</span>.nns).<span class="bu">map</span>(<span class="kw">lambda</span> neuron: neuron.parameters()).concat()</span>
<span id="cb340-25"><a href="#cb340-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-26"><a href="#cb340-26" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP:</span>
<span id="cb340-27"><a href="#cb340-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nouts):</span>
<span id="cb340-28"><a href="#cb340-28" aria-hidden="true" tabindex="-1"></a>        store_attr(<span class="st">'nin,nouts'</span>)</span>
<span id="cb340-29"><a href="#cb340-29" aria-hidden="true" tabindex="-1"></a>        lszs <span class="op">=</span> nouts[:]</span>
<span id="cb340-30"><a href="#cb340-30" aria-hidden="true" tabindex="-1"></a>        lszs.insert(<span class="dv">0</span>, nin)</span>
<span id="cb340-31"><a href="#cb340-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># All layers use tanh except the last (output) layer</span></span>
<span id="cb340-32"><a href="#cb340-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> L(<span class="bu">zip</span>(lszs[:<span class="op">-</span><span class="dv">2</span>], lszs[<span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>])).starmap(Layer) <span class="op">+</span> [Layer(lszs[<span class="op">-</span><span class="dv">2</span>], lszs[<span class="op">-</span><span class="dv">1</span>], nonlin<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb340-33"><a href="#cb340-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, xs):</span>
<span id="cb340-34"><a href="#cb340-34" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> xs</span>
<span id="cb340-35"><a href="#cb340-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers: o <span class="op">=</span> layer(o)</span>
<span id="cb340-36"><a href="#cb340-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o</span>
<span id="cb340-37"><a href="#cb340-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="st">"-&gt;"</span>.join(<span class="bu">str</span>(l) <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.layers)</span>
<span id="cb340-38"><a href="#cb340-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-39"><a href="#cb340-39" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb340-40"><a href="#cb340-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parameters(<span class="va">self</span>:MLP): <span class="cf">return</span> L(<span class="va">self</span>.layers).<span class="bu">map</span>(<span class="kw">lambda</span> layer: layer.parameters()).concat()</span>
<span id="cb340-41"><a href="#cb340-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-42"><a href="#cb340-42" aria-hidden="true" tabindex="-1"></a><span class="at">@patch_to</span>(MLP)</span>
<span id="cb340-43"><a href="#cb340-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zero_grad(<span class="va">self</span>):</span>
<span id="cb340-44"><a href="#cb340-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> <span class="va">self</span>.parameters(): p.grad <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb340-45"><a href="#cb340-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-46"><a href="#cb340-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Training code</span></span>
<span id="cb340-47"><a href="#cb340-47" aria-hidden="true" tabindex="-1"></a>xs_train <span class="op">=</span> [[<span class="dv">1</span>], [<span class="dv">2</span>], [<span class="dv">3</span>], [<span class="dv">4</span>]]</span>
<span id="cb340-48"><a href="#cb340-48" aria-hidden="true" tabindex="-1"></a>ys_train <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>]</span>
<span id="cb340-49"><a href="#cb340-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-50"><a href="#cb340-50" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> MLP(<span class="dv">1</span>, [<span class="dv">8</span>, <span class="dv">1</span>])  <span class="co"># 1 input -&gt; 8 hidden -&gt; 1 output (linear)</span></span>
<span id="cb340-51"><a href="#cb340-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-52"><a href="#cb340-52" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>):</span>
<span id="cb340-53"><a href="#cb340-53" aria-hidden="true" tabindex="-1"></a>    net.zero_grad()</span>
<span id="cb340-54"><a href="#cb340-54" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> L(<span class="bu">zip</span>(xs_train, ys_train)).starmap(<span class="kw">lambda</span> x, y: mse(net, x, y)).<span class="bu">sum</span>()<span class="op">/</span><span class="bu">len</span>(ys_train)</span>
<span id="cb340-55"><a href="#cb340-55" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb340-56"><a href="#cb340-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> p <span class="kw">in</span> net.parameters(): p.data <span class="op">-=</span> p.grad <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb340-57"><a href="#cb340-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb340-58"><a href="#cb340-58" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>data<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb340-59"><a href="#cb340-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-60"><a href="#cb340-60" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Predictions:"</span>)</span>
<span id="cb340-61"><a href="#cb340-61" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> x, y_true <span class="kw">in</span> <span class="bu">zip</span>(xs_train, ys_train):</span>
<span id="cb340-62"><a href="#cb340-62" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> net(x)[<span class="dv">0</span>].data</span>
<span id="cb340-63"><a href="#cb340-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"x=</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">, true=</span><span class="sc">{</span>y_true<span class="sc">}</span><span class="ss">, pred=</span><span class="sc">{</span>y_pred<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 54.1773
Epoch 100, Loss: 0.2514
Epoch 200, Loss: 0.1438
Epoch 300, Loss: 0.1029
Epoch 400, Loss: 0.0792
Epoch 500, Loss: 0.0629
Epoch 600, Loss: 0.0505
Epoch 700, Loss: 0.0406
Epoch 800, Loss: 0.0325
Epoch 900, Loss: 0.0262

Predictions:
x=1, true=5, pred=4.89
x=2, true=7, pred=7.11
x=3, true=9, pred=9.16
x=4, true=11, pred=10.81</code></pre>
</div>
</div>
</section>
</section>
</section>
</section>
<section id="part-9-summary-training-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="part-9-summary-training-neural-networks">Part 9 Summary: Training Neural Networks</h2>
<section id="training-loop-structure" class="level3">
<h3 class="anchored" data-anchor-id="training-loop-structure">Training Loop Structure</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb342"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb342-2"><a href="#cb342-2" aria-hidden="true" tabindex="-1"></a>    network.zero_grad()           <span class="co"># 1. Clear old gradients</span></span>
<span id="cb342-3"><a href="#cb342-3" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> compute_loss(...)      <span class="co"># 2. Forward pass</span></span>
<span id="cb342-4"><a href="#cb342-4" aria-hidden="true" tabindex="-1"></a>    loss.backward()               <span class="co"># 3. Backward pass (compute gradients)</span></span>
<span id="cb342-5"><a href="#cb342-5" aria-hidden="true" tabindex="-1"></a>    update_weights(...)           <span class="co"># 4. Gradient descent step</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="loss-function-mse" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-mse">Loss Function (MSE)</h3>
<ul>
<li><strong>Mean Squared Error</strong>: <code>(prediction - target)Â²</code></li>
<li><strong>Average over dataset</strong>: Sum individual losses, divide by count</li>
<li><strong>Purpose</strong>: Measures how far predictions are from targets</li>
</ul>
</section>
<section id="gradient-descent-update" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-update">Gradient Descent Update</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb343"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> p <span class="kw">in</span> network.parameters():</span>
<span id="cb343-2"><a href="#cb343-2" aria-hidden="true" tabindex="-1"></a>    p.data <span class="op">-=</span> learning_rate <span class="op">*</span> p.grad</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Direction</strong>: Opposite of gradient (descent)</li>
<li><strong>Learning rate</strong>: Controls step size (typically 0.01 - 0.1)</li>
</ul>
</section>
<section id="critical-insight-activation-choice" class="level3">
<h3 class="anchored" data-anchor-id="critical-insight-activation-choice">Critical Insight: Activation Choice</h3>
<ul>
<li><strong>Problem</strong>: Tanh outputs bounded in [-1, 1]</li>
<li><strong>Issue</strong>: Canâ€™t predict values like 5, 7, 9, 11</li>
<li><strong>Solution</strong>: Use <strong>linear output layer</strong> (no activation) for regression</li>
<li><strong>Result</strong>: Network can output any real value</li>
</ul>
</section>
<section id="training-results" class="level3">
<h3 class="anchored" data-anchor-id="training-results">Training Results</h3>
<ul>
<li>Linear problem (<code>y = 2x + 3</code>) successfully learned</li>
<li>Loss decreased from ~54 to ~0.026</li>
<li>Predictions close to targets (e.g., 4.89 vs 5, 7.11 vs 7)</li>
</ul>
</section>
</section>
<section id="part-10-summary-neural-network-components" class="level2">
<h2 class="anchored" data-anchor-id="part-10-summary-neural-network-components">Part 10 Summary: Neural Network Components</h2>
<section id="neuron" class="level3">
<h3 class="anchored" data-anchor-id="neuron">Neuron</h3>
<p><strong>Purpose</strong>: Basic computational unit - <strong>Inputs</strong>: Takes <code>nin</code> input values - <strong>Weights</strong>: One <code>Value</code> weight per input (randomly initialized) - <strong>Bias</strong>: Single <code>Value</code> bias term - <strong>Forward pass</strong>: <code>output = activation(Î£(wi * xi) + b)</code> - <strong>Activation</strong>: Optional (tanh for hidden layers, linear for output)</p>
</section>
<section id="layer" class="level3">
<h3 class="anchored" data-anchor-id="layer">Layer</h3>
<p><strong>Purpose</strong>: Collection of neurons processing same inputs - <strong>Structure</strong>: <code>nout</code> neurons, each with <code>nin</code> inputs - <strong>Forward pass</strong>: Each neuron independently processes input - <strong>Output</strong>: List of <code>nout</code> values</p>
</section>
<section id="mlp-multi-layer-perceptron" class="level3">
<h3 class="anchored" data-anchor-id="mlp-multi-layer-perceptron">MLP (Multi-Layer Perceptron)</h3>
<p><strong>Purpose</strong>: Stack of layers for deep learning - <strong>Architecture</strong>: Defined by <code>[nin, h1, h2, ..., nout]</code> - <strong>Hidden layers</strong>: Use tanh activation - <strong>Output layer</strong>: Linear activation (for regression) - <strong>Forward pass</strong>: Chain layers sequentially</p>
</section>
<section id="parameter-management" class="level3">
<h3 class="anchored" data-anchor-id="parameter-management">Parameter Management</h3>
<ul>
<li><strong><code>parameters()</code></strong>: Collects all weights and biases from entire network</li>
<li><strong><code>zero_grad()</code></strong>: Resets all gradients to 0 (essential before each backward pass)</li>
<li><strong>Why zero?</strong>: Gradients accumulate (<code>+=</code>), so must clear between iterations</li>
</ul>
</section>
</section>
<section id="complete-dialog-synopsis" class="level2">
<h2 class="anchored" data-anchor-id="complete-dialog-synopsis">Complete Dialog Synopsis</h2>
<section id="what-we-built" class="level3">
<h3 class="anchored" data-anchor-id="what-we-built">What We Built</h3>
<p>A <strong>complete autograd engine and neural network library from scratch</strong> - a simplified version of PyTorch/JAXâ€™s automatic differentiation system.</p>
</section>
<section id="major-accomplishments" class="level3">
<h3 class="anchored" data-anchor-id="major-accomplishments">Major Accomplishments</h3>
<section id="autograd-engine-value-class" class="level4">
<h4 class="anchored" data-anchor-id="autograd-engine-value-class">1. Autograd Engine (<code>Value</code> class)</h4>
<ul>
<li>Scalar-valued automatic differentiation</li>
<li>Computation graph tracking via <code>_prev</code> links</li>
<li>Backward propagation through arbitrary expressions</li>
<li>Support for: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>**</code> operations</li>
<li>Multiple activation functions: tanh, ReLU, Leaky ReLU, Sigmoid, GELU</li>
</ul>
</section>
<section id="backpropagation-system" class="level4">
<h4 class="anchored" data-anchor-id="backpropagation-system">2. Backpropagation System</h4>
<ul>
<li>Topological sort for correct gradient flow order</li>
<li>Automatic <code>backward()</code> method</li>
<li>Gradient accumulation for nodes used multiple times</li>
<li>Chain rule implementation through closures</li>
</ul>
</section>
<section id="neural-network-library" class="level4">
<h4 class="anchored" data-anchor-id="neural-network-library">3. Neural Network Library</h4>
<ul>
<li><code>Neuron</code>: Basic computational unit with weights, bias, optional activation</li>
<li><code>Layer</code>: Collection of neurons</li>
<li><code>MLP</code>: Multi-layer perceptron with configurable architecture</li>
<li>Parameter management and gradient zeroing</li>
</ul>
</section>
<section id="training-infrastructure" class="level4">
<h4 class="anchored" data-anchor-id="training-infrastructure">4. Training Infrastructure</h4>
<ul>
<li>Mean squared error loss function</li>
<li>Gradient descent optimizer</li>
<li>Complete training loop</li>
<li>Successfully trained on linear regression problem</li>
</ul>
</section>
</section>
<section id="key-concepts-learned" class="level3">
<h3 class="anchored" data-anchor-id="key-concepts-learned">Key Concepts Learned</h3>
<p><strong>Derivatives &amp; Gradients</strong> - Local derivatives vs global gradients - Chain rule for composite functions - Gradient accumulation with <code>+=</code></p>
<p><strong>Computation Graphs</strong> - Forward pass builds graph - Backward pass traverses in reverse - Topological ordering ensures correctness</p>
<p><strong>Neural Networks</strong> - Activation functions and their purposes - Why output layers need linear activation for regression - Parameter initialization and updates</p>
<p><strong>Training</strong> - Forward pass â†’ loss â†’ backward pass â†’ update cycle - Importance of <code>zero_grad()</code> before each iteration - Learning rate selection</p>
</section>
<section id="following-andrej-karpathys-approach" class="level3">
<h3 class="anchored" data-anchor-id="following-andrej-karpathys-approach">Following Andrej Karpathyâ€™s Approach</h3>
<p>This implementation closely follows the micrograd tutorial, building understanding through: 1. Manual derivative calculation 2. Implementing <code>_backward</code> for each operation 3. Automating with topological sort 4. Building neural network abstractions on top</p>
</section>
<section id="final-achievement" class="level3">
<h3 class="anchored" data-anchor-id="final-achievement">Final Achievement</h3>
<p>âœ… Working neural network that learns <code>y = 2x + 3</code> from 4 examples âœ… Loss: 54 â†’ 0.026 over 1000 epochs âœ… Predictions: Within ~0.2 of true values</p>
<p>Can you review the dialog so far and add notes with headings and subheadings in correct places. You can use &amp;add_msg. Please make sure you add headings and subheadings and not just summary. Final Provide synopsis of entire dialog by adding a note below</p>
<section id="reply-95" class="level5">
<h5 class="anchored" data-anchor-id="reply-95">ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c --></h5>
<p>âš ï¸ <strong>Important:</strong> The dialog has grown too large - some earlier messages have been removed from the start. Originally there were 326 messages; now there are 205 messages.</p>
<hr>
<p>Iâ€™ll add structured notes throughout the dialog with proper headings and subheadings, then create a comprehensive synopsis at the end.</p>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb344"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01WZoa7PgpT4We8KYECp6Aji"</span><span class="fu">,</span></span>
<span id="cb344-3"><a href="#cb344-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb344-4"><a href="#cb344-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb344-5"><a href="#cb344-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb344-6"><a href="#cb344-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 1: Understanding Derivatives and Gradients</span><span class="ch">\n\n</span><span class="st">### What is a Derivative?</span><span class="ch">\n</span><span class="st">- **Definition**: Sensitivity or slope - how much output changes when input changes</span><span class="ch">\n</span><span class="st">- **Numerical approximation**: `(f(x+h) - f(x)) / h` for small h</span><span class="ch">\n</span><span class="st">- **Sign interpretation**: </span><span class="ch">\n</span><span class="st">  - Positive = function increasing</span><span class="ch">\n</span><span class="st">  - Negative = function decreasing</span><span class="ch">\n</span><span class="st">  - Zero = critical point (min/max/inflection)</span><span class="ch">\n\n</span><span class="st">### Multiple Inputs (Partial Derivatives)</span><span class="ch">\n</span><span class="st">- Each input has its own partial derivative</span><span class="ch">\n</span><span class="st">- **Example**: For `d = a*b + c`</span><span class="ch">\n</span><span class="st">  - </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">a = b</span><span class="ch">\n</span><span class="st">  - </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">b = a</span><span class="ch">\n</span><span class="st">  - </span><span class="ch">\u2202</span><span class="st">d/</span><span class="ch">\u2202</span><span class="st">c = 1</span><span class="ch">\n\n</span><span class="st">### Chain Rule Fundamentals</span><span class="ch">\n</span><span class="st">- **Local derivative**: How current n&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb344-7"><a href="#cb344-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb344-8"><a href="#cb344-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb344-9"><a href="#cb344-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_1a6d681c"</span></span>
<span id="cb344-10"><a href="#cb344-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb344-11"><a href="#cb344-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb344-12"><a href="#cb344-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_93f56ee0'"</span></span>
<span id="cb344-13"><a href="#cb344-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb345"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb345-2"><a href="#cb345-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01Xvmxj6HFedACFcxP8RrDyK"</span><span class="fu">,</span></span>
<span id="cb345-3"><a href="#cb345-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb345-4"><a href="#cb345-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb345-5"><a href="#cb345-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb345-6"><a href="#cb345-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 2: Building the Value Class</span><span class="ch">\n\n</span><span class="st">### Core Components</span><span class="ch">\n</span><span class="st">- **`data`**: The actual numerical value</span><span class="ch">\n</span><span class="st">- **`_prev`**: Set of parent nodes (builds computation graph)</span><span class="ch">\n</span><span class="st">- **`_op`**: Operation that created this value (for visualization)</span><span class="ch">\n</span><span class="st">- **`grad`**: Gradient (initialized to 0, accumulated during backprop)</span><span class="ch">\n</span><span class="st">- **`_backward`**: Function to propagate gradients (closure that remembers operands)</span><span class="ch">\n\n</span><span class="st">### Primitive Operations (with `_backward`)</span><span class="ch">\n</span><span class="st">1. **Addition (`__add__`)**: Local derivative = 1 for both operands</span><span class="ch">\n</span><span class="st">2. **Multiplication (`__mul__`)**: Local derivatives swap - `</span><span class="ch">\u2202</span><span class="st">(a*b)/</span><span class="ch">\u2202</span><span class="st">a = b`, `</span><span class="ch">\u2202</span><span class="st">(a*b)/</span><span class="ch">\u2202</span><span class="st">b = a`</span><span class="ch">\n</span><span class="st">3. **Power &lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb345-7"><a href="#cb345-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb345-8"><a href="#cb345-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb345-9"><a href="#cb345-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_81d39513"</span></span>
<span id="cb345-10"><a href="#cb345-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb345-11"><a href="#cb345-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb345-12"><a href="#cb345-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_81c1abcf'"</span></span>
<span id="cb345-13"><a href="#cb345-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb346"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb346-2"><a href="#cb346-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01BagW9wAZD2dhY4jGY1ECAh"</span><span class="fu">,</span></span>
<span id="cb346-3"><a href="#cb346-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb346-4"><a href="#cb346-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb346-5"><a href="#cb346-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb346-6"><a href="#cb346-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 3: Activation Functions</span><span class="ch">\n\n</span><span class="st">### Implemented Activations</span><span class="ch">\n\n</span><span class="st">#### 1. Tanh (Hyperbolic Tangent)</span><span class="ch">\n</span><span class="st">- **Forward**: `tanh(x) = (e^(2x) - 1) / (e^(2x) + 1)`</span><span class="ch">\n</span><span class="st">- **Backward**: `</span><span class="ch">\u2202</span><span class="st">tanh/</span><span class="ch">\u2202</span><span class="st">x = 1 - tanh</span><span class="ch">\u00b2</span><span class="st">(x)`</span><span class="ch">\n</span><span class="st">- **Range**: [-1, 1]</span><span class="ch">\n\n</span><span class="st">#### 2. ReLU (Rectified Linear Unit)</span><span class="ch">\n</span><span class="st">- **Forward**: `max(0, x)`</span><span class="ch">\n</span><span class="st">- **Backward**: `1 if x &gt; 0, else 0`</span><span class="ch">\n</span><span class="st">- **Use case**: Most common in modern networks</span><span class="ch">\n\n</span><span class="st">#### 3. Leaky ReLU</span><span class="ch">\n</span><span class="st">- **Forward**: `x if x &gt; 0, else </span><span class="ch">\u03b1</span><span class="st">*x` (</span><span class="ch">\u03b1</span><span class="st"> typically 0.01)</span><span class="ch">\n</span><span class="st">- **Backward**: `1 if x &gt; 0, else </span><span class="ch">\u03b1</span><span class="st">`</span><span class="ch">\n</span><span class="st">- **Advantage**: Prevents </span><span class="ch">\"</span><span class="st">dying ReLU</span><span class="ch">\"</span><span class="st"> problem</span><span class="ch">\n\n</span><span class="st">#### 4. Sigmoid</span><span class="ch">\n</span><span class="st">- **Forward**: `1 / (1 + e^(-x))`</span><span class="ch">\n</span><span class="st">- **Backward**: `</span><span class="ch">\u03c3</span><span class="st">(x) * (&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb346-7"><a href="#cb346-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb346-8"><a href="#cb346-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb346-9"><a href="#cb346-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_723054de"</span></span>
<span id="cb346-10"><a href="#cb346-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb346-11"><a href="#cb346-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb346-12"><a href="#cb346-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_6315c300'"</span></span>
<span id="cb346-13"><a href="#cb346-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb347"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb347-2"><a href="#cb347-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01HQiymyxZmhKT1u12Atohwt"</span><span class="fu">,</span></span>
<span id="cb347-3"><a href="#cb347-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb347-4"><a href="#cb347-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb347-5"><a href="#cb347-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb347-6"><a href="#cb347-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 4: Topological Sort and Automatic Backpropagation</span><span class="ch">\n\n</span><span class="st">### Why Topological Sort?</span><span class="ch">\n</span><span class="st">- **Problem**: Must call `_backward()` on nodes in correct order</span><span class="ch">\n</span><span class="st">- **Requirement**: Each node needs its output's `.grad` already filled in</span><span class="ch">\n</span><span class="st">- **Solution**: Reverse topological order (output </span><span class="ch">\u2192</span><span class="st"> inputs)</span><span class="ch">\n\n</span><span class="st">### Algorithm (DFS-based)</span><span class="ch">\n</span><span class="st">```</span><span class="ch">\n</span><span class="st">1. Start at output node</span><span class="ch">\n</span><span class="st">2. Mark as visited (avoid reprocessing)</span><span class="ch">\n</span><span class="st">3. Recursively visit all children FIRST</span><span class="ch">\n</span><span class="st">4. THEN add yourself to the list</span><span class="ch">\n</span><span class="st">5. Reverse the list for backprop</span><span class="ch">\n</span><span class="st">```</span><span class="ch">\n\n</span><span class="st">### The `backward()` Method</span><span class="ch">\n</span><span class="st">```python</span><span class="ch">\n</span><span class="st">def backward(self):</span><span class="ch">\n</span><span class="st">    self.grad = 1.0              # Base case: output&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb347-7"><a href="#cb347-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb347-8"><a href="#cb347-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb347-9"><a href="#cb347-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_46954e0e"</span></span>
<span id="cb347-10"><a href="#cb347-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb347-11"><a href="#cb347-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb347-12"><a href="#cb347-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_dcabea43'"</span></span>
<span id="cb347-13"><a href="#cb347-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb348"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb348-2"><a href="#cb348-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01Nx2jGiakBDUwuXfCDiCgyX"</span><span class="fu">,</span></span>
<span id="cb348-3"><a href="#cb348-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb348-4"><a href="#cb348-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb348-5"><a href="#cb348-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb348-6"><a href="#cb348-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 5: Neural Network Components</span><span class="ch">\n\n</span><span class="st">### Neuron</span><span class="ch">\n</span><span class="st">**Purpose**: Basic computational unit</span><span class="ch">\n</span><span class="st">- **Inputs**: Takes `nin` input values</span><span class="ch">\n</span><span class="st">- **Weights**: One `Value` weight per input (randomly initialized)</span><span class="ch">\n</span><span class="st">- **Bias**: Single `Value` bias term</span><span class="ch">\n</span><span class="st">- **Forward pass**: `output = activation(</span><span class="ch">\u03a3</span><span class="st">(wi * xi) + b)`</span><span class="ch">\n</span><span class="st">- **Activation**: Optional (tanh for hidden layers, linear for output)</span><span class="ch">\n\n</span><span class="st">### Layer</span><span class="ch">\n</span><span class="st">**Purpose**: Collection of neurons processing same inputs</span><span class="ch">\n</span><span class="st">- **Structure**: `nout` neurons, each with `nin` inputs</span><span class="ch">\n</span><span class="st">- **Forward pass**: Each neuron independently processes input</span><span class="ch">\n</span><span class="st">- **Output**: List of `nout` values</span><span class="ch">\n\n</span><span class="st">### MLP (Multi-La&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb348-7"><a href="#cb348-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb348-8"><a href="#cb348-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb348-9"><a href="#cb348-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_615d6a65"</span></span>
<span id="cb348-10"><a href="#cb348-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb348-11"><a href="#cb348-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb348-12"><a href="#cb348-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_6eef3abd'"</span></span>
<span id="cb348-13"><a href="#cb348-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb349"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb349-2"><a href="#cb349-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_01BJ5weXhZGZ6A5RZuKmiDxd"</span><span class="fu">,</span></span>
<span id="cb349-3"><a href="#cb349-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb349-4"><a href="#cb349-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb349-5"><a href="#cb349-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb349-6"><a href="#cb349-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Part 6: Training Neural Networks</span><span class="ch">\n\n</span><span class="st">### Training Loop Structure</span><span class="ch">\n</span><span class="st">```python</span><span class="ch">\n</span><span class="st">for epoch in range(num_epochs):</span><span class="ch">\n</span><span class="st">    network.zero_grad()           # 1. Clear old gradients</span><span class="ch">\n</span><span class="st">    loss = compute_loss(...)      # 2. Forward pass</span><span class="ch">\n</span><span class="st">    loss.backward()               # 3. Backward pass (compute gradients)</span><span class="ch">\n</span><span class="st">    update_weights(...)           # 4. Gradient descent step</span><span class="ch">\n</span><span class="st">```</span><span class="ch">\n\n</span><span class="st">### Loss Function (MSE)</span><span class="ch">\n</span><span class="st">- **Mean Squared Error**: `(prediction - target)</span><span class="ch">\u00b2</span><span class="st">`</span><span class="ch">\n</span><span class="st">- **Average over dataset**: Sum individual losses, divide by count</span><span class="ch">\n</span><span class="st">- **Purpose**: Measures how far predictions are from targets</span><span class="ch">\n\n</span><span class="st">### Gradient Descent Update</span><span class="ch">\n</span><span class="st">```python</span><span class="ch">\n</span><span class="st">f&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb349-7"><a href="#cb349-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb349-8"><a href="#cb349-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb349-9"><a href="#cb349-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_615d6a65"</span></span>
<span id="cb349-10"><a href="#cb349-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb349-11"><a href="#cb349-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb349-12"><a href="#cb349-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_0f81399d'"</span></span>
<span id="cb349-13"><a href="#cb349-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<p>Now let me add a comprehensive synopsis:</p>
<details class="tool-usage-details">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb350"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb350-2"><a href="#cb350-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"id"</span><span class="fu">:</span> <span class="st">"toolu_012h3W9QCACm3Rvt3DpQPqG4"</span><span class="fu">,</span></span>
<span id="cb350-3"><a href="#cb350-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"call"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb350-4"><a href="#cb350-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"function"</span><span class="fu">:</span> <span class="st">"add_msg"</span><span class="fu">,</span></span>
<span id="cb350-5"><a href="#cb350-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"arguments"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="cb350-6"><a href="#cb350-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"content"</span><span class="fu">:</span> <span class="st">"## Complete Dialog Synopsis</span><span class="ch">\n\n</span><span class="st">### What We Built</span><span class="ch">\n</span><span class="st">A **complete autograd engine and neural network library from scratch** - a simplified version of PyTorch/JAX's automatic differentiation system.</span><span class="ch">\n\n</span><span class="st">### Major Accomplishments</span><span class="ch">\n\n</span><span class="st">#### 1. Autograd Engine (`Value` class)</span><span class="ch">\n</span><span class="st">- Scalar-valued automatic differentiation</span><span class="ch">\n</span><span class="st">- Computation graph tracking via `_prev` links</span><span class="ch">\n</span><span class="st">- Backward propagation through arbitrary expressions</span><span class="ch">\n</span><span class="st">- Support for: `+`, `-`, `*`, `/`, `**` operations</span><span class="ch">\n</span><span class="st">- Multiple activation functions: tanh, ReLU, Leaky ReLU, Sigmoid, GELU</span><span class="ch">\n\n</span><span class="st">#### 2. Backpropagation System</span><span class="ch">\n</span><span class="st">- Topological sort for correct gradient flow&lt;TRUNCATED&gt;"</span><span class="fu">,</span></span>
<span id="cb350-7"><a href="#cb350-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msg_type"</span><span class="fu">:</span> <span class="st">"note"</span><span class="fu">,</span></span>
<span id="cb350-8"><a href="#cb350-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"placement"</span><span class="fu">:</span> <span class="st">"add_after"</span><span class="fu">,</span></span>
<span id="cb350-9"><a href="#cb350-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"msgid"</span><span class="fu">:</span> <span class="st">"_4943e17d"</span></span>
<span id="cb350-10"><a href="#cb350-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb350-11"><a href="#cb350-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">},</span></span>
<span id="cb350-12"><a href="#cb350-12" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"result"</span><span class="fu">:</span> <span class="st">"'_c0901417'"</span></span>
<span id="cb350-13"><a href="#cb350-13" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<p>Done! Iâ€™ve added structured notes with headings and subheadings throughout the dialog:</p>
<ol type="1">
<li><strong>Part 1</strong>: Understanding Derivatives and Gradients</li>
<li><strong>Part 2</strong>: Building the Value Class</li>
<li><strong>Part 3</strong>: Activation Functions</li>
<li><strong>Part 4</strong>: Topological Sort and Automatic Backpropagation</li>
<li><strong>Part 5</strong>: Neural Network Components</li>
<li><strong>Part 6</strong>: Training Neural Networks</li>
<li><strong>Complete Dialog Synopsis</strong>: Comprehensive overview of everything accomplished</li>
</ol>
<p>Each section includes proper headings, subheadings, and organized information for easy review!</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/Rahuketu86\.github\.io\/solveit_z2h");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Rahuketu86/solveit_z2h/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>